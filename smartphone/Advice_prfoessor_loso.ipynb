{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Activity Recognition with Smartphones\n",
    "## Experiment Plan and Approaches\n",
    "### 1. Summary of Professor's Advice\n",
    "- General Obserbation:\n",
    "    - Typically, activities such as walking, running, sitting, and lying down yield high classification accuracy. However, my results show the opposite - ambiguous activities like walking downstairs/upstairs are classified with higher accuracy. This raises some questions.\n",
    "- Professor's Recommendations:\n",
    "    - Preprocessing:\n",
    "        - Apply different preprocessing methods because different preprocessing approaches yield different results.\n",
    "    - Compare Different ML Pipelines:\n",
    "        - Compare various machine learning flows (e.g. LGBM, LSTM, Transfer Learning) to evaluate their performance.\n",
    "    - Cross Validation Strategy:\n",
    "        - Use k-fold and Leave-One-Subject-Out (LOSO) cross-validation methods.\n",
    "    - Transfer Learning:\n",
    "        - Explore transfer learning approaches.\n",
    "    - Raw Data Analysis:\n",
    "        - Try to perform analysis on raw data (i.e., without dimensionality reduction methods like PCA or t-SNE)\n",
    "\n",
    "### 2. Experiment Plan\n",
    "Our experiments will be divided into two major categories:\n",
    "\n",
    "### [1] Data Preprocessing Comparison\n",
    "\n",
    "### 1. t-SNE Approach:\n",
    "- Objective: Compare the performance after applying t-SNE for dimensionality reduction followed by LightGBM classification, both in standard splits and LOSO cross-validation.\n",
    "- Experiments:\n",
    "    - t-SNE: LightGBM classifier evaluation.\n",
    "    - t-SNE: LOSO cross validation evaluation.\n",
    "\n",
    "### 2. Raw Data Approach:\n",
    "    1. Raw Data Approach:\n",
    "    - Objective: Compare the performance of a LightGBM classifier using raw data under standard train/test splits versus LOSO cross-validation.\n",
    "    - Experiments:\n",
    "        - Raw data -> LightGBM classifier evaluation.\n",
    "        - Raw data -> LOSO cross-validation evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "### [2] Raw Data Analysis (Without Feature Engineering such as PCA/t-SNE)\n",
    "\n",
    "### 1. Activity Classification Accuracy:\n",
    "    - Target: Classify activities (e.g, lying, walking, running) using the entire dataset.\n",
    "    - Methods:\n",
    "        - Compare approaches using LGBM, LSTM, and Transfer Learning.\n",
    "\n",
    "### 2. Activity Classification with LOSO:\n",
    "    - Target: Evaluate activity classification using LOSO cross-validation.\n",
    "    - Methods:\n",
    "        - Compare LGBM, LSTM, and Transfer Learning approaches.\n",
    "\n",
    "### 3. Per-Activity Accuracy:\n",
    "    - Target: Evaluate the subject classification accuracy for each activity (e.g., LAYING, WALKING, etc.).\n",
    "    - Methods:\n",
    "        - Compare LGBM, LSTM, and Transfer Learning results for each activity.\n",
    "\n",
    "### 4. Per-Activity Accuracy with LOSO:\n",
    "    - Target: Evaluate the subject classification accuracy for each activity using LOSO cross-validation.\n",
    "    - Methods:\n",
    "        - Compare LGBM, LSTM, and Transfer Learning approaches for each activity under LOSO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between training with a standard train/test split and using LOSO is whether the model has indirectly seen data related to the test set during training. \n",
    "\n",
    "With a conventional train/test split, the training data and test data are drawn from the same overall distribution, so the model benefits from patterns that are common across the dataset. \n",
    "\n",
    "This typically results in higher accuracy when evaluating on the test set.\n",
    "\n",
    "---\n",
    "\n",
    "In contrast, LOSO (Leave-One-Subject-Out) ensures that the model is trained without any exposure to one entire subject’s data. \n",
    "\n",
    "This means the model is tested on completely unseen data from a subject it has never encountered before. \n",
    "\n",
    "Although this often results in lower accuracy compared to a standard train/test split, LOSO provides a more realistic simulation of how the model would perform when new user data is introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To store data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "\n",
    "# To create plots\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# To create nicer plots\n",
    "import seaborn as sns\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To get new datatypes and functions\n",
    "from collections import Counter\n",
    "from cycler import cycler\n",
    "\n",
    "# To investigate distributions\n",
    "from scipy.stats import norm, skew, probplot\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# To build models\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import LeaveOneGroupOut, KFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# To gbm light\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# To measure time\n",
    "from time import time\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # FutureWarning만 무시\n",
    "# 혹은 모든 경고 무시: warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check gpu availability\n",
    "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During preprocessing or EDA, it is acceptable to combine the train and test sets to examine the data. \n",
    "\n",
    "However, when it comes to model training and final performance evaluation, the train and test sets must be clearly separated to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Train:\t(7352, 564)\n",
      "Shape Test:\t(2947, 564)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  angle(tBodyAccMean,gravity)  \\\n",
       "0         -0.923527         -0.934724  ...                    -0.112754   \n",
       "1         -0.957686         -0.943068  ...                     0.053477   \n",
       "2         -0.977469         -0.938692  ...                    -0.118559   \n",
       "3         -0.989302         -0.938692  ...                    -0.036788   \n",
       "4         -0.990441         -0.942469  ...                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  subject  Activity   Data  \n",
       "0              0.179941             -0.058627        1  STANDING  Train  \n",
       "1              0.180289             -0.054317        1  STANDING  Train  \n",
       "2              0.180637             -0.049118        1  STANDING  Train  \n",
       "3              0.181935             -0.047663        1  STANDING  Train  \n",
       "4              0.185151             -0.043892        1  STANDING  Train  \n",
       "\n",
       "[5 rows x 564 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# combine both datasets\n",
    "train_df['Data'] = 'Train'\n",
    "test_df['Data'] = 'Test'\n",
    "\n",
    "both_df = pd.concat([train_df, test_df], axis = 0).reset_index(drop = True)\n",
    "both_df['subject'] = '#' + both_df['subject'].astype(str)\n",
    "\n",
    "label = both_df.pop('Activity')\n",
    "label_counts = label.value_counts()\n",
    "\n",
    "print('Shape Train:\\t{}'.format(train_df.shape))\n",
    "print('Shape Test:\\t{}'.format(test_df.shape))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values in DataFrames: 0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10299 entries, 0 to 10298\n",
      "Columns: 563 entries, tBodyAcc-mean()-X to Data\n",
      "dtypes: float64(561), object(2)\n",
      "memory usage: 44.2+ MB\n"
     ]
    }
   ],
   "source": [
    "print('Null Values in DataFrames: {}\\n'.format(both_df.isna().sum().sum()))\n",
    "both_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>#1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>#1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>#1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>#1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>#1</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.710304   \n",
       "1         -0.957686         -0.943068  ...                        -0.861499   \n",
       "2         -0.977469         -0.938692  ...                        -0.760104   \n",
       "3         -0.989302         -0.938692  ...                        -0.482845   \n",
       "4         -0.990441         -0.942469  ...                        -0.699205   \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                    -0.112754                              0.030400   \n",
       "1                     0.053477                             -0.007435   \n",
       "2                    -0.118559                              0.177899   \n",
       "3                    -0.036788                             -0.012892   \n",
       "4                     0.123320                              0.122542   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.464761                             -0.018446   \n",
       "1                         -0.732626                              0.703511   \n",
       "2                          0.100699                              0.808529   \n",
       "3                          0.640011                             -0.485366   \n",
       "4                          0.693578                             -0.615971   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  subject  \\\n",
       "0             -0.841247              0.179941             -0.058627       #1   \n",
       "1             -0.844788              0.180289             -0.054317       #1   \n",
       "2             -0.848933              0.180637             -0.049118       #1   \n",
       "3             -0.848649              0.181935             -0.047663       #1   \n",
       "4             -0.847865              0.185151             -0.043892       #1   \n",
       "\n",
       "    Data  \n",
       "0  Train  \n",
       "1  Train  \n",
       "2  Train  \n",
       "3  Train  \n",
       "4  Train  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = both_df.copy()\n",
    "data_data = raw_data.pop('Data')\n",
    "subject_data = raw_data.pop('subject')\n",
    "\n",
    "scl = StandardScaler()\n",
    "raw_data = scl.fit_transform(raw_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for using LOSO (Leave-One-Subject-Out) is to verify that the model can generalize well to bew subjects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the data after appluing only scaling without performing dimensionality reduction (e.g., PCA or t-SNE)\n",
    "\n",
    "[BASE]\n",
    "- With PCA/t-SNE applied [LGBM]: 0.86%\n",
    "- With raw data [LGBM]: 0.99%\n",
    "\n",
    "\n",
    "[LOSO]\n",
    "- With PCA/t-SNE applied [LGBM]: 0.82% (cross validation reached up to 90% in some folds)\n",
    "- With raw data [LGBM]: 0.94%\n",
    "\n",
    "Overall, the raw data performs better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity accuracy - With raw data [LGBM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset:\t0.9930\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "label_encoded = enc.fit_transform(label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_data, label_encoded, random_state = 3)\n",
    "\n",
    "# create the model\n",
    "lgbm = LGBMClassifier(n_estimators = 500, random_state = 3, device = device, verbose = -1)\n",
    "lgbm = lgbm.fit(X_train, y_train)\n",
    "\n",
    "score = accuracy_score(y_true = y_test, y_pred = lgbm.predict(X_test))\n",
    "print('Accuracy on testset:\\t{:.4f}'.format(score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity accuracy - With raw data [LSTM - BASE]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "early_stopping_patience = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes) # Finally fully connected layer for classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (hn, cn) = self.lstm(x) # Use the hidden state from the last time step of each sequence. \n",
    "        ## hn and cn represent the cell state, which are often not used in subsequent operations.\n",
    "        out = out[:, -1, :] # Select the hidden state from the last time step.\n",
    "        out = self.fc(out) # Pass the last time step's hidden state through the fully connected layer.\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = raw_data.reshape(raw_data.shape[0], 1, raw_data.shape[1])\n",
    "y = label_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 3)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype = torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype = torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype = torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Loss: 0.7564 Acc: 0.8287\n",
      "Epoch 2/50 Loss: 0.2484 Acc: 0.9430\n",
      "Epoch 3/50 Loss: 0.1352 Acc: 0.9649\n",
      "Epoch 4/50 Loss: 0.0921 Acc: 0.9757\n",
      "Epoch 5/50 Loss: 0.0750 Acc: 0.9783\n",
      "Epoch 6/50 Loss: 0.0586 Acc: 0.9824\n",
      "Epoch 7/50 Loss: 0.0494 Acc: 0.9839\n",
      "Epoch 8/50 Loss: 0.0406 Acc: 0.9886\n",
      "Epoch 9/50 Loss: 0.0367 Acc: 0.9881\n",
      "Epoch 10/50 Loss: 0.0327 Acc: 0.9908\n",
      "Epoch 11/50 Loss: 0.0264 Acc: 0.9931\n",
      "Epoch 12/50 Loss: 0.0226 Acc: 0.9943\n",
      "Epoch 13/50 Loss: 0.0225 Acc: 0.9934\n",
      "Epoch 14/50 Loss: 0.0191 Acc: 0.9943\n",
      "Epoch 15/50 Loss: 0.0148 Acc: 0.9970\n",
      "Epoch 16/50 Loss: 0.0129 Acc: 0.9973\n",
      "Epoch 17/50 Loss: 0.0114 Acc: 0.9984\n",
      "Epoch 18/50 Loss: 0.0092 Acc: 0.9988\n",
      "Epoch 19/50 Loss: 0.0096 Acc: 0.9983\n",
      "Epoch 20/50 Loss: 0.0068 Acc: 0.9993\n",
      "Epoch 21/50 Loss: 0.0063 Acc: 0.9992\n",
      "Epoch 22/50 Loss: 0.0053 Acc: 0.9995\n",
      "Epoch 23/50 Loss: 0.0043 Acc: 1.0000\n",
      "Epoch 24/50 Loss: 0.0040 Acc: 0.9999\n",
      "Epoch 25/50 Loss: 0.0034 Acc: 1.0000\n",
      "Epoch 26/50 Loss: 0.0033 Acc: 1.0000\n",
      "Epoch 27/50 Loss: 0.0027 Acc: 1.0000\n",
      "Epoch 28/50 Loss: 0.0024 Acc: 0.9999\n",
      "Epoch 29/50 Loss: 0.0022 Acc: 1.0000\n",
      "Epoch 30/50 Loss: 0.0019 Acc: 1.0000\n",
      "Epoch 31/50 Loss: 0.0017 Acc: 1.0000\n",
      "Epoch 32/50 Loss: 0.0040 Acc: 0.9988\n",
      "Epoch 33/50 Loss: 0.0049 Acc: 0.9995\n",
      "Epoch 34/50 Loss: 0.0048 Acc: 0.9993\n",
      "Epoch 35/50 Loss: 0.0020 Acc: 0.9999\n",
      "Epoch 36/50 Loss: 0.0013 Acc: 1.0000\n",
      "Epoch 37/50 Loss: 0.0010 Acc: 1.0000\n",
      "Epoch 38/50 Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 39/50 Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 40/50 Loss: 0.0008 Acc: 1.0000\n",
      "Epoch 41/50 Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 42/50 Loss: 0.0006 Acc: 1.0000\n",
      "Epoch 43/50 Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 44/50 Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 45/50 Loss: 0.0005 Acc: 1.0000\n",
      "Epoch 46/50 Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 47/50 Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 48/50 Loss: 0.0004 Acc: 1.0000\n",
      "Epoch 49/50 Loss: 0.0003 Acc: 1.0000\n",
      "Epoch 50/50 Loss: 0.0003 Acc: 1.0000\n",
      "\n",
      " LSTM Test Accuracy: 0.9859\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(input_dim = X_train_tensor.shape[2], hidden_dim = 64, num_layers = 1, num_classes = len(np.unique(label_encoded)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = train_loss / len(train_dataset)\n",
    "    epoch_acc = train_corrects.double() / len(train_dataset)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} Train Loss: {epoch_loss:.4f} Train Acc: {epoch_acc:.4f}')\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "test_acc = test_corrects.double() / len(test_dataset)\n",
    "print(f'\\n LSTM Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity accuracy - With raw data [LSTM - early stopping / reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Train Loss: 0.7298 Acc: 0.8179 || Val Loss: 0.3396 Acc: 0.9311\n",
      "Epoch 2/50 Train Loss: 0.2365 Acc: 0.9455 || Val Loss: 0.1672 Acc: 0.9563\n",
      "Epoch 3/50 Train Loss: 0.1312 Acc: 0.9667 || Val Loss: 0.1228 Acc: 0.9646\n",
      "Epoch 4/50 Train Loss: 0.0942 Acc: 0.9734 || Val Loss: 0.0930 Acc: 0.9733\n",
      "Epoch 5/50 Train Loss: 0.0703 Acc: 0.9805 || Val Loss: 0.0797 Acc: 0.9757\n",
      "Epoch 6/50 Train Loss: 0.0606 Acc: 0.9829 || Val Loss: 0.0790 Acc: 0.9762\n",
      "Epoch 7/50 Train Loss: 0.0494 Acc: 0.9856 || Val Loss: 0.0683 Acc: 0.9767\n",
      "Epoch 8/50 Train Loss: 0.0460 Acc: 0.9851 || Val Loss: 0.0609 Acc: 0.9782\n",
      "Epoch 9/50 Train Loss: 0.0402 Acc: 0.9874 || Val Loss: 0.0634 Acc: 0.9762\n",
      "Epoch 10/50 Train Loss: 0.0328 Acc: 0.9903 || Val Loss: 0.0541 Acc: 0.9796\n",
      "Epoch 11/50 Train Loss: 0.0320 Acc: 0.9904 || Val Loss: 0.0542 Acc: 0.9796\n",
      "Epoch 12/50 Train Loss: 0.0240 Acc: 0.9939 || Val Loss: 0.0510 Acc: 0.9782\n",
      "Epoch 13/50 Train Loss: 0.0222 Acc: 0.9936 || Val Loss: 0.0496 Acc: 0.9801\n",
      "Epoch 14/50 Train Loss: 0.0194 Acc: 0.9948 || Val Loss: 0.0485 Acc: 0.9816\n",
      "Epoch 15/50 Train Loss: 0.0167 Acc: 0.9967 || Val Loss: 0.0468 Acc: 0.9820\n",
      "Epoch 16/50 Train Loss: 0.0151 Acc: 0.9967 || Val Loss: 0.0446 Acc: 0.9859\n",
      "Epoch 17/50 Train Loss: 0.0130 Acc: 0.9976 || Val Loss: 0.0475 Acc: 0.9816\n",
      "Epoch 18/50 Train Loss: 0.0122 Acc: 0.9976 || Val Loss: 0.0462 Acc: 0.9825\n",
      "Epoch 19/50 Train Loss: 0.0151 Acc: 0.9953 || Val Loss: 0.0441 Acc: 0.9825\n",
      "Epoch 20/50 Train Loss: 0.0087 Acc: 0.9992 || Val Loss: 0.0454 Acc: 0.9820\n",
      "Epoch 21/50 Train Loss: 0.0103 Acc: 0.9975 || Val Loss: 0.0523 Acc: 0.9777\n",
      "Epoch 22/50 Train Loss: 0.0074 Acc: 0.9992 || Val Loss: 0.0426 Acc: 0.9840\n",
      "Epoch 23/50 Train Loss: 0.0057 Acc: 0.9996 || Val Loss: 0.0399 Acc: 0.9840\n",
      "Epoch 24/50 Train Loss: 0.0053 Acc: 0.9995 || Val Loss: 0.0389 Acc: 0.9854\n",
      "Epoch 25/50 Train Loss: 0.0041 Acc: 0.9999 || Val Loss: 0.0414 Acc: 0.9835\n",
      "Epoch 26/50 Train Loss: 0.0041 Acc: 0.9999 || Val Loss: 0.0425 Acc: 0.9840\n",
      "Epoch 27/50 Train Loss: 0.0035 Acc: 0.9998 || Val Loss: 0.0394 Acc: 0.9864\n",
      "Epoch 28/50 Train Loss: 0.0032 Acc: 0.9999 || Val Loss: 0.0364 Acc: 0.9854\n",
      "Epoch 29/50 Train Loss: 0.0028 Acc: 1.0000 || Val Loss: 0.0441 Acc: 0.9854\n",
      "Epoch 30/50 Train Loss: 0.0031 Acc: 0.9998 || Val Loss: 0.0425 Acc: 0.9845\n",
      "Epoch 31/50 Train Loss: 0.0024 Acc: 1.0000 || Val Loss: 0.0422 Acc: 0.9859\n",
      "Epoch 00032: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 32/50 Train Loss: 0.0018 Acc: 1.0000 || Val Loss: 0.0430 Acc: 0.9859\n",
      "Epoch 33/50 Train Loss: 0.0016 Acc: 1.0000 || Val Loss: 0.0395 Acc: 0.9854\n",
      "Early stopping triggered at epoch 33\n",
      "\n",
      "LSTM Test Accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(input_dim = X_train_tensor.shape[2], hidden_dim = 64, num_layers = 1, num_classes = len(np.unique(label_encoded)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Use ReduceLROnPlateau to reduce the learning rate when the validation loss stops improving.\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = 3, factor = 0.5, verbose = True)\n",
    "\n",
    "# Initialize early stopping variables\n",
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    # Training phase\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and number of correct predictions.\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_train_loss = train_loss / len(train_dataset)\n",
    "    epoch_train_acc  = train_corrects.double() / len(train_dataset)\n",
    "    \n",
    "    # Validation phase (using test set as validation)\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "    epoch_val_loss = val_loss / len(test_dataset)\n",
    "    epoch_val_acc  = val_corrects.double() / len(test_dataset)\n",
    "\n",
    "    # Update the scheduler with the validation loss\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} '\n",
    "          f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f} || '\n",
    "          f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')\n",
    "\n",
    "    # Early stopping check: if validation loss does not improve, increment counter\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= early_stopping_patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Final evaluateion on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_corrects = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "test_acc = test_corrects.double() / len(test_dataset)\n",
    "print(f'\\nLSTM Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity accuracy - With raw data [Transfer Learning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I was unable to find a suitable transfer learning model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw DATA LOSO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity each subject accuracy [LOSO]- With raw data [LGBM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testset:\t0.9470\n"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "accuracy_list = []\n",
    "classification_reports = []\n",
    "\n",
    "for train_idx, test_idx in logo.split(raw_data, label_encoded, subject_data):\n",
    "    X_train, X_test = raw_data[train_idx], raw_data[test_idx]\n",
    "    y_train, y_test = label_encoded[train_idx], label_encoded[test_idx]\n",
    "    \n",
    "    model = LGBMClassifier(n_estimators = 500, random_state = 3, device = device, verbose =-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict = True)\n",
    "\n",
    "    accuracy_list.append(accuracy)\n",
    "    classification_reports.append(report)\n",
    "\n",
    "average_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "\n",
    "print('Accuracy on testset:\\t{:.4f}'.format(average_accuracy))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity each subject accuracy [LOSO]- With raw data [LSTM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 1/50, Train Loss: 0.9427, Val Loss: 0.4726\n",
      "Epoch 2/50, Train Loss: 0.3448, Val Loss: 0.1931\n",
      "Epoch 3/50, Train Loss: 0.1887, Val Loss: 0.1036\n",
      "Epoch 4/50, Train Loss: 0.1276, Val Loss: 0.0806\n",
      "Epoch 5/50, Train Loss: 0.0988, Val Loss: 0.0634\n",
      "Epoch 6/50, Train Loss: 0.0802, Val Loss: 0.0434\n",
      "Epoch 7/50, Train Loss: 0.0652, Val Loss: 0.0391\n",
      "Epoch 8/50, Train Loss: 0.0575, Val Loss: 0.0384\n",
      "Epoch 9/50, Train Loss: 0.0495, Val Loss: 0.0342\n",
      "Epoch 10/50, Train Loss: 0.0423, Val Loss: 0.0306\n",
      "Epoch 11/50, Train Loss: 0.0366, Val Loss: 0.0425\n",
      "Epoch 12/50, Train Loss: 0.0343, Val Loss: 0.0248\n",
      "Epoch 13/50, Train Loss: 0.0297, Val Loss: 0.0258\n",
      "Epoch 14/50, Train Loss: 0.0265, Val Loss: 0.0222\n",
      "Epoch 15/50, Train Loss: 0.0255, Val Loss: 0.0233\n",
      "Epoch 16/50, Train Loss: 0.0224, Val Loss: 0.0218\n",
      "Epoch 17/50, Train Loss: 0.0213, Val Loss: 0.0225\n",
      "Epoch 18/50, Train Loss: 0.0175, Val Loss: 0.0165\n",
      "Epoch 19/50, Train Loss: 0.0160, Val Loss: 0.0143\n",
      "Epoch 20/50, Train Loss: 0.0141, Val Loss: 0.0203\n",
      "Epoch 21/50, Train Loss: 0.0136, Val Loss: 0.0197\n",
      "Epoch 22/50, Train Loss: 0.0112, Val Loss: 0.0138\n",
      "Epoch 23/50, Train Loss: 0.0110, Val Loss: 0.0156\n",
      "Epoch 24/50, Train Loss: 0.0089, Val Loss: 0.0106\n",
      "Epoch 25/50, Train Loss: 0.0080, Val Loss: 0.0132\n",
      "Epoch 26/50, Train Loss: 0.0075, Val Loss: 0.0143\n",
      "Epoch 27/50, Train Loss: 0.0067, Val Loss: 0.0164\n",
      "Epoch 28/50, Train Loss: 0.0063, Val Loss: 0.0154\n",
      "Epoch 29/50, Train Loss: 0.0056, Val Loss: 0.0141\n",
      "Epoch 30/50, Train Loss: 0.0048, Val Loss: 0.0112\n",
      "Epoch 31/50, Train Loss: 0.0054, Val Loss: 0.0093\n",
      "Epoch 32/50, Train Loss: 0.0037, Val Loss: 0.0104\n",
      "Epoch 33/50, Train Loss: 0.0029, Val Loss: 0.0078\n",
      "Epoch 34/50, Train Loss: 0.0031, Val Loss: 0.0092\n",
      "Epoch 35/50, Train Loss: 0.0030, Val Loss: 0.0071\n",
      "Epoch 36/50, Train Loss: 0.0024, Val Loss: 0.0111\n",
      "Epoch 37/50, Train Loss: 0.0021, Val Loss: 0.0092\n",
      "Epoch 38/50, Train Loss: 0.0020, Val Loss: 0.0114\n",
      "Epoch 39/50, Train Loss: 0.0017, Val Loss: 0.0095\n",
      "Epoch 40/50, Train Loss: 0.0017, Val Loss: 0.0089\n",
      "Epoch 41/50, Train Loss: 0.0015, Val Loss: 0.0112\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.0094\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.0124\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.0108\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.0068\n",
      "Epoch 46/50, Train Loss: 0.0008, Val Loss: 0.0073\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.0088\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.0068\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.0090\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.0091\n",
      "Fold 1 Accuracy: 0.9971\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/50, Train Loss: 0.9019, Val Loss: 0.6047\n",
      "Epoch 2/50, Train Loss: 0.3469, Val Loss: 0.4319\n",
      "Epoch 3/50, Train Loss: 0.1959, Val Loss: 0.3298\n",
      "Epoch 4/50, Train Loss: 0.1312, Val Loss: 0.3397\n",
      "Epoch 5/50, Train Loss: 0.0981, Val Loss: 0.3310\n",
      "Epoch 6/50, Train Loss: 0.0780, Val Loss: 0.3649\n",
      "Epoch 7/50, Train Loss: 0.0654, Val Loss: 0.4117\n",
      "Epoch 8/50, Train Loss: 0.0575, Val Loss: 0.3591\n",
      "Epoch 9/50, Train Loss: 0.0493, Val Loss: 0.3536\n",
      "Epoch 10/50, Train Loss: 0.0438, Val Loss: 0.3954\n",
      "Epoch 11/50, Train Loss: 0.0386, Val Loss: 0.4471\n",
      "Epoch 12/50, Train Loss: 0.0381, Val Loss: 0.3733\n",
      "Epoch 13/50, Train Loss: 0.0330, Val Loss: 0.4098\n",
      "Epoch 14/50, Train Loss: 0.0282, Val Loss: 0.4219\n",
      "Epoch 15/50, Train Loss: 0.0266, Val Loss: 0.4084\n",
      "Epoch 16/50, Train Loss: 0.0241, Val Loss: 0.4368\n",
      "Epoch 17/50, Train Loss: 0.0216, Val Loss: 0.4681\n",
      "Epoch 18/50, Train Loss: 0.0207, Val Loss: 0.4968\n",
      "Epoch 19/50, Train Loss: 0.0185, Val Loss: 0.4183\n",
      "Epoch 20/50, Train Loss: 0.0167, Val Loss: 0.4491\n",
      "Epoch 21/50, Train Loss: 0.0156, Val Loss: 0.5071\n",
      "Epoch 22/50, Train Loss: 0.0150, Val Loss: 0.4431\n",
      "Epoch 23/50, Train Loss: 0.0117, Val Loss: 0.4633\n",
      "Epoch 24/50, Train Loss: 0.0116, Val Loss: 0.4615\n",
      "Epoch 25/50, Train Loss: 0.0097, Val Loss: 0.4702\n",
      "Epoch 26/50, Train Loss: 0.0097, Val Loss: 0.4850\n",
      "Epoch 27/50, Train Loss: 0.0092, Val Loss: 0.4344\n",
      "Epoch 28/50, Train Loss: 0.0076, Val Loss: 0.5116\n",
      "Epoch 29/50, Train Loss: 0.0107, Val Loss: 0.5227\n",
      "Epoch 30/50, Train Loss: 0.0063, Val Loss: 0.5263\n",
      "Epoch 31/50, Train Loss: 0.0078, Val Loss: 0.5650\n",
      "Epoch 32/50, Train Loss: 0.0055, Val Loss: 0.5035\n",
      "Epoch 33/50, Train Loss: 0.0051, Val Loss: 0.4610\n",
      "Epoch 34/50, Train Loss: 0.0044, Val Loss: 0.4882\n",
      "Epoch 35/50, Train Loss: 0.0035, Val Loss: 0.5066\n",
      "Epoch 36/50, Train Loss: 0.0030, Val Loss: 0.5502\n",
      "Epoch 37/50, Train Loss: 0.0030, Val Loss: 0.5951\n",
      "Epoch 38/50, Train Loss: 0.0040, Val Loss: 0.5161\n",
      "Epoch 39/50, Train Loss: 0.0032, Val Loss: 0.5358\n",
      "Epoch 40/50, Train Loss: 0.0024, Val Loss: 0.5307\n",
      "Epoch 41/50, Train Loss: 0.0020, Val Loss: 0.5402\n",
      "Epoch 42/50, Train Loss: 0.0020, Val Loss: 0.5096\n",
      "Epoch 43/50, Train Loss: 0.0016, Val Loss: 0.5495\n",
      "Epoch 44/50, Train Loss: 0.0013, Val Loss: 0.5449\n",
      "Epoch 45/50, Train Loss: 0.0013, Val Loss: 0.5926\n",
      "Epoch 46/50, Train Loss: 0.0011, Val Loss: 0.5228\n",
      "Epoch 47/50, Train Loss: 0.0011, Val Loss: 0.5707\n",
      "Epoch 48/50, Train Loss: 0.0020, Val Loss: 0.5089\n",
      "Epoch 49/50, Train Loss: 0.0014, Val Loss: 0.5478\n",
      "Epoch 50/50, Train Loss: 0.0008, Val Loss: 0.6056\n",
      "Fold 2 Accuracy: 0.8605\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/50, Train Loss: 0.9170, Val Loss: 0.4742\n",
      "Epoch 2/50, Train Loss: 0.3283, Val Loss: 0.1963\n",
      "Epoch 3/50, Train Loss: 0.1765, Val Loss: 0.1112\n",
      "Epoch 4/50, Train Loss: 0.1188, Val Loss: 0.0766\n",
      "Epoch 5/50, Train Loss: 0.0923, Val Loss: 0.0603\n",
      "Epoch 6/50, Train Loss: 0.0733, Val Loss: 0.0409\n",
      "Epoch 7/50, Train Loss: 0.0620, Val Loss: 0.0339\n",
      "Epoch 8/50, Train Loss: 0.0524, Val Loss: 0.0290\n",
      "Epoch 9/50, Train Loss: 0.0458, Val Loss: 0.0278\n",
      "Epoch 10/50, Train Loss: 0.0400, Val Loss: 0.0251\n",
      "Epoch 11/50, Train Loss: 0.0361, Val Loss: 0.0203\n",
      "Epoch 12/50, Train Loss: 0.0311, Val Loss: 0.0206\n",
      "Epoch 13/50, Train Loss: 0.0275, Val Loss: 0.0162\n",
      "Epoch 14/50, Train Loss: 0.0246, Val Loss: 0.0192\n",
      "Epoch 15/50, Train Loss: 0.0228, Val Loss: 0.0202\n",
      "Epoch 16/50, Train Loss: 0.0194, Val Loss: 0.0154\n",
      "Epoch 17/50, Train Loss: 0.0179, Val Loss: 0.0167\n",
      "Epoch 18/50, Train Loss: 0.0171, Val Loss: 0.0135\n",
      "Epoch 19/50, Train Loss: 0.0148, Val Loss: 0.0113\n",
      "Epoch 20/50, Train Loss: 0.0133, Val Loss: 0.0133\n",
      "Epoch 21/50, Train Loss: 0.0110, Val Loss: 0.0127\n",
      "Epoch 22/50, Train Loss: 0.0095, Val Loss: 0.0121\n",
      "Epoch 23/50, Train Loss: 0.0092, Val Loss: 0.0108\n",
      "Epoch 24/50, Train Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch 25/50, Train Loss: 0.0074, Val Loss: 0.0103\n",
      "Epoch 26/50, Train Loss: 0.0064, Val Loss: 0.0096\n",
      "Epoch 27/50, Train Loss: 0.0054, Val Loss: 0.0107\n",
      "Epoch 28/50, Train Loss: 0.0052, Val Loss: 0.0111\n",
      "Epoch 29/50, Train Loss: 0.0048, Val Loss: 0.0105\n",
      "Epoch 30/50, Train Loss: 0.0040, Val Loss: 0.0111\n",
      "Epoch 31/50, Train Loss: 0.0039, Val Loss: 0.0082\n",
      "Epoch 32/50, Train Loss: 0.0032, Val Loss: 0.0096\n",
      "Epoch 33/50, Train Loss: 0.0027, Val Loss: 0.0091\n",
      "Epoch 34/50, Train Loss: 0.0047, Val Loss: 0.0128\n",
      "Epoch 35/50, Train Loss: 0.0035, Val Loss: 0.0118\n",
      "Epoch 36/50, Train Loss: 0.0021, Val Loss: 0.0092\n",
      "Epoch 37/50, Train Loss: 0.0018, Val Loss: 0.0086\n",
      "Epoch 38/50, Train Loss: 0.0018, Val Loss: 0.0085\n",
      "Epoch 39/50, Train Loss: 0.0016, Val Loss: 0.0082\n",
      "Epoch 40/50, Train Loss: 0.0013, Val Loss: 0.0088\n",
      "Epoch 41/50, Train Loss: 0.0012, Val Loss: 0.0077\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.0082\n",
      "Epoch 43/50, Train Loss: 0.0016, Val Loss: 0.0073\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.0075\n",
      "Epoch 45/50, Train Loss: 0.0009, Val Loss: 0.0068\n",
      "Epoch 46/50, Train Loss: 0.0008, Val Loss: 0.0075\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 0.0190\n",
      "Epoch 48/50, Train Loss: 0.0145, Val Loss: 0.0072\n",
      "Epoch 49/50, Train Loss: 0.0102, Val Loss: 0.0115\n",
      "Epoch 50/50, Train Loss: 0.0036, Val Loss: 0.0084\n",
      "Fold 3 Accuracy: 0.9968\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/50, Train Loss: 0.8883, Val Loss: 0.5173\n",
      "Epoch 2/50, Train Loss: 0.3533, Val Loss: 0.2755\n",
      "Epoch 3/50, Train Loss: 0.2019, Val Loss: 0.1752\n",
      "Epoch 4/50, Train Loss: 0.1372, Val Loss: 0.1240\n",
      "Epoch 5/50, Train Loss: 0.1045, Val Loss: 0.1190\n",
      "Epoch 6/50, Train Loss: 0.0848, Val Loss: 0.1095\n",
      "Epoch 7/50, Train Loss: 0.0703, Val Loss: 0.1313\n",
      "Epoch 8/50, Train Loss: 0.0614, Val Loss: 0.1096\n",
      "Epoch 9/50, Train Loss: 0.0536, Val Loss: 0.0800\n",
      "Epoch 10/50, Train Loss: 0.0485, Val Loss: 0.0943\n",
      "Epoch 11/50, Train Loss: 0.0432, Val Loss: 0.1271\n",
      "Epoch 12/50, Train Loss: 0.0381, Val Loss: 0.0851\n",
      "Epoch 13/50, Train Loss: 0.0338, Val Loss: 0.0830\n",
      "Epoch 14/50, Train Loss: 0.0302, Val Loss: 0.1061\n",
      "Epoch 15/50, Train Loss: 0.0273, Val Loss: 0.0867\n",
      "Epoch 16/50, Train Loss: 0.0250, Val Loss: 0.1051\n",
      "Epoch 17/50, Train Loss: 0.0243, Val Loss: 0.0897\n",
      "Epoch 18/50, Train Loss: 0.0206, Val Loss: 0.1049\n",
      "Epoch 19/50, Train Loss: 0.0190, Val Loss: 0.0974\n",
      "Epoch 20/50, Train Loss: 0.0172, Val Loss: 0.1032\n",
      "Epoch 21/50, Train Loss: 0.0159, Val Loss: 0.1259\n",
      "Epoch 22/50, Train Loss: 0.0144, Val Loss: 0.0999\n",
      "Epoch 23/50, Train Loss: 0.0136, Val Loss: 0.1004\n",
      "Epoch 24/50, Train Loss: 0.0121, Val Loss: 0.0860\n",
      "Epoch 25/50, Train Loss: 0.0176, Val Loss: 0.0973\n",
      "Epoch 26/50, Train Loss: 0.0104, Val Loss: 0.0730\n",
      "Epoch 27/50, Train Loss: 0.0088, Val Loss: 0.0646\n",
      "Epoch 28/50, Train Loss: 0.0074, Val Loss: 0.0881\n",
      "Epoch 29/50, Train Loss: 0.0070, Val Loss: 0.0864\n",
      "Epoch 30/50, Train Loss: 0.0065, Val Loss: 0.0742\n",
      "Epoch 31/50, Train Loss: 0.0061, Val Loss: 0.0834\n",
      "Epoch 32/50, Train Loss: 0.0052, Val Loss: 0.0671\n",
      "Epoch 33/50, Train Loss: 0.0046, Val Loss: 0.0770\n",
      "Epoch 34/50, Train Loss: 0.0044, Val Loss: 0.0731\n",
      "Epoch 35/50, Train Loss: 0.0037, Val Loss: 0.0822\n",
      "Epoch 36/50, Train Loss: 0.0036, Val Loss: 0.0607\n",
      "Epoch 37/50, Train Loss: 0.0045, Val Loss: 0.0845\n",
      "Epoch 38/50, Train Loss: 0.0032, Val Loss: 0.0714\n",
      "Epoch 39/50, Train Loss: 0.0023, Val Loss: 0.0640\n",
      "Epoch 40/50, Train Loss: 0.0021, Val Loss: 0.0750\n",
      "Epoch 41/50, Train Loss: 0.0019, Val Loss: 0.0538\n",
      "Epoch 42/50, Train Loss: 0.0026, Val Loss: 0.0534\n",
      "Epoch 43/50, Train Loss: 0.0023, Val Loss: 0.0731\n",
      "Epoch 44/50, Train Loss: 0.0015, Val Loss: 0.0555\n",
      "Epoch 45/50, Train Loss: 0.0022, Val Loss: 0.0789\n",
      "Epoch 46/50, Train Loss: 0.0012, Val Loss: 0.0610\n",
      "Epoch 47/50, Train Loss: 0.0015, Val Loss: 0.0597\n",
      "Epoch 48/50, Train Loss: 0.0013, Val Loss: 0.0732\n",
      "Epoch 49/50, Train Loss: 0.0009, Val Loss: 0.0938\n",
      "Epoch 50/50, Train Loss: 0.0008, Val Loss: 0.0706\n",
      "Fold 4 Accuracy: 0.9719\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/50, Train Loss: 0.9112, Val Loss: 0.4603\n",
      "Epoch 2/50, Train Loss: 0.3355, Val Loss: 0.2209\n",
      "Epoch 3/50, Train Loss: 0.1852, Val Loss: 0.1628\n",
      "Epoch 4/50, Train Loss: 0.1249, Val Loss: 0.1062\n",
      "Epoch 5/50, Train Loss: 0.0943, Val Loss: 0.0824\n",
      "Epoch 6/50, Train Loss: 0.0771, Val Loss: 0.1102\n",
      "Epoch 7/50, Train Loss: 0.0656, Val Loss: 0.0611\n",
      "Epoch 8/50, Train Loss: 0.0573, Val Loss: 0.0787\n",
      "Epoch 9/50, Train Loss: 0.0501, Val Loss: 0.0628\n",
      "Epoch 10/50, Train Loss: 0.0445, Val Loss: 0.0570\n",
      "Epoch 11/50, Train Loss: 0.0386, Val Loss: 0.0455\n",
      "Epoch 12/50, Train Loss: 0.0355, Val Loss: 0.0559\n",
      "Epoch 13/50, Train Loss: 0.0322, Val Loss: 0.0626\n",
      "Epoch 14/50, Train Loss: 0.0279, Val Loss: 0.0477\n",
      "Epoch 15/50, Train Loss: 0.0260, Val Loss: 0.0436\n",
      "Epoch 16/50, Train Loss: 0.0220, Val Loss: 0.0438\n",
      "Epoch 17/50, Train Loss: 0.0193, Val Loss: 0.0396\n",
      "Epoch 18/50, Train Loss: 0.0183, Val Loss: 0.0422\n",
      "Epoch 19/50, Train Loss: 0.0159, Val Loss: 0.0428\n",
      "Epoch 20/50, Train Loss: 0.0143, Val Loss: 0.0512\n",
      "Epoch 21/50, Train Loss: 0.0132, Val Loss: 0.0467\n",
      "Epoch 22/50, Train Loss: 0.0116, Val Loss: 0.0397\n",
      "Epoch 23/50, Train Loss: 0.0096, Val Loss: 0.0400\n",
      "Epoch 24/50, Train Loss: 0.0088, Val Loss: 0.0415\n",
      "Epoch 25/50, Train Loss: 0.0087, Val Loss: 0.0348\n",
      "Epoch 26/50, Train Loss: 0.0075, Val Loss: 0.0494\n",
      "Epoch 27/50, Train Loss: 0.0067, Val Loss: 0.0336\n",
      "Epoch 28/50, Train Loss: 0.0058, Val Loss: 0.0488\n",
      "Epoch 29/50, Train Loss: 0.0051, Val Loss: 0.0372\n",
      "Epoch 30/50, Train Loss: 0.0042, Val Loss: 0.0370\n",
      "Epoch 31/50, Train Loss: 0.0039, Val Loss: 0.0310\n",
      "Epoch 32/50, Train Loss: 0.0034, Val Loss: 0.0380\n",
      "Epoch 33/50, Train Loss: 0.0030, Val Loss: 0.0312\n",
      "Epoch 34/50, Train Loss: 0.0028, Val Loss: 0.0336\n",
      "Epoch 35/50, Train Loss: 0.0026, Val Loss: 0.0333\n",
      "Epoch 36/50, Train Loss: 0.0022, Val Loss: 0.0337\n",
      "Epoch 37/50, Train Loss: 0.0024, Val Loss: 0.0273\n",
      "Epoch 38/50, Train Loss: 0.0023, Val Loss: 0.0263\n",
      "Epoch 39/50, Train Loss: 0.0022, Val Loss: 0.0342\n",
      "Epoch 40/50, Train Loss: 0.0020, Val Loss: 0.0297\n",
      "Epoch 41/50, Train Loss: 0.0065, Val Loss: 0.0106\n",
      "Epoch 42/50, Train Loss: 0.0077, Val Loss: 0.0706\n",
      "Epoch 43/50, Train Loss: 0.0021, Val Loss: 0.0598\n",
      "Epoch 44/50, Train Loss: 0.0013, Val Loss: 0.0539\n",
      "Epoch 45/50, Train Loss: 0.0011, Val Loss: 0.0518\n",
      "Epoch 46/50, Train Loss: 0.0009, Val Loss: 0.0520\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.0523\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.0531\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.0535\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.0533\n",
      "Fold 5 Accuracy: 0.9847\n",
      "\n",
      "===== Fold 6 =====\n",
      "Epoch 1/50, Train Loss: 0.9266, Val Loss: 0.8409\n",
      "Epoch 2/50, Train Loss: 0.3599, Val Loss: 0.7820\n",
      "Epoch 3/50, Train Loss: 0.1942, Val Loss: 0.6890\n",
      "Epoch 4/50, Train Loss: 0.1286, Val Loss: 0.7394\n",
      "Epoch 5/50, Train Loss: 0.0997, Val Loss: 0.8106\n",
      "Epoch 6/50, Train Loss: 0.0797, Val Loss: 0.8656\n",
      "Epoch 7/50, Train Loss: 0.0662, Val Loss: 0.9063\n",
      "Epoch 8/50, Train Loss: 0.0583, Val Loss: 0.8635\n",
      "Epoch 9/50, Train Loss: 0.0500, Val Loss: 0.9143\n",
      "Epoch 10/50, Train Loss: 0.0441, Val Loss: 1.0323\n",
      "Epoch 11/50, Train Loss: 0.0407, Val Loss: 1.0155\n",
      "Epoch 12/50, Train Loss: 0.0350, Val Loss: 1.0411\n",
      "Epoch 13/50, Train Loss: 0.0318, Val Loss: 1.0641\n",
      "Epoch 14/50, Train Loss: 0.0286, Val Loss: 1.0848\n",
      "Epoch 15/50, Train Loss: 0.0256, Val Loss: 1.0980\n",
      "Epoch 16/50, Train Loss: 0.0226, Val Loss: 1.1136\n",
      "Epoch 17/50, Train Loss: 0.0206, Val Loss: 1.1019\n",
      "Epoch 18/50, Train Loss: 0.0185, Val Loss: 1.1548\n",
      "Epoch 19/50, Train Loss: 0.0160, Val Loss: 1.2181\n",
      "Epoch 20/50, Train Loss: 0.0140, Val Loss: 1.1866\n",
      "Epoch 21/50, Train Loss: 0.0136, Val Loss: 1.2308\n",
      "Epoch 22/50, Train Loss: 0.0114, Val Loss: 1.2702\n",
      "Epoch 23/50, Train Loss: 0.0100, Val Loss: 1.2849\n",
      "Epoch 24/50, Train Loss: 0.0104, Val Loss: 1.3132\n",
      "Epoch 25/50, Train Loss: 0.0085, Val Loss: 1.3302\n",
      "Epoch 26/50, Train Loss: 0.0079, Val Loss: 1.3983\n",
      "Epoch 27/50, Train Loss: 0.0066, Val Loss: 1.4178\n",
      "Epoch 28/50, Train Loss: 0.0055, Val Loss: 1.4042\n",
      "Epoch 29/50, Train Loss: 0.0052, Val Loss: 1.4329\n",
      "Epoch 30/50, Train Loss: 0.0052, Val Loss: 1.4194\n",
      "Epoch 31/50, Train Loss: 0.0041, Val Loss: 1.4647\n",
      "Epoch 32/50, Train Loss: 0.0041, Val Loss: 1.4741\n",
      "Epoch 33/50, Train Loss: 0.0034, Val Loss: 1.5059\n",
      "Epoch 34/50, Train Loss: 0.0037, Val Loss: 1.5098\n",
      "Epoch 35/50, Train Loss: 0.0028, Val Loss: 1.5512\n",
      "Epoch 36/50, Train Loss: 0.0025, Val Loss: 1.5862\n",
      "Epoch 37/50, Train Loss: 0.0021, Val Loss: 1.5974\n",
      "Epoch 38/50, Train Loss: 0.0019, Val Loss: 1.5848\n",
      "Epoch 39/50, Train Loss: 0.0017, Val Loss: 1.6056\n",
      "Epoch 40/50, Train Loss: 0.0016, Val Loss: 1.6332\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 1.6657\n",
      "Epoch 42/50, Train Loss: 0.0022, Val Loss: 1.6937\n",
      "Epoch 43/50, Train Loss: 0.0019, Val Loss: 1.6862\n",
      "Epoch 44/50, Train Loss: 0.0013, Val Loss: 1.7245\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 1.7415\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 1.7421\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 1.7406\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 1.8013\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 1.7813\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 1.7898\n",
      "Fold 6 Accuracy: 0.7709\n",
      "\n",
      "===== Fold 7 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.9581, Val Loss: 0.5190\n",
      "Epoch 2/50, Train Loss: 0.3479, Val Loss: 0.2043\n",
      "Epoch 3/50, Train Loss: 0.1895, Val Loss: 0.1083\n",
      "Epoch 4/50, Train Loss: 0.1290, Val Loss: 0.0781\n",
      "Epoch 5/50, Train Loss: 0.0975, Val Loss: 0.0541\n",
      "Epoch 6/50, Train Loss: 0.0771, Val Loss: 0.0415\n",
      "Epoch 7/50, Train Loss: 0.0661, Val Loss: 0.0357\n",
      "Epoch 8/50, Train Loss: 0.0577, Val Loss: 0.0306\n",
      "Epoch 9/50, Train Loss: 0.0489, Val Loss: 0.0236\n",
      "Epoch 10/50, Train Loss: 0.0437, Val Loss: 0.0216\n",
      "Epoch 11/50, Train Loss: 0.0387, Val Loss: 0.0227\n",
      "Epoch 12/50, Train Loss: 0.0336, Val Loss: 0.0196\n",
      "Epoch 13/50, Train Loss: 0.0320, Val Loss: 0.0230\n",
      "Epoch 14/50, Train Loss: 0.0275, Val Loss: 0.0213\n",
      "Epoch 15/50, Train Loss: 0.0249, Val Loss: 0.0158\n",
      "Epoch 16/50, Train Loss: 0.0224, Val Loss: 0.0264\n",
      "Epoch 17/50, Train Loss: 0.0214, Val Loss: 0.0180\n",
      "Epoch 18/50, Train Loss: 0.0206, Val Loss: 0.0216\n",
      "Epoch 19/50, Train Loss: 0.0169, Val Loss: 0.0190\n",
      "Epoch 20/50, Train Loss: 0.0157, Val Loss: 0.0178\n",
      "Epoch 21/50, Train Loss: 0.0154, Val Loss: 0.0224\n",
      "Epoch 22/50, Train Loss: 0.0126, Val Loss: 0.0219\n",
      "Epoch 23/50, Train Loss: 0.0125, Val Loss: 0.0190\n",
      "Epoch 24/50, Train Loss: 0.0101, Val Loss: 0.0198\n",
      "Epoch 25/50, Train Loss: 0.0134, Val Loss: 0.0186\n",
      "Epoch 26/50, Train Loss: 0.0079, Val Loss: 0.0232\n",
      "Epoch 27/50, Train Loss: 0.0077, Val Loss: 0.0241\n",
      "Epoch 28/50, Train Loss: 0.0075, Val Loss: 0.0241\n",
      "Epoch 29/50, Train Loss: 0.0081, Val Loss: 0.0199\n",
      "Epoch 30/50, Train Loss: 0.0052, Val Loss: 0.0227\n",
      "Epoch 31/50, Train Loss: 0.0053, Val Loss: 0.0185\n",
      "Epoch 32/50, Train Loss: 0.0047, Val Loss: 0.0216\n",
      "Epoch 33/50, Train Loss: 0.0036, Val Loss: 0.0214\n",
      "Epoch 34/50, Train Loss: 0.0031, Val Loss: 0.0199\n",
      "Epoch 35/50, Train Loss: 0.0030, Val Loss: 0.0171\n",
      "Epoch 36/50, Train Loss: 0.0026, Val Loss: 0.0207\n",
      "Epoch 37/50, Train Loss: 0.0024, Val Loss: 0.0191\n",
      "Epoch 38/50, Train Loss: 0.0021, Val Loss: 0.0206\n",
      "Epoch 39/50, Train Loss: 0.0061, Val Loss: 0.0252\n",
      "Epoch 40/50, Train Loss: 0.0074, Val Loss: 0.0248\n",
      "Epoch 41/50, Train Loss: 0.0027, Val Loss: 0.0233\n",
      "Epoch 42/50, Train Loss: 0.0021, Val Loss: 0.0226\n",
      "Epoch 43/50, Train Loss: 0.0020, Val Loss: 0.0205\n",
      "Epoch 44/50, Train Loss: 0.0016, Val Loss: 0.0256\n",
      "Epoch 45/50, Train Loss: 0.0014, Val Loss: 0.0256\n",
      "Epoch 46/50, Train Loss: 0.0012, Val Loss: 0.0219\n",
      "Epoch 47/50, Train Loss: 0.0011, Val Loss: 0.0253\n",
      "Epoch 48/50, Train Loss: 0.0010, Val Loss: 0.0250\n",
      "Epoch 49/50, Train Loss: 0.0009, Val Loss: 0.0249\n",
      "Epoch 50/50, Train Loss: 0.0008, Val Loss: 0.0285\n",
      "Fold 7 Accuracy: 0.9939\n",
      "\n",
      "===== Fold 8 =====\n",
      "Epoch 1/50, Train Loss: 0.8728, Val Loss: 0.5308\n",
      "Epoch 2/50, Train Loss: 0.3267, Val Loss: 0.3608\n",
      "Epoch 3/50, Train Loss: 0.1790, Val Loss: 0.3330\n",
      "Epoch 4/50, Train Loss: 0.1199, Val Loss: 0.3054\n",
      "Epoch 5/50, Train Loss: 0.0899, Val Loss: 0.3247\n",
      "Epoch 6/50, Train Loss: 0.0730, Val Loss: 0.3143\n",
      "Epoch 7/50, Train Loss: 0.0608, Val Loss: 0.3126\n",
      "Epoch 8/50, Train Loss: 0.0520, Val Loss: 0.3272\n",
      "Epoch 9/50, Train Loss: 0.0446, Val Loss: 0.3052\n",
      "Epoch 10/50, Train Loss: 0.0381, Val Loss: 0.3785\n",
      "Epoch 11/50, Train Loss: 0.0374, Val Loss: 0.2774\n",
      "Epoch 12/50, Train Loss: 0.0305, Val Loss: 0.3765\n",
      "Epoch 13/50, Train Loss: 0.0287, Val Loss: 0.2823\n",
      "Epoch 14/50, Train Loss: 0.0250, Val Loss: 0.3250\n",
      "Epoch 15/50, Train Loss: 0.0219, Val Loss: 0.3276\n",
      "Epoch 16/50, Train Loss: 0.0215, Val Loss: 0.3699\n",
      "Epoch 17/50, Train Loss: 0.0182, Val Loss: 0.4112\n",
      "Epoch 18/50, Train Loss: 0.0168, Val Loss: 0.3040\n",
      "Epoch 19/50, Train Loss: 0.0168, Val Loss: 0.3078\n",
      "Epoch 20/50, Train Loss: 0.0142, Val Loss: 0.4009\n",
      "Epoch 21/50, Train Loss: 0.0130, Val Loss: 0.3225\n",
      "Epoch 22/50, Train Loss: 0.0122, Val Loss: 0.3668\n",
      "Epoch 23/50, Train Loss: 0.0100, Val Loss: 0.3421\n",
      "Epoch 24/50, Train Loss: 0.0091, Val Loss: 0.3370\n",
      "Epoch 25/50, Train Loss: 0.0085, Val Loss: 0.3651\n",
      "Epoch 26/50, Train Loss: 0.0075, Val Loss: 0.4665\n",
      "Epoch 27/50, Train Loss: 0.0076, Val Loss: 0.4323\n",
      "Epoch 28/50, Train Loss: 0.0084, Val Loss: 0.4268\n",
      "Epoch 29/50, Train Loss: 0.0062, Val Loss: 0.3246\n",
      "Epoch 30/50, Train Loss: 0.0051, Val Loss: 0.3755\n",
      "Epoch 31/50, Train Loss: 0.0045, Val Loss: 0.5236\n",
      "Epoch 32/50, Train Loss: 0.0048, Val Loss: 0.4240\n",
      "Epoch 33/50, Train Loss: 0.0039, Val Loss: 0.3633\n",
      "Epoch 34/50, Train Loss: 0.0035, Val Loss: 0.3521\n",
      "Epoch 35/50, Train Loss: 0.0050, Val Loss: 0.5039\n",
      "Epoch 36/50, Train Loss: 0.0027, Val Loss: 0.3755\n",
      "Epoch 37/50, Train Loss: 0.0026, Val Loss: 0.4965\n",
      "Epoch 38/50, Train Loss: 0.0021, Val Loss: 0.4319\n",
      "Epoch 39/50, Train Loss: 0.0018, Val Loss: 0.4681\n",
      "Epoch 40/50, Train Loss: 0.0017, Val Loss: 0.4309\n",
      "Epoch 41/50, Train Loss: 0.0116, Val Loss: 0.7889\n",
      "Epoch 42/50, Train Loss: 0.0087, Val Loss: 0.4383\n",
      "Epoch 43/50, Train Loss: 0.0017, Val Loss: 0.4005\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.3822\n",
      "Epoch 45/50, Train Loss: 0.0012, Val Loss: 0.5053\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 0.4129\n",
      "Epoch 47/50, Train Loss: 0.0010, Val Loss: 0.4126\n",
      "Epoch 48/50, Train Loss: 0.0009, Val Loss: 0.3727\n",
      "Epoch 49/50, Train Loss: 0.0008, Val Loss: 0.4466\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.4338\n",
      "Fold 8 Accuracy: 0.9044\n",
      "\n",
      "===== Fold 9 =====\n",
      "Epoch 1/50, Train Loss: 0.9692, Val Loss: 0.4898\n",
      "Epoch 2/50, Train Loss: 0.3556, Val Loss: 0.2495\n",
      "Epoch 3/50, Train Loss: 0.1889, Val Loss: 0.1646\n",
      "Epoch 4/50, Train Loss: 0.1245, Val Loss: 0.1458\n",
      "Epoch 5/50, Train Loss: 0.0962, Val Loss: 0.0956\n",
      "Epoch 6/50, Train Loss: 0.0779, Val Loss: 0.0812\n",
      "Epoch 7/50, Train Loss: 0.0646, Val Loss: 0.0811\n",
      "Epoch 8/50, Train Loss: 0.0563, Val Loss: 0.0620\n",
      "Epoch 9/50, Train Loss: 0.0527, Val Loss: 0.0830\n",
      "Epoch 10/50, Train Loss: 0.0440, Val Loss: 0.0884\n",
      "Epoch 11/50, Train Loss: 0.0400, Val Loss: 0.0831\n",
      "Epoch 12/50, Train Loss: 0.0346, Val Loss: 0.0916\n",
      "Epoch 13/50, Train Loss: 0.0319, Val Loss: 0.0630\n",
      "Epoch 14/50, Train Loss: 0.0284, Val Loss: 0.0870\n",
      "Epoch 15/50, Train Loss: 0.0252, Val Loss: 0.0440\n",
      "Epoch 16/50, Train Loss: 0.0254, Val Loss: 0.0774\n",
      "Epoch 17/50, Train Loss: 0.0218, Val Loss: 0.0755\n",
      "Epoch 18/50, Train Loss: 0.0198, Val Loss: 0.0464\n",
      "Epoch 19/50, Train Loss: 0.0174, Val Loss: 0.0616\n",
      "Epoch 20/50, Train Loss: 0.0145, Val Loss: 0.0539\n",
      "Epoch 21/50, Train Loss: 0.0143, Val Loss: 0.0365\n",
      "Epoch 22/50, Train Loss: 0.0116, Val Loss: 0.0511\n",
      "Epoch 23/50, Train Loss: 0.0122, Val Loss: 0.0571\n",
      "Epoch 24/50, Train Loss: 0.0104, Val Loss: 0.0311\n",
      "Epoch 25/50, Train Loss: 0.0091, Val Loss: 0.0372\n",
      "Epoch 26/50, Train Loss: 0.0080, Val Loss: 0.0521\n",
      "Epoch 27/50, Train Loss: 0.0088, Val Loss: 0.0479\n",
      "Epoch 28/50, Train Loss: 0.0079, Val Loss: 0.0510\n",
      "Epoch 29/50, Train Loss: 0.0069, Val Loss: 0.0548\n",
      "Epoch 30/50, Train Loss: 0.0046, Val Loss: 0.0547\n",
      "Epoch 31/50, Train Loss: 0.0040, Val Loss: 0.0535\n",
      "Epoch 32/50, Train Loss: 0.0043, Val Loss: 0.0614\n",
      "Epoch 33/50, Train Loss: 0.0040, Val Loss: 0.0375\n",
      "Epoch 34/50, Train Loss: 0.0033, Val Loss: 0.0528\n",
      "Epoch 35/50, Train Loss: 0.0038, Val Loss: 0.0539\n",
      "Epoch 36/50, Train Loss: 0.0024, Val Loss: 0.0359\n",
      "Epoch 37/50, Train Loss: 0.0022, Val Loss: 0.0358\n",
      "Epoch 38/50, Train Loss: 0.0040, Val Loss: 0.0383\n",
      "Epoch 39/50, Train Loss: 0.0028, Val Loss: 0.0558\n",
      "Epoch 40/50, Train Loss: 0.0021, Val Loss: 0.0468\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 0.0449\n",
      "Epoch 42/50, Train Loss: 0.0013, Val Loss: 0.0538\n",
      "Epoch 43/50, Train Loss: 0.0012, Val Loss: 0.0365\n",
      "Epoch 44/50, Train Loss: 0.0010, Val Loss: 0.0515\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.0429\n",
      "Epoch 46/50, Train Loss: 0.0009, Val Loss: 0.0697\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 0.0371\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 0.0401\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.0399\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.0494\n",
      "Fold 9 Accuracy: 0.9837\n",
      "\n",
      "===== Fold 10 =====\n",
      "Epoch 1/50, Train Loss: 0.9413, Val Loss: 0.6262\n",
      "Epoch 2/50, Train Loss: 0.3651, Val Loss: 0.3624\n",
      "Epoch 3/50, Train Loss: 0.2053, Val Loss: 0.2863\n",
      "Epoch 4/50, Train Loss: 0.1354, Val Loss: 0.2225\n",
      "Epoch 5/50, Train Loss: 0.1007, Val Loss: 0.1608\n",
      "Epoch 6/50, Train Loss: 0.0794, Val Loss: 0.1725\n",
      "Epoch 7/50, Train Loss: 0.0659, Val Loss: 0.1484\n",
      "Epoch 8/50, Train Loss: 0.0567, Val Loss: 0.1448\n",
      "Epoch 9/50, Train Loss: 0.0502, Val Loss: 0.1270\n",
      "Epoch 10/50, Train Loss: 0.0417, Val Loss: 0.1230\n",
      "Epoch 11/50, Train Loss: 0.0367, Val Loss: 0.1310\n",
      "Epoch 12/50, Train Loss: 0.0326, Val Loss: 0.1207\n",
      "Epoch 13/50, Train Loss: 0.0293, Val Loss: 0.1330\n",
      "Epoch 14/50, Train Loss: 0.0266, Val Loss: 0.1278\n",
      "Epoch 15/50, Train Loss: 0.0240, Val Loss: 0.1305\n",
      "Epoch 16/50, Train Loss: 0.0209, Val Loss: 0.1295\n",
      "Epoch 17/50, Train Loss: 0.0190, Val Loss: 0.1211\n",
      "Epoch 18/50, Train Loss: 0.0170, Val Loss: 0.1188\n",
      "Epoch 19/50, Train Loss: 0.0157, Val Loss: 0.1137\n",
      "Epoch 20/50, Train Loss: 0.0136, Val Loss: 0.1286\n",
      "Epoch 21/50, Train Loss: 0.0123, Val Loss: 0.1225\n",
      "Epoch 22/50, Train Loss: 0.0121, Val Loss: 0.1057\n",
      "Epoch 23/50, Train Loss: 0.0106, Val Loss: 0.1196\n",
      "Epoch 24/50, Train Loss: 0.0088, Val Loss: 0.1048\n",
      "Epoch 25/50, Train Loss: 0.0083, Val Loss: 0.1196\n",
      "Epoch 26/50, Train Loss: 0.0075, Val Loss: 0.1038\n",
      "Epoch 27/50, Train Loss: 0.0064, Val Loss: 0.1141\n",
      "Epoch 28/50, Train Loss: 0.0070, Val Loss: 0.1179\n",
      "Epoch 29/50, Train Loss: 0.0047, Val Loss: 0.1065\n",
      "Epoch 30/50, Train Loss: 0.0044, Val Loss: 0.0978\n",
      "Epoch 31/50, Train Loss: 0.0041, Val Loss: 0.1156\n",
      "Epoch 32/50, Train Loss: 0.0040, Val Loss: 0.1087\n",
      "Epoch 33/50, Train Loss: 0.0030, Val Loss: 0.1294\n",
      "Epoch 34/50, Train Loss: 0.0028, Val Loss: 0.1156\n",
      "Epoch 35/50, Train Loss: 0.0025, Val Loss: 0.1125\n",
      "Epoch 36/50, Train Loss: 0.0021, Val Loss: 0.1092\n",
      "Epoch 37/50, Train Loss: 0.0019, Val Loss: 0.1145\n",
      "Epoch 38/50, Train Loss: 0.0017, Val Loss: 0.1100\n",
      "Epoch 39/50, Train Loss: 0.0015, Val Loss: 0.1086\n",
      "Epoch 40/50, Train Loss: 0.0014, Val Loss: 0.1124\n",
      "Epoch 41/50, Train Loss: 0.0012, Val Loss: 0.1066\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.1162\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.1136\n",
      "Epoch 44/50, Train Loss: 0.0010, Val Loss: 0.1086\n",
      "Epoch 45/50, Train Loss: 0.0011, Val Loss: 0.1066\n",
      "Epoch 46/50, Train Loss: 0.0009, Val Loss: 0.1133\n",
      "Epoch 47/50, Train Loss: 0.0007, Val Loss: 0.1162\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 0.1086\n",
      "Epoch 49/50, Train Loss: 0.0006, Val Loss: 0.1181\n",
      "Epoch 50/50, Train Loss: 0.0005, Val Loss: 0.1127\n",
      "Fold 10 Accuracy: 0.9725\n",
      "\n",
      "===== Fold 11 =====\n",
      "Epoch 1/50, Train Loss: 0.9473, Val Loss: 0.7087\n",
      "Epoch 2/50, Train Loss: 0.3830, Val Loss: 0.4216\n",
      "Epoch 3/50, Train Loss: 0.2044, Val Loss: 0.2925\n",
      "Epoch 4/50, Train Loss: 0.1328, Val Loss: 0.2442\n",
      "Epoch 5/50, Train Loss: 0.1005, Val Loss: 0.2361\n",
      "Epoch 6/50, Train Loss: 0.0799, Val Loss: 0.2443\n",
      "Epoch 7/50, Train Loss: 0.0669, Val Loss: 0.2280\n",
      "Epoch 8/50, Train Loss: 0.0565, Val Loss: 0.1909\n",
      "Epoch 9/50, Train Loss: 0.0497, Val Loss: 0.1992\n",
      "Epoch 10/50, Train Loss: 0.0429, Val Loss: 0.1898\n",
      "Epoch 11/50, Train Loss: 0.0384, Val Loss: 0.1896\n",
      "Epoch 12/50, Train Loss: 0.0337, Val Loss: 0.1858\n",
      "Epoch 13/50, Train Loss: 0.0316, Val Loss: 0.1874\n",
      "Epoch 14/50, Train Loss: 0.0285, Val Loss: 0.2074\n",
      "Epoch 15/50, Train Loss: 0.0236, Val Loss: 0.2023\n",
      "Epoch 16/50, Train Loss: 0.0220, Val Loss: 0.2071\n",
      "Epoch 17/50, Train Loss: 0.0192, Val Loss: 0.2064\n",
      "Epoch 18/50, Train Loss: 0.0181, Val Loss: 0.2088\n",
      "Epoch 19/50, Train Loss: 0.0153, Val Loss: 0.1858\n",
      "Epoch 20/50, Train Loss: 0.0155, Val Loss: 0.2125\n",
      "Epoch 21/50, Train Loss: 0.0123, Val Loss: 0.2185\n",
      "Epoch 22/50, Train Loss: 0.0114, Val Loss: 0.1919\n",
      "Epoch 23/50, Train Loss: 0.0097, Val Loss: 0.2257\n",
      "Epoch 24/50, Train Loss: 0.0087, Val Loss: 0.2404\n",
      "Epoch 25/50, Train Loss: 0.0085, Val Loss: 0.2359\n",
      "Epoch 26/50, Train Loss: 0.0081, Val Loss: 0.2229\n",
      "Epoch 27/50, Train Loss: 0.0059, Val Loss: 0.2432\n",
      "Epoch 28/50, Train Loss: 0.0060, Val Loss: 0.2342\n",
      "Epoch 29/50, Train Loss: 0.0053, Val Loss: 0.2224\n",
      "Epoch 30/50, Train Loss: 0.0050, Val Loss: 0.2635\n",
      "Epoch 31/50, Train Loss: 0.0044, Val Loss: 0.2408\n",
      "Epoch 32/50, Train Loss: 0.0035, Val Loss: 0.2285\n",
      "Epoch 33/50, Train Loss: 0.0065, Val Loss: 0.2568\n",
      "Epoch 34/50, Train Loss: 0.0032, Val Loss: 0.2616\n",
      "Epoch 35/50, Train Loss: 0.0025, Val Loss: 0.2496\n",
      "Epoch 36/50, Train Loss: 0.0029, Val Loss: 0.2466\n",
      "Epoch 37/50, Train Loss: 0.0021, Val Loss: 0.2248\n",
      "Epoch 38/50, Train Loss: 0.0020, Val Loss: 0.2595\n",
      "Epoch 39/50, Train Loss: 0.0017, Val Loss: 0.2774\n",
      "Epoch 40/50, Train Loss: 0.0016, Val Loss: 0.2704\n",
      "Epoch 41/50, Train Loss: 0.0015, Val Loss: 0.2639\n",
      "Epoch 42/50, Train Loss: 0.0013, Val Loss: 0.2713\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.2449\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.2727\n",
      "Epoch 45/50, Train Loss: 0.0009, Val Loss: 0.2658\n",
      "Epoch 46/50, Train Loss: 0.0009, Val Loss: 0.2553\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 0.2771\n",
      "Epoch 48/50, Train Loss: 0.0044, Val Loss: 0.2292\n",
      "Epoch 49/50, Train Loss: 0.0160, Val Loss: 0.3766\n",
      "Epoch 50/50, Train Loss: 0.0068, Val Loss: 0.1868\n",
      "Fold 11 Accuracy: 0.9361\n",
      "\n",
      "===== Fold 12 =====\n",
      "Epoch 1/50, Train Loss: 0.9246, Val Loss: 0.4878\n",
      "Epoch 2/50, Train Loss: 0.3415, Val Loss: 0.2515\n",
      "Epoch 3/50, Train Loss: 0.1865, Val Loss: 0.1463\n",
      "Epoch 4/50, Train Loss: 0.1232, Val Loss: 0.1031\n",
      "Epoch 5/50, Train Loss: 0.0927, Val Loss: 0.0827\n",
      "Epoch 6/50, Train Loss: 0.0748, Val Loss: 0.0736\n",
      "Epoch 7/50, Train Loss: 0.0626, Val Loss: 0.0583\n",
      "Epoch 8/50, Train Loss: 0.0545, Val Loss: 0.0649\n",
      "Epoch 9/50, Train Loss: 0.0477, Val Loss: 0.0618\n",
      "Epoch 10/50, Train Loss: 0.0408, Val Loss: 0.0403\n",
      "Epoch 11/50, Train Loss: 0.0393, Val Loss: 0.0361\n",
      "Epoch 12/50, Train Loss: 0.0316, Val Loss: 0.0341\n",
      "Epoch 13/50, Train Loss: 0.0303, Val Loss: 0.0362\n",
      "Epoch 14/50, Train Loss: 0.0247, Val Loss: 0.0477\n",
      "Epoch 15/50, Train Loss: 0.0229, Val Loss: 0.0578\n",
      "Epoch 16/50, Train Loss: 0.0202, Val Loss: 0.0446\n",
      "Epoch 17/50, Train Loss: 0.0189, Val Loss: 0.0479\n",
      "Epoch 18/50, Train Loss: 0.0157, Val Loss: 0.0366\n",
      "Epoch 19/50, Train Loss: 0.0148, Val Loss: 0.0400\n",
      "Epoch 20/50, Train Loss: 0.0128, Val Loss: 0.0701\n",
      "Epoch 21/50, Train Loss: 0.0113, Val Loss: 0.0439\n",
      "Epoch 22/50, Train Loss: 0.0099, Val Loss: 0.0477\n",
      "Epoch 23/50, Train Loss: 0.0089, Val Loss: 0.0537\n",
      "Epoch 24/50, Train Loss: 0.0078, Val Loss: 0.0493\n",
      "Epoch 25/50, Train Loss: 0.0066, Val Loss: 0.0447\n",
      "Epoch 26/50, Train Loss: 0.0062, Val Loss: 0.0399\n",
      "Epoch 27/50, Train Loss: 0.0065, Val Loss: 0.0625\n",
      "Epoch 28/50, Train Loss: 0.0050, Val Loss: 0.0560\n",
      "Epoch 29/50, Train Loss: 0.0044, Val Loss: 0.0312\n",
      "Epoch 30/50, Train Loss: 0.0038, Val Loss: 0.0458\n",
      "Epoch 31/50, Train Loss: 0.0031, Val Loss: 0.0437\n",
      "Epoch 32/50, Train Loss: 0.0038, Val Loss: 0.0578\n",
      "Epoch 33/50, Train Loss: 0.0026, Val Loss: 0.0653\n",
      "Epoch 34/50, Train Loss: 0.0023, Val Loss: 0.0580\n",
      "Epoch 35/50, Train Loss: 0.0020, Val Loss: 0.0564\n",
      "Epoch 36/50, Train Loss: 0.0019, Val Loss: 0.0580\n",
      "Epoch 37/50, Train Loss: 0.0020, Val Loss: 0.0366\n",
      "Epoch 38/50, Train Loss: 0.0015, Val Loss: 0.0651\n",
      "Epoch 39/50, Train Loss: 0.0014, Val Loss: 0.0685\n",
      "Epoch 40/50, Train Loss: 0.0012, Val Loss: 0.0908\n",
      "Epoch 41/50, Train Loss: 0.0011, Val Loss: 0.0372\n",
      "Epoch 42/50, Train Loss: 0.0017, Val Loss: 0.0892\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.0750\n",
      "Epoch 44/50, Train Loss: 0.0007, Val Loss: 0.1053\n",
      "Epoch 45/50, Train Loss: 0.0007, Val Loss: 0.0831\n",
      "Epoch 46/50, Train Loss: 0.0006, Val Loss: 0.1029\n",
      "Epoch 47/50, Train Loss: 0.0006, Val Loss: 0.0910\n",
      "Epoch 48/50, Train Loss: 0.0005, Val Loss: 0.1095\n",
      "Epoch 49/50, Train Loss: 0.0005, Val Loss: 0.0969\n",
      "Epoch 50/50, Train Loss: 0.0004, Val Loss: 0.0961\n",
      "Fold 12 Accuracy: 0.9768\n",
      "\n",
      "===== Fold 13 =====\n",
      "Epoch 1/50, Train Loss: 0.9353, Val Loss: 0.6184\n",
      "Epoch 2/50, Train Loss: 0.3487, Val Loss: 0.3052\n",
      "Epoch 3/50, Train Loss: 0.1922, Val Loss: 0.2842\n",
      "Epoch 4/50, Train Loss: 0.1301, Val Loss: 0.2492\n",
      "Epoch 5/50, Train Loss: 0.0986, Val Loss: 0.2550\n",
      "Epoch 6/50, Train Loss: 0.0807, Val Loss: 0.2250\n",
      "Epoch 7/50, Train Loss: 0.0705, Val Loss: 0.2221\n",
      "Epoch 8/50, Train Loss: 0.0623, Val Loss: 0.2369\n",
      "Epoch 9/50, Train Loss: 0.0523, Val Loss: 0.2032\n",
      "Epoch 10/50, Train Loss: 0.0468, Val Loss: 0.2882\n",
      "Epoch 11/50, Train Loss: 0.0431, Val Loss: 0.2130\n",
      "Epoch 12/50, Train Loss: 0.0387, Val Loss: 0.2193\n",
      "Epoch 13/50, Train Loss: 0.0342, Val Loss: 0.1890\n",
      "Epoch 14/50, Train Loss: 0.0318, Val Loss: 0.1892\n",
      "Epoch 15/50, Train Loss: 0.0293, Val Loss: 0.2006\n",
      "Epoch 16/50, Train Loss: 0.0265, Val Loss: 0.1840\n",
      "Epoch 17/50, Train Loss: 0.0252, Val Loss: 0.1774\n",
      "Epoch 18/50, Train Loss: 0.0225, Val Loss: 0.1995\n",
      "Epoch 19/50, Train Loss: 0.0204, Val Loss: 0.1894\n",
      "Epoch 20/50, Train Loss: 0.0191, Val Loss: 0.1631\n",
      "Epoch 21/50, Train Loss: 0.0173, Val Loss: 0.1491\n",
      "Epoch 22/50, Train Loss: 0.0148, Val Loss: 0.1866\n",
      "Epoch 23/50, Train Loss: 0.0133, Val Loss: 0.1677\n",
      "Epoch 24/50, Train Loss: 0.0125, Val Loss: 0.1636\n",
      "Epoch 25/50, Train Loss: 0.0113, Val Loss: 0.1642\n",
      "Epoch 26/50, Train Loss: 0.0110, Val Loss: 0.1817\n",
      "Epoch 27/50, Train Loss: 0.0101, Val Loss: 0.1759\n",
      "Epoch 28/50, Train Loss: 0.0087, Val Loss: 0.1347\n",
      "Epoch 29/50, Train Loss: 0.0075, Val Loss: 0.1849\n",
      "Epoch 30/50, Train Loss: 0.0077, Val Loss: 0.1285\n",
      "Epoch 31/50, Train Loss: 0.0071, Val Loss: 0.1435\n",
      "Epoch 32/50, Train Loss: 0.0064, Val Loss: 0.1876\n",
      "Epoch 33/50, Train Loss: 0.0052, Val Loss: 0.2073\n",
      "Epoch 34/50, Train Loss: 0.0045, Val Loss: 0.1704\n",
      "Epoch 35/50, Train Loss: 0.0040, Val Loss: 0.1733\n",
      "Epoch 36/50, Train Loss: 0.0048, Val Loss: 0.1430\n",
      "Epoch 37/50, Train Loss: 0.0033, Val Loss: 0.1629\n",
      "Epoch 38/50, Train Loss: 0.0032, Val Loss: 0.1373\n",
      "Epoch 39/50, Train Loss: 0.0024, Val Loss: 0.1489\n",
      "Epoch 40/50, Train Loss: 0.0024, Val Loss: 0.1721\n",
      "Epoch 41/50, Train Loss: 0.0020, Val Loss: 0.1783\n",
      "Epoch 42/50, Train Loss: 0.0019, Val Loss: 0.1551\n",
      "Epoch 43/50, Train Loss: 0.0020, Val Loss: 0.1739\n",
      "Epoch 44/50, Train Loss: 0.0016, Val Loss: 0.1425\n",
      "Epoch 45/50, Train Loss: 0.0015, Val Loss: 0.1529\n",
      "Epoch 46/50, Train Loss: 0.0014, Val Loss: 0.1565\n",
      "Epoch 47/50, Train Loss: 0.0011, Val Loss: 0.1415\n",
      "Epoch 48/50, Train Loss: 0.0019, Val Loss: 0.1384\n",
      "Epoch 49/50, Train Loss: 0.0011, Val Loss: 0.1498\n",
      "Epoch 50/50, Train Loss: 0.0010, Val Loss: 0.1315\n",
      "Fold 13 Accuracy: 0.9492\n",
      "\n",
      "===== Fold 14 =====\n",
      "Epoch 1/50, Train Loss: 0.9556, Val Loss: 0.5014\n",
      "Epoch 2/50, Train Loss: 0.3669, Val Loss: 0.2752\n",
      "Epoch 3/50, Train Loss: 0.1954, Val Loss: 0.2031\n",
      "Epoch 4/50, Train Loss: 0.1296, Val Loss: 0.1539\n",
      "Epoch 5/50, Train Loss: 0.0980, Val Loss: 0.1804\n",
      "Epoch 6/50, Train Loss: 0.0774, Val Loss: 0.1551\n",
      "Epoch 7/50, Train Loss: 0.0641, Val Loss: 0.1514\n",
      "Epoch 8/50, Train Loss: 0.0549, Val Loss: 0.1346\n",
      "Epoch 9/50, Train Loss: 0.0521, Val Loss: 0.2026\n",
      "Epoch 10/50, Train Loss: 0.0417, Val Loss: 0.1329\n",
      "Epoch 11/50, Train Loss: 0.0388, Val Loss: 0.1547\n",
      "Epoch 12/50, Train Loss: 0.0334, Val Loss: 0.1577\n",
      "Epoch 13/50, Train Loss: 0.0299, Val Loss: 0.1298\n",
      "Epoch 14/50, Train Loss: 0.0263, Val Loss: 0.1241\n",
      "Epoch 15/50, Train Loss: 0.0237, Val Loss: 0.1545\n",
      "Epoch 16/50, Train Loss: 0.0211, Val Loss: 0.1130\n",
      "Epoch 17/50, Train Loss: 0.0188, Val Loss: 0.2009\n",
      "Epoch 18/50, Train Loss: 0.0166, Val Loss: 0.1746\n",
      "Epoch 19/50, Train Loss: 0.0160, Val Loss: 0.1440\n",
      "Epoch 20/50, Train Loss: 0.0131, Val Loss: 0.0916\n",
      "Epoch 21/50, Train Loss: 0.0115, Val Loss: 0.1346\n",
      "Epoch 22/50, Train Loss: 0.0099, Val Loss: 0.1609\n",
      "Epoch 23/50, Train Loss: 0.0088, Val Loss: 0.1725\n",
      "Epoch 24/50, Train Loss: 0.0076, Val Loss: 0.1177\n",
      "Epoch 25/50, Train Loss: 0.0067, Val Loss: 0.1189\n",
      "Epoch 26/50, Train Loss: 0.0068, Val Loss: 0.1509\n",
      "Epoch 27/50, Train Loss: 0.0050, Val Loss: 0.1456\n",
      "Epoch 28/50, Train Loss: 0.0048, Val Loss: 0.1895\n",
      "Epoch 29/50, Train Loss: 0.0039, Val Loss: 0.1359\n",
      "Epoch 30/50, Train Loss: 0.0034, Val Loss: 0.1461\n",
      "Epoch 31/50, Train Loss: 0.0031, Val Loss: 0.1459\n",
      "Epoch 32/50, Train Loss: 0.0029, Val Loss: 0.1459\n",
      "Epoch 33/50, Train Loss: 0.0025, Val Loss: 0.1646\n",
      "Epoch 34/50, Train Loss: 0.0022, Val Loss: 0.0972\n",
      "Epoch 35/50, Train Loss: 0.0020, Val Loss: 0.1613\n",
      "Epoch 36/50, Train Loss: 0.0018, Val Loss: 0.1888\n",
      "Epoch 37/50, Train Loss: 0.0070, Val Loss: 0.0591\n",
      "Epoch 38/50, Train Loss: 0.0105, Val Loss: 0.1100\n",
      "Epoch 39/50, Train Loss: 0.0080, Val Loss: 0.1604\n",
      "Epoch 40/50, Train Loss: 0.0025, Val Loss: 0.1833\n",
      "Epoch 41/50, Train Loss: 0.0017, Val Loss: 0.1646\n",
      "Epoch 42/50, Train Loss: 0.0013, Val Loss: 0.1453\n",
      "Epoch 43/50, Train Loss: 0.0012, Val Loss: 0.1453\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.1796\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.1539\n",
      "Epoch 46/50, Train Loss: 0.0009, Val Loss: 0.1509\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.1527\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 0.1639\n",
      "Epoch 49/50, Train Loss: 0.0006, Val Loss: 0.1820\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.1755\n",
      "Fold 14 Accuracy: 0.9608\n",
      "\n",
      "===== Fold 15 =====\n",
      "Epoch 1/50, Train Loss: 0.9084, Val Loss: 0.4578\n",
      "Epoch 2/50, Train Loss: 0.3160, Val Loss: 0.2121\n",
      "Epoch 3/50, Train Loss: 0.1790, Val Loss: 0.1487\n",
      "Epoch 4/50, Train Loss: 0.1197, Val Loss: 0.1063\n",
      "Epoch 5/50, Train Loss: 0.0923, Val Loss: 0.1063\n",
      "Epoch 6/50, Train Loss: 0.0750, Val Loss: 0.0848\n",
      "Epoch 7/50, Train Loss: 0.0620, Val Loss: 0.0705\n",
      "Epoch 8/50, Train Loss: 0.0534, Val Loss: 0.0603\n",
      "Epoch 9/50, Train Loss: 0.0481, Val Loss: 0.0710\n",
      "Epoch 10/50, Train Loss: 0.0416, Val Loss: 0.0445\n",
      "Epoch 11/50, Train Loss: 0.0364, Val Loss: 0.0447\n",
      "Epoch 12/50, Train Loss: 0.0337, Val Loss: 0.0468\n",
      "Epoch 13/50, Train Loss: 0.0317, Val Loss: 0.0407\n",
      "Epoch 14/50, Train Loss: 0.0275, Val Loss: 0.0424\n",
      "Epoch 15/50, Train Loss: 0.0258, Val Loss: 0.0422\n",
      "Epoch 16/50, Train Loss: 0.0230, Val Loss: 0.0611\n",
      "Epoch 17/50, Train Loss: 0.0214, Val Loss: 0.0246\n",
      "Epoch 18/50, Train Loss: 0.0198, Val Loss: 0.0392\n",
      "Epoch 19/50, Train Loss: 0.0176, Val Loss: 0.0300\n",
      "Epoch 20/50, Train Loss: 0.0150, Val Loss: 0.0314\n",
      "Epoch 21/50, Train Loss: 0.0127, Val Loss: 0.0390\n",
      "Epoch 22/50, Train Loss: 0.0115, Val Loss: 0.0280\n",
      "Epoch 23/50, Train Loss: 0.0113, Val Loss: 0.0346\n",
      "Epoch 24/50, Train Loss: 0.0101, Val Loss: 0.0321\n",
      "Epoch 25/50, Train Loss: 0.0085, Val Loss: 0.0315\n",
      "Epoch 26/50, Train Loss: 0.0081, Val Loss: 0.0286\n",
      "Epoch 27/50, Train Loss: 0.0126, Val Loss: 0.0288\n",
      "Epoch 28/50, Train Loss: 0.0065, Val Loss: 0.0305\n",
      "Epoch 29/50, Train Loss: 0.0057, Val Loss: 0.0245\n",
      "Epoch 30/50, Train Loss: 0.0064, Val Loss: 0.0355\n",
      "Epoch 31/50, Train Loss: 0.0052, Val Loss: 0.0418\n",
      "Epoch 32/50, Train Loss: 0.0044, Val Loss: 0.0296\n",
      "Epoch 33/50, Train Loss: 0.0051, Val Loss: 0.0325\n",
      "Epoch 34/50, Train Loss: 0.0032, Val Loss: 0.0242\n",
      "Epoch 35/50, Train Loss: 0.0031, Val Loss: 0.0250\n",
      "Epoch 36/50, Train Loss: 0.0026, Val Loss: 0.0238\n",
      "Epoch 37/50, Train Loss: 0.0022, Val Loss: 0.0261\n",
      "Epoch 38/50, Train Loss: 0.0019, Val Loss: 0.0254\n",
      "Epoch 39/50, Train Loss: 0.0019, Val Loss: 0.0256\n",
      "Epoch 40/50, Train Loss: 0.0017, Val Loss: 0.0286\n",
      "Epoch 41/50, Train Loss: 0.0014, Val Loss: 0.0225\n",
      "Epoch 42/50, Train Loss: 0.0013, Val Loss: 0.0256\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.0315\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.0241\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.0225\n",
      "Epoch 46/50, Train Loss: 0.0043, Val Loss: 0.2012\n",
      "Epoch 47/50, Train Loss: 0.0201, Val Loss: 0.1296\n",
      "Epoch 48/50, Train Loss: 0.0124, Val Loss: 0.0580\n",
      "Epoch 49/50, Train Loss: 0.0030, Val Loss: 0.0557\n",
      "Epoch 50/50, Train Loss: 0.0018, Val Loss: 0.0389\n",
      "Fold 15 Accuracy: 0.9875\n",
      "\n",
      "===== Fold 16 =====\n",
      "Epoch 1/50, Train Loss: 1.0104, Val Loss: 0.5633\n",
      "Epoch 2/50, Train Loss: 0.4028, Val Loss: 0.2726\n",
      "Epoch 3/50, Train Loss: 0.2120, Val Loss: 0.1613\n",
      "Epoch 4/50, Train Loss: 0.1402, Val Loss: 0.1290\n",
      "Epoch 5/50, Train Loss: 0.1059, Val Loss: 0.1027\n",
      "Epoch 6/50, Train Loss: 0.0820, Val Loss: 0.0869\n",
      "Epoch 7/50, Train Loss: 0.0705, Val Loss: 0.0772\n",
      "Epoch 8/50, Train Loss: 0.0587, Val Loss: 0.0812\n",
      "Epoch 9/50, Train Loss: 0.0519, Val Loss: 0.0737\n",
      "Epoch 10/50, Train Loss: 0.0453, Val Loss: 0.0662\n",
      "Epoch 11/50, Train Loss: 0.0407, Val Loss: 0.0738\n",
      "Epoch 12/50, Train Loss: 0.0354, Val Loss: 0.0637\n",
      "Epoch 13/50, Train Loss: 0.0330, Val Loss: 0.0593\n",
      "Epoch 14/50, Train Loss: 0.0290, Val Loss: 0.0723\n",
      "Epoch 15/50, Train Loss: 0.0259, Val Loss: 0.0538\n",
      "Epoch 16/50, Train Loss: 0.0223, Val Loss: 0.0550\n",
      "Epoch 17/50, Train Loss: 0.0200, Val Loss: 0.0591\n",
      "Epoch 18/50, Train Loss: 0.0172, Val Loss: 0.0486\n",
      "Epoch 19/50, Train Loss: 0.0161, Val Loss: 0.0484\n",
      "Epoch 20/50, Train Loss: 0.0139, Val Loss: 0.0573\n",
      "Epoch 21/50, Train Loss: 0.0132, Val Loss: 0.0417\n",
      "Epoch 22/50, Train Loss: 0.0108, Val Loss: 0.0435\n",
      "Epoch 23/50, Train Loss: 0.0105, Val Loss: 0.0442\n",
      "Epoch 24/50, Train Loss: 0.0094, Val Loss: 0.0520\n",
      "Epoch 25/50, Train Loss: 0.0090, Val Loss: 0.0517\n",
      "Epoch 26/50, Train Loss: 0.0070, Val Loss: 0.0517\n",
      "Epoch 27/50, Train Loss: 0.0059, Val Loss: 0.0489\n",
      "Epoch 28/50, Train Loss: 0.0062, Val Loss: 0.0543\n",
      "Epoch 29/50, Train Loss: 0.0046, Val Loss: 0.0490\n",
      "Epoch 30/50, Train Loss: 0.0040, Val Loss: 0.0440\n",
      "Epoch 31/50, Train Loss: 0.0034, Val Loss: 0.0477\n",
      "Epoch 32/50, Train Loss: 0.0035, Val Loss: 0.0401\n",
      "Epoch 33/50, Train Loss: 0.0030, Val Loss: 0.0480\n",
      "Epoch 34/50, Train Loss: 0.0029, Val Loss: 0.0512\n",
      "Epoch 35/50, Train Loss: 0.0024, Val Loss: 0.0437\n",
      "Epoch 36/50, Train Loss: 0.0020, Val Loss: 0.0457\n",
      "Epoch 37/50, Train Loss: 0.0037, Val Loss: 0.0708\n",
      "Epoch 38/50, Train Loss: 0.0128, Val Loss: 0.0528\n",
      "Epoch 39/50, Train Loss: 0.0065, Val Loss: 0.0397\n",
      "Epoch 40/50, Train Loss: 0.0023, Val Loss: 0.0327\n",
      "Epoch 41/50, Train Loss: 0.0018, Val Loss: 0.0288\n",
      "Epoch 42/50, Train Loss: 0.0016, Val Loss: 0.0313\n",
      "Epoch 43/50, Train Loss: 0.0014, Val Loss: 0.0333\n",
      "Epoch 44/50, Train Loss: 0.0013, Val Loss: 0.0320\n",
      "Epoch 45/50, Train Loss: 0.0011, Val Loss: 0.0310\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 0.0310\n",
      "Epoch 47/50, Train Loss: 0.0010, Val Loss: 0.0276\n",
      "Epoch 48/50, Train Loss: 0.0010, Val Loss: 0.0353\n",
      "Epoch 49/50, Train Loss: 0.0008, Val Loss: 0.0476\n",
      "Epoch 50/50, Train Loss: 0.0126, Val Loss: 0.0570\n",
      "Fold 16 Accuracy: 0.9758\n",
      "\n",
      "===== Fold 17 =====\n",
      "Epoch 1/50, Train Loss: 0.9274, Val Loss: 0.5211\n",
      "Epoch 2/50, Train Loss: 0.3409, Val Loss: 0.2808\n",
      "Epoch 3/50, Train Loss: 0.1798, Val Loss: 0.1771\n",
      "Epoch 4/50, Train Loss: 0.1222, Val Loss: 0.1507\n",
      "Epoch 5/50, Train Loss: 0.0924, Val Loss: 0.0970\n",
      "Epoch 6/50, Train Loss: 0.0740, Val Loss: 0.1040\n",
      "Epoch 7/50, Train Loss: 0.0636, Val Loss: 0.0701\n",
      "Epoch 8/50, Train Loss: 0.0554, Val Loss: 0.0658\n",
      "Epoch 9/50, Train Loss: 0.0470, Val Loss: 0.0648\n",
      "Epoch 10/50, Train Loss: 0.0471, Val Loss: 0.0609\n",
      "Epoch 11/50, Train Loss: 0.0389, Val Loss: 0.0565\n",
      "Epoch 12/50, Train Loss: 0.0352, Val Loss: 0.0423\n",
      "Epoch 13/50, Train Loss: 0.0307, Val Loss: 0.0502\n",
      "Epoch 14/50, Train Loss: 0.0286, Val Loss: 0.0362\n",
      "Epoch 15/50, Train Loss: 0.0268, Val Loss: 0.0340\n",
      "Epoch 16/50, Train Loss: 0.0234, Val Loss: 0.0406\n",
      "Epoch 17/50, Train Loss: 0.0206, Val Loss: 0.0344\n",
      "Epoch 18/50, Train Loss: 0.0180, Val Loss: 0.0308\n",
      "Epoch 19/50, Train Loss: 0.0186, Val Loss: 0.0363\n",
      "Epoch 20/50, Train Loss: 0.0155, Val Loss: 0.0296\n",
      "Epoch 21/50, Train Loss: 0.0143, Val Loss: 0.0284\n",
      "Epoch 22/50, Train Loss: 0.0122, Val Loss: 0.0266\n",
      "Epoch 23/50, Train Loss: 0.0111, Val Loss: 0.0312\n",
      "Epoch 24/50, Train Loss: 0.0101, Val Loss: 0.0288\n",
      "Epoch 25/50, Train Loss: 0.0088, Val Loss: 0.0300\n",
      "Epoch 26/50, Train Loss: 0.0078, Val Loss: 0.0318\n",
      "Epoch 27/50, Train Loss: 0.0074, Val Loss: 0.0253\n",
      "Epoch 28/50, Train Loss: 0.0063, Val Loss: 0.0361\n",
      "Epoch 29/50, Train Loss: 0.0061, Val Loss: 0.0249\n",
      "Epoch 30/50, Train Loss: 0.0049, Val Loss: 0.0287\n",
      "Epoch 31/50, Train Loss: 0.0046, Val Loss: 0.0280\n",
      "Epoch 32/50, Train Loss: 0.0058, Val Loss: 0.0285\n",
      "Epoch 33/50, Train Loss: 0.0042, Val Loss: 0.0263\n",
      "Epoch 34/50, Train Loss: 0.0033, Val Loss: 0.0278\n",
      "Epoch 35/50, Train Loss: 0.0029, Val Loss: 0.0293\n",
      "Epoch 36/50, Train Loss: 0.0029, Val Loss: 0.0302\n",
      "Epoch 37/50, Train Loss: 0.0042, Val Loss: 0.0421\n",
      "Epoch 38/50, Train Loss: 0.0066, Val Loss: 0.0366\n",
      "Epoch 39/50, Train Loss: 0.0057, Val Loss: 0.0378\n",
      "Epoch 40/50, Train Loss: 0.0031, Val Loss: 0.0284\n",
      "Epoch 41/50, Train Loss: 0.0017, Val Loss: 0.0241\n",
      "Epoch 42/50, Train Loss: 0.0016, Val Loss: 0.0275\n",
      "Epoch 43/50, Train Loss: 0.0015, Val Loss: 0.0253\n",
      "Epoch 44/50, Train Loss: 0.0013, Val Loss: 0.0279\n",
      "Epoch 45/50, Train Loss: 0.0013, Val Loss: 0.0271\n",
      "Epoch 46/50, Train Loss: 0.0011, Val Loss: 0.0298\n",
      "Epoch 47/50, Train Loss: 0.0010, Val Loss: 0.0261\n",
      "Epoch 48/50, Train Loss: 0.0012, Val Loss: 0.0277\n",
      "Epoch 49/50, Train Loss: 0.0008, Val Loss: 0.0278\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.0309\n",
      "Fold 17 Accuracy: 0.9895\n",
      "\n",
      "===== Fold 18 =====\n",
      "Epoch 1/50, Train Loss: 0.9146, Val Loss: 0.7116\n",
      "Epoch 2/50, Train Loss: 0.3421, Val Loss: 0.4364\n",
      "Epoch 3/50, Train Loss: 0.1872, Val Loss: 0.2960\n",
      "Epoch 4/50, Train Loss: 0.1280, Val Loss: 0.2548\n",
      "Epoch 5/50, Train Loss: 0.1005, Val Loss: 0.2265\n",
      "Epoch 6/50, Train Loss: 0.0807, Val Loss: 0.2250\n",
      "Epoch 7/50, Train Loss: 0.0666, Val Loss: 0.2082\n",
      "Epoch 8/50, Train Loss: 0.0597, Val Loss: 0.1697\n",
      "Epoch 9/50, Train Loss: 0.0573, Val Loss: 0.1578\n",
      "Epoch 10/50, Train Loss: 0.0464, Val Loss: 0.1793\n",
      "Epoch 11/50, Train Loss: 0.0421, Val Loss: 0.1702\n",
      "Epoch 12/50, Train Loss: 0.0386, Val Loss: 0.1989\n",
      "Epoch 13/50, Train Loss: 0.0351, Val Loss: 0.1536\n",
      "Epoch 14/50, Train Loss: 0.0323, Val Loss: 0.1612\n",
      "Epoch 15/50, Train Loss: 0.0301, Val Loss: 0.1773\n",
      "Epoch 16/50, Train Loss: 0.0272, Val Loss: 0.1845\n",
      "Epoch 17/50, Train Loss: 0.0257, Val Loss: 0.1622\n",
      "Epoch 18/50, Train Loss: 0.0212, Val Loss: 0.2338\n",
      "Epoch 19/50, Train Loss: 0.0205, Val Loss: 0.1770\n",
      "Epoch 20/50, Train Loss: 0.0176, Val Loss: 0.1830\n",
      "Epoch 21/50, Train Loss: 0.0160, Val Loss: 0.2009\n",
      "Epoch 22/50, Train Loss: 0.0142, Val Loss: 0.1931\n",
      "Epoch 23/50, Train Loss: 0.0126, Val Loss: 0.1917\n",
      "Epoch 24/50, Train Loss: 0.0119, Val Loss: 0.1824\n",
      "Epoch 25/50, Train Loss: 0.0108, Val Loss: 0.1633\n",
      "Epoch 26/50, Train Loss: 0.0096, Val Loss: 0.1807\n",
      "Epoch 27/50, Train Loss: 0.0109, Val Loss: 0.1752\n",
      "Epoch 28/50, Train Loss: 0.0075, Val Loss: 0.1588\n",
      "Epoch 29/50, Train Loss: 0.0063, Val Loss: 0.1977\n",
      "Epoch 30/50, Train Loss: 0.0061, Val Loss: 0.1801\n",
      "Epoch 31/50, Train Loss: 0.0051, Val Loss: 0.1787\n",
      "Epoch 32/50, Train Loss: 0.0043, Val Loss: 0.1672\n",
      "Epoch 33/50, Train Loss: 0.0039, Val Loss: 0.1652\n",
      "Epoch 34/50, Train Loss: 0.0040, Val Loss: 0.1567\n",
      "Epoch 35/50, Train Loss: 0.0032, Val Loss: 0.1833\n",
      "Epoch 36/50, Train Loss: 0.0027, Val Loss: 0.1858\n",
      "Epoch 37/50, Train Loss: 0.0024, Val Loss: 0.1919\n",
      "Epoch 38/50, Train Loss: 0.0031, Val Loss: 0.1836\n",
      "Epoch 39/50, Train Loss: 0.0027, Val Loss: 0.1965\n",
      "Epoch 40/50, Train Loss: 0.0019, Val Loss: 0.2160\n",
      "Epoch 41/50, Train Loss: 0.0017, Val Loss: 0.1727\n",
      "Epoch 42/50, Train Loss: 0.0014, Val Loss: 0.1859\n",
      "Epoch 43/50, Train Loss: 0.0012, Val Loss: 0.1741\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.1794\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.1814\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 0.1748\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 0.1726\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.1911\n",
      "Epoch 49/50, Train Loss: 0.0008, Val Loss: 0.1929\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.1856\n",
      "Fold 18 Accuracy: 0.9535\n",
      "\n",
      "===== Fold 19 =====\n",
      "Epoch 1/50, Train Loss: 0.9222, Val Loss: 0.5187\n",
      "Epoch 2/50, Train Loss: 0.3319, Val Loss: 0.2281\n",
      "Epoch 3/50, Train Loss: 0.1750, Val Loss: 0.1680\n",
      "Epoch 4/50, Train Loss: 0.1204, Val Loss: 0.1201\n",
      "Epoch 5/50, Train Loss: 0.0927, Val Loss: 0.0919\n",
      "Epoch 6/50, Train Loss: 0.0745, Val Loss: 0.0688\n",
      "Epoch 7/50, Train Loss: 0.0652, Val Loss: 0.0734\n",
      "Epoch 8/50, Train Loss: 0.0548, Val Loss: 0.0454\n",
      "Epoch 9/50, Train Loss: 0.0492, Val Loss: 0.0361\n",
      "Epoch 10/50, Train Loss: 0.0432, Val Loss: 0.0341\n",
      "Epoch 11/50, Train Loss: 0.0389, Val Loss: 0.0349\n",
      "Epoch 12/50, Train Loss: 0.0366, Val Loss: 0.0373\n",
      "Epoch 13/50, Train Loss: 0.0306, Val Loss: 0.0308\n",
      "Epoch 14/50, Train Loss: 0.0290, Val Loss: 0.0263\n",
      "Epoch 15/50, Train Loss: 0.0252, Val Loss: 0.0278\n",
      "Epoch 16/50, Train Loss: 0.0224, Val Loss: 0.0240\n",
      "Epoch 17/50, Train Loss: 0.0199, Val Loss: 0.0248\n",
      "Epoch 18/50, Train Loss: 0.0178, Val Loss: 0.0244\n",
      "Epoch 19/50, Train Loss: 0.0163, Val Loss: 0.0385\n",
      "Epoch 20/50, Train Loss: 0.0166, Val Loss: 0.0379\n",
      "Epoch 21/50, Train Loss: 0.0142, Val Loss: 0.0250\n",
      "Epoch 22/50, Train Loss: 0.0119, Val Loss: 0.0250\n",
      "Epoch 23/50, Train Loss: 0.0116, Val Loss: 0.0365\n",
      "Epoch 24/50, Train Loss: 0.0105, Val Loss: 0.0185\n",
      "Epoch 25/50, Train Loss: 0.0088, Val Loss: 0.0227\n",
      "Epoch 26/50, Train Loss: 0.0078, Val Loss: 0.0327\n",
      "Epoch 27/50, Train Loss: 0.0080, Val Loss: 0.0223\n",
      "Epoch 28/50, Train Loss: 0.0069, Val Loss: 0.0267\n",
      "Epoch 29/50, Train Loss: 0.0053, Val Loss: 0.0175\n",
      "Epoch 30/50, Train Loss: 0.0061, Val Loss: 0.0236\n",
      "Epoch 31/50, Train Loss: 0.0045, Val Loss: 0.0245\n",
      "Epoch 32/50, Train Loss: 0.0044, Val Loss: 0.0155\n",
      "Epoch 33/50, Train Loss: 0.0046, Val Loss: 0.0567\n",
      "Epoch 34/50, Train Loss: 0.0043, Val Loss: 0.0166\n",
      "Epoch 35/50, Train Loss: 0.0029, Val Loss: 0.0272\n",
      "Epoch 36/50, Train Loss: 0.0024, Val Loss: 0.0233\n",
      "Epoch 37/50, Train Loss: 0.0020, Val Loss: 0.0148\n",
      "Epoch 38/50, Train Loss: 0.0022, Val Loss: 0.0225\n",
      "Epoch 39/50, Train Loss: 0.0017, Val Loss: 0.0302\n",
      "Epoch 40/50, Train Loss: 0.0018, Val Loss: 0.0276\n",
      "Epoch 41/50, Train Loss: 0.0014, Val Loss: 0.0269\n",
      "Epoch 42/50, Train Loss: 0.0014, Val Loss: 0.0208\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.0373\n",
      "Epoch 44/50, Train Loss: 0.0010, Val Loss: 0.0262\n",
      "Epoch 45/50, Train Loss: 0.0009, Val Loss: 0.0228\n",
      "Epoch 46/50, Train Loss: 0.0008, Val Loss: 0.0306\n",
      "Epoch 47/50, Train Loss: 0.0009, Val Loss: 0.0195\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 0.0604\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.0178\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.0197\n",
      "Fold 19 Accuracy: 0.9898\n",
      "\n",
      "===== Fold 20 =====\n",
      "Epoch 1/50, Train Loss: 0.9508, Val Loss: 0.4505\n",
      "Epoch 2/50, Train Loss: 0.3727, Val Loss: 0.2180\n",
      "Epoch 3/50, Train Loss: 0.2167, Val Loss: 0.1268\n",
      "Epoch 4/50, Train Loss: 0.1484, Val Loss: 0.0907\n",
      "Epoch 5/50, Train Loss: 0.1095, Val Loss: 0.0720\n",
      "Epoch 6/50, Train Loss: 0.0905, Val Loss: 0.0575\n",
      "Epoch 7/50, Train Loss: 0.0754, Val Loss: 0.0526\n",
      "Epoch 8/50, Train Loss: 0.0645, Val Loss: 0.0615\n",
      "Epoch 9/50, Train Loss: 0.0559, Val Loss: 0.0751\n",
      "Epoch 10/50, Train Loss: 0.0517, Val Loss: 0.0396\n",
      "Epoch 11/50, Train Loss: 0.0436, Val Loss: 0.0503\n",
      "Epoch 12/50, Train Loss: 0.0405, Val Loss: 0.0426\n",
      "Epoch 13/50, Train Loss: 0.0441, Val Loss: 0.0345\n",
      "Epoch 14/50, Train Loss: 0.0322, Val Loss: 0.0277\n",
      "Epoch 15/50, Train Loss: 0.0286, Val Loss: 0.0256\n",
      "Epoch 16/50, Train Loss: 0.0256, Val Loss: 0.0246\n",
      "Epoch 17/50, Train Loss: 0.0239, Val Loss: 0.0216\n",
      "Epoch 18/50, Train Loss: 0.0233, Val Loss: 0.0384\n",
      "Epoch 19/50, Train Loss: 0.0189, Val Loss: 0.0321\n",
      "Epoch 20/50, Train Loss: 0.0173, Val Loss: 0.0492\n",
      "Epoch 21/50, Train Loss: 0.0154, Val Loss: 0.0179\n",
      "Epoch 22/50, Train Loss: 0.0139, Val Loss: 0.0234\n",
      "Epoch 23/50, Train Loss: 0.0131, Val Loss: 0.0382\n",
      "Epoch 24/50, Train Loss: 0.0112, Val Loss: 0.0258\n",
      "Epoch 25/50, Train Loss: 0.0107, Val Loss: 0.0242\n",
      "Epoch 26/50, Train Loss: 0.0086, Val Loss: 0.0379\n",
      "Epoch 27/50, Train Loss: 0.0080, Val Loss: 0.0219\n",
      "Epoch 28/50, Train Loss: 0.0066, Val Loss: 0.0463\n",
      "Epoch 29/50, Train Loss: 0.0067, Val Loss: 0.0240\n",
      "Epoch 30/50, Train Loss: 0.0054, Val Loss: 0.0320\n",
      "Epoch 31/50, Train Loss: 0.0044, Val Loss: 0.0253\n",
      "Epoch 32/50, Train Loss: 0.0043, Val Loss: 0.0305\n",
      "Epoch 33/50, Train Loss: 0.0035, Val Loss: 0.0316\n",
      "Epoch 34/50, Train Loss: 0.0032, Val Loss: 0.0420\n",
      "Epoch 35/50, Train Loss: 0.0029, Val Loss: 0.0262\n",
      "Epoch 36/50, Train Loss: 0.0043, Val Loss: 0.0837\n",
      "Epoch 37/50, Train Loss: 0.0031, Val Loss: 0.0217\n",
      "Epoch 38/50, Train Loss: 0.0023, Val Loss: 0.0346\n",
      "Epoch 39/50, Train Loss: 0.0019, Val Loss: 0.0293\n",
      "Epoch 40/50, Train Loss: 0.0017, Val Loss: 0.0460\n",
      "Epoch 41/50, Train Loss: 0.0020, Val Loss: 0.0294\n",
      "Epoch 42/50, Train Loss: 0.0017, Val Loss: 0.0307\n",
      "Epoch 43/50, Train Loss: 0.0013, Val Loss: 0.0301\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.0258\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.0346\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 0.0328\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.0215\n",
      "Epoch 48/50, Train Loss: 0.0090, Val Loss: 0.0398\n",
      "Epoch 49/50, Train Loss: 0.0079, Val Loss: 0.0354\n",
      "Epoch 50/50, Train Loss: 0.0023, Val Loss: 0.0362\n",
      "Fold 20 Accuracy: 0.9867\n",
      "\n",
      "===== Fold 21 =====\n",
      "Epoch 1/50, Train Loss: 0.8906, Val Loss: 0.5938\n",
      "Epoch 2/50, Train Loss: 0.3347, Val Loss: 0.3413\n",
      "Epoch 3/50, Train Loss: 0.1791, Val Loss: 0.2947\n",
      "Epoch 4/50, Train Loss: 0.1155, Val Loss: 0.2713\n",
      "Epoch 5/50, Train Loss: 0.0886, Val Loss: 0.1759\n",
      "Epoch 6/50, Train Loss: 0.0711, Val Loss: 0.1729\n",
      "Epoch 7/50, Train Loss: 0.0585, Val Loss: 0.2322\n",
      "Epoch 8/50, Train Loss: 0.0513, Val Loss: 0.2479\n",
      "Epoch 9/50, Train Loss: 0.0456, Val Loss: 0.1787\n",
      "Epoch 10/50, Train Loss: 0.0402, Val Loss: 0.2049\n",
      "Epoch 11/50, Train Loss: 0.0346, Val Loss: 0.1988\n",
      "Epoch 12/50, Train Loss: 0.0315, Val Loss: 0.1381\n",
      "Epoch 13/50, Train Loss: 0.0274, Val Loss: 0.1781\n",
      "Epoch 14/50, Train Loss: 0.0256, Val Loss: 0.2582\n",
      "Epoch 15/50, Train Loss: 0.0226, Val Loss: 0.2548\n",
      "Epoch 16/50, Train Loss: 0.0199, Val Loss: 0.2097\n",
      "Epoch 17/50, Train Loss: 0.0181, Val Loss: 0.2599\n",
      "Epoch 18/50, Train Loss: 0.0159, Val Loss: 0.2553\n",
      "Epoch 19/50, Train Loss: 0.0150, Val Loss: 0.1718\n",
      "Epoch 20/50, Train Loss: 0.0138, Val Loss: 0.3217\n",
      "Epoch 21/50, Train Loss: 0.0116, Val Loss: 0.3339\n",
      "Epoch 22/50, Train Loss: 0.0101, Val Loss: 0.2513\n",
      "Epoch 23/50, Train Loss: 0.0089, Val Loss: 0.2551\n",
      "Epoch 24/50, Train Loss: 0.0082, Val Loss: 0.3130\n",
      "Epoch 25/50, Train Loss: 0.0078, Val Loss: 0.2473\n",
      "Epoch 26/50, Train Loss: 0.0080, Val Loss: 0.3231\n",
      "Epoch 27/50, Train Loss: 0.0060, Val Loss: 0.2531\n",
      "Epoch 28/50, Train Loss: 0.0051, Val Loss: 0.2331\n",
      "Epoch 29/50, Train Loss: 0.0043, Val Loss: 0.2089\n",
      "Epoch 30/50, Train Loss: 0.0039, Val Loss: 0.2680\n",
      "Epoch 31/50, Train Loss: 0.0036, Val Loss: 0.2756\n",
      "Epoch 32/50, Train Loss: 0.0035, Val Loss: 0.2958\n",
      "Epoch 33/50, Train Loss: 0.0035, Val Loss: 0.3413\n",
      "Epoch 34/50, Train Loss: 0.0028, Val Loss: 0.3147\n",
      "Epoch 35/50, Train Loss: 0.0023, Val Loss: 0.2967\n",
      "Epoch 36/50, Train Loss: 0.0021, Val Loss: 0.2812\n",
      "Epoch 37/50, Train Loss: 0.0018, Val Loss: 0.2603\n",
      "Epoch 38/50, Train Loss: 0.0017, Val Loss: 0.2892\n",
      "Epoch 39/50, Train Loss: 0.0014, Val Loss: 0.3004\n",
      "Epoch 40/50, Train Loss: 0.0016, Val Loss: 0.3331\n",
      "Epoch 41/50, Train Loss: 0.0015, Val Loss: 0.3939\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.3470\n",
      "Epoch 43/50, Train Loss: 0.0010, Val Loss: 0.2884\n",
      "Epoch 44/50, Train Loss: 0.0009, Val Loss: 0.3610\n",
      "Epoch 45/50, Train Loss: 0.0012, Val Loss: 0.3345\n",
      "Epoch 46/50, Train Loss: 0.0007, Val Loss: 0.3053\n",
      "Epoch 47/50, Train Loss: 0.0010, Val Loss: 0.2639\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.3573\n",
      "Epoch 49/50, Train Loss: 0.0006, Val Loss: 0.3935\n",
      "Epoch 50/50, Train Loss: 0.0005, Val Loss: 0.3320\n",
      "Fold 21 Accuracy: 0.9241\n",
      "\n",
      "===== Fold 22 =====\n",
      "Epoch 1/50, Train Loss: 0.9969, Val Loss: 0.5508\n",
      "Epoch 2/50, Train Loss: 0.3796, Val Loss: 0.2548\n",
      "Epoch 3/50, Train Loss: 0.2038, Val Loss: 0.1876\n",
      "Epoch 4/50, Train Loss: 0.1329, Val Loss: 0.1407\n",
      "Epoch 5/50, Train Loss: 0.0997, Val Loss: 0.1271\n",
      "Epoch 6/50, Train Loss: 0.0786, Val Loss: 0.1809\n",
      "Epoch 7/50, Train Loss: 0.0664, Val Loss: 0.1814\n",
      "Epoch 8/50, Train Loss: 0.0556, Val Loss: 0.1152\n",
      "Epoch 9/50, Train Loss: 0.0478, Val Loss: 0.0977\n",
      "Epoch 10/50, Train Loss: 0.0411, Val Loss: 0.1334\n",
      "Epoch 11/50, Train Loss: 0.0381, Val Loss: 0.0663\n",
      "Epoch 12/50, Train Loss: 0.0320, Val Loss: 0.0799\n",
      "Epoch 13/50, Train Loss: 0.0295, Val Loss: 0.1064\n",
      "Epoch 14/50, Train Loss: 0.0257, Val Loss: 0.1123\n",
      "Epoch 15/50, Train Loss: 0.0233, Val Loss: 0.0674\n",
      "Epoch 16/50, Train Loss: 0.0216, Val Loss: 0.0826\n",
      "Epoch 17/50, Train Loss: 0.0186, Val Loss: 0.0581\n",
      "Epoch 18/50, Train Loss: 0.0163, Val Loss: 0.0888\n",
      "Epoch 19/50, Train Loss: 0.0152, Val Loss: 0.0763\n",
      "Epoch 20/50, Train Loss: 0.0149, Val Loss: 0.0649\n",
      "Epoch 21/50, Train Loss: 0.0120, Val Loss: 0.0857\n",
      "Epoch 22/50, Train Loss: 0.0106, Val Loss: 0.0574\n",
      "Epoch 23/50, Train Loss: 0.0107, Val Loss: 0.0958\n",
      "Epoch 24/50, Train Loss: 0.0090, Val Loss: 0.1228\n",
      "Epoch 25/50, Train Loss: 0.0075, Val Loss: 0.0485\n",
      "Epoch 26/50, Train Loss: 0.0074, Val Loss: 0.0779\n",
      "Epoch 27/50, Train Loss: 0.0069, Val Loss: 0.0684\n",
      "Epoch 28/50, Train Loss: 0.0059, Val Loss: 0.0495\n",
      "Epoch 29/50, Train Loss: 0.0053, Val Loss: 0.0414\n",
      "Epoch 30/50, Train Loss: 0.0051, Val Loss: 0.0369\n",
      "Epoch 31/50, Train Loss: 0.0043, Val Loss: 0.0717\n",
      "Epoch 32/50, Train Loss: 0.0042, Val Loss: 0.1456\n",
      "Epoch 33/50, Train Loss: 0.0033, Val Loss: 0.0654\n",
      "Epoch 34/50, Train Loss: 0.0028, Val Loss: 0.0645\n",
      "Epoch 35/50, Train Loss: 0.0027, Val Loss: 0.0947\n",
      "Epoch 36/50, Train Loss: 0.0024, Val Loss: 0.0992\n",
      "Epoch 37/50, Train Loss: 0.0020, Val Loss: 0.1052\n",
      "Epoch 38/50, Train Loss: 0.0018, Val Loss: 0.0870\n",
      "Epoch 39/50, Train Loss: 0.0017, Val Loss: 0.0944\n",
      "Epoch 40/50, Train Loss: 0.0017, Val Loss: 0.0808\n",
      "Epoch 41/50, Train Loss: 0.0017, Val Loss: 0.0721\n",
      "Epoch 42/50, Train Loss: 0.0016, Val Loss: 0.1326\n",
      "Epoch 43/50, Train Loss: 0.0069, Val Loss: 0.0731\n",
      "Epoch 44/50, Train Loss: 0.0023, Val Loss: 0.0788\n",
      "Epoch 45/50, Train Loss: 0.0025, Val Loss: 0.0369\n",
      "Epoch 46/50, Train Loss: 0.0050, Val Loss: 0.0765\n",
      "Epoch 47/50, Train Loss: 0.0018, Val Loss: 0.0687\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.1029\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.1012\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.0785\n",
      "Fold 22 Accuracy: 0.9651\n",
      "\n",
      "===== Fold 23 =====\n",
      "Epoch 1/50, Train Loss: 0.9089, Val Loss: 0.4103\n",
      "Epoch 2/50, Train Loss: 0.3135, Val Loss: 0.1964\n",
      "Epoch 3/50, Train Loss: 0.1702, Val Loss: 0.1293\n",
      "Epoch 4/50, Train Loss: 0.1161, Val Loss: 0.1020\n",
      "Epoch 5/50, Train Loss: 0.0869, Val Loss: 0.0809\n",
      "Epoch 6/50, Train Loss: 0.0699, Val Loss: 0.0827\n",
      "Epoch 7/50, Train Loss: 0.0636, Val Loss: 0.0830\n",
      "Epoch 8/50, Train Loss: 0.0533, Val Loss: 0.0626\n",
      "Epoch 9/50, Train Loss: 0.0466, Val Loss: 0.0731\n",
      "Epoch 10/50, Train Loss: 0.0412, Val Loss: 0.0587\n",
      "Epoch 11/50, Train Loss: 0.0371, Val Loss: 0.0650\n",
      "Epoch 12/50, Train Loss: 0.0347, Val Loss: 0.0687\n",
      "Epoch 13/50, Train Loss: 0.0316, Val Loss: 0.0627\n",
      "Epoch 14/50, Train Loss: 0.0284, Val Loss: 0.0670\n",
      "Epoch 15/50, Train Loss: 0.0258, Val Loss: 0.0619\n",
      "Epoch 16/50, Train Loss: 0.0227, Val Loss: 0.0652\n",
      "Epoch 17/50, Train Loss: 0.0217, Val Loss: 0.0599\n",
      "Epoch 18/50, Train Loss: 0.0187, Val Loss: 0.0646\n",
      "Epoch 19/50, Train Loss: 0.0171, Val Loss: 0.0574\n",
      "Epoch 20/50, Train Loss: 0.0153, Val Loss: 0.0635\n",
      "Epoch 21/50, Train Loss: 0.0140, Val Loss: 0.0724\n",
      "Epoch 22/50, Train Loss: 0.0132, Val Loss: 0.0636\n",
      "Epoch 23/50, Train Loss: 0.0117, Val Loss: 0.0630\n",
      "Epoch 24/50, Train Loss: 0.0094, Val Loss: 0.0660\n",
      "Epoch 25/50, Train Loss: 0.0092, Val Loss: 0.0579\n",
      "Epoch 26/50, Train Loss: 0.0081, Val Loss: 0.0704\n",
      "Epoch 27/50, Train Loss: 0.0070, Val Loss: 0.0658\n",
      "Epoch 28/50, Train Loss: 0.0063, Val Loss: 0.0636\n",
      "Epoch 29/50, Train Loss: 0.0058, Val Loss: 0.0716\n",
      "Epoch 30/50, Train Loss: 0.0065, Val Loss: 0.0694\n",
      "Epoch 31/50, Train Loss: 0.0049, Val Loss: 0.0628\n",
      "Epoch 32/50, Train Loss: 0.0038, Val Loss: 0.0620\n",
      "Epoch 33/50, Train Loss: 0.0033, Val Loss: 0.0617\n",
      "Epoch 34/50, Train Loss: 0.0031, Val Loss: 0.0680\n",
      "Epoch 35/50, Train Loss: 0.0025, Val Loss: 0.0712\n",
      "Epoch 36/50, Train Loss: 0.0022, Val Loss: 0.0904\n",
      "Epoch 37/50, Train Loss: 0.0021, Val Loss: 0.0590\n",
      "Epoch 38/50, Train Loss: 0.0018, Val Loss: 0.0634\n",
      "Epoch 39/50, Train Loss: 0.0021, Val Loss: 0.0663\n",
      "Epoch 40/50, Train Loss: 0.0029, Val Loss: 0.0683\n",
      "Epoch 41/50, Train Loss: 0.0017, Val Loss: 0.0681\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.0620\n",
      "Epoch 43/50, Train Loss: 0.0011, Val Loss: 0.0634\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.0640\n",
      "Epoch 45/50, Train Loss: 0.0048, Val Loss: 0.1055\n",
      "Epoch 46/50, Train Loss: 0.0114, Val Loss: 0.0618\n",
      "Epoch 47/50, Train Loss: 0.0073, Val Loss: 0.0661\n",
      "Epoch 48/50, Train Loss: 0.0012, Val Loss: 0.0705\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.0720\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.0651\n",
      "Fold 23 Accuracy: 0.9883\n",
      "\n",
      "===== Fold 24 =====\n",
      "Epoch 1/50, Train Loss: 0.9642, Val Loss: 0.5128\n",
      "Epoch 2/50, Train Loss: 0.3575, Val Loss: 0.2208\n",
      "Epoch 3/50, Train Loss: 0.1897, Val Loss: 0.1227\n",
      "Epoch 4/50, Train Loss: 0.1273, Val Loss: 0.0869\n",
      "Epoch 5/50, Train Loss: 0.0957, Val Loss: 0.0609\n",
      "Epoch 6/50, Train Loss: 0.0775, Val Loss: 0.0509\n",
      "Epoch 7/50, Train Loss: 0.0662, Val Loss: 0.0416\n",
      "Epoch 8/50, Train Loss: 0.0558, Val Loss: 0.0352\n",
      "Epoch 9/50, Train Loss: 0.0473, Val Loss: 0.0288\n",
      "Epoch 10/50, Train Loss: 0.0429, Val Loss: 0.0246\n",
      "Epoch 11/50, Train Loss: 0.0395, Val Loss: 0.0286\n",
      "Epoch 12/50, Train Loss: 0.0335, Val Loss: 0.0216\n",
      "Epoch 13/50, Train Loss: 0.0298, Val Loss: 0.0185\n",
      "Epoch 14/50, Train Loss: 0.0279, Val Loss: 0.0202\n",
      "Epoch 15/50, Train Loss: 0.0271, Val Loss: 0.0245\n",
      "Epoch 16/50, Train Loss: 0.0223, Val Loss: 0.0210\n",
      "Epoch 17/50, Train Loss: 0.0207, Val Loss: 0.0215\n",
      "Epoch 18/50, Train Loss: 0.0192, Val Loss: 0.0165\n",
      "Epoch 19/50, Train Loss: 0.0172, Val Loss: 0.0168\n",
      "Epoch 20/50, Train Loss: 0.0172, Val Loss: 0.0147\n",
      "Epoch 21/50, Train Loss: 0.0140, Val Loss: 0.0163\n",
      "Epoch 22/50, Train Loss: 0.0137, Val Loss: 0.0151\n",
      "Epoch 23/50, Train Loss: 0.0118, Val Loss: 0.0142\n",
      "Epoch 24/50, Train Loss: 0.0103, Val Loss: 0.0178\n",
      "Epoch 25/50, Train Loss: 0.0093, Val Loss: 0.0163\n",
      "Epoch 26/50, Train Loss: 0.0080, Val Loss: 0.0146\n",
      "Epoch 27/50, Train Loss: 0.0074, Val Loss: 0.0142\n",
      "Epoch 28/50, Train Loss: 0.0070, Val Loss: 0.0155\n",
      "Epoch 29/50, Train Loss: 0.0064, Val Loss: 0.0123\n",
      "Epoch 30/50, Train Loss: 0.0055, Val Loss: 0.0132\n",
      "Epoch 31/50, Train Loss: 0.0048, Val Loss: 0.0153\n",
      "Epoch 32/50, Train Loss: 0.0054, Val Loss: 0.0170\n",
      "Epoch 33/50, Train Loss: 0.0055, Val Loss: 0.0130\n",
      "Epoch 34/50, Train Loss: 0.0036, Val Loss: 0.0128\n",
      "Epoch 35/50, Train Loss: 0.0033, Val Loss: 0.0136\n",
      "Epoch 36/50, Train Loss: 0.0036, Val Loss: 0.0151\n",
      "Epoch 37/50, Train Loss: 0.0027, Val Loss: 0.0127\n",
      "Epoch 38/50, Train Loss: 0.0023, Val Loss: 0.0106\n",
      "Epoch 39/50, Train Loss: 0.0023, Val Loss: 0.0134\n",
      "Epoch 40/50, Train Loss: 0.0019, Val Loss: 0.0127\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 0.0149\n",
      "Epoch 42/50, Train Loss: 0.0016, Val Loss: 0.0136\n",
      "Epoch 43/50, Train Loss: 0.0014, Val Loss: 0.0138\n",
      "Epoch 44/50, Train Loss: 0.0012, Val Loss: 0.0133\n",
      "Epoch 45/50, Train Loss: 0.0017, Val Loss: 0.0162\n",
      "Epoch 46/50, Train Loss: 0.0060, Val Loss: 0.0215\n",
      "Epoch 47/50, Train Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch 48/50, Train Loss: 0.0053, Val Loss: 0.0116\n",
      "Epoch 49/50, Train Loss: 0.0029, Val Loss: 0.0094\n",
      "Epoch 50/50, Train Loss: 0.0026, Val Loss: 0.0106\n",
      "Fold 24 Accuracy: 0.9922\n",
      "\n",
      "===== Fold 25 =====\n",
      "Epoch 1/50, Train Loss: 0.9764, Val Loss: 0.5486\n",
      "Epoch 2/50, Train Loss: 0.3835, Val Loss: 0.3068\n",
      "Epoch 3/50, Train Loss: 0.2054, Val Loss: 0.1993\n",
      "Epoch 4/50, Train Loss: 0.1367, Val Loss: 0.1329\n",
      "Epoch 5/50, Train Loss: 0.1029, Val Loss: 0.1233\n",
      "Epoch 6/50, Train Loss: 0.0821, Val Loss: 0.1146\n",
      "Epoch 7/50, Train Loss: 0.0691, Val Loss: 0.1120\n",
      "Epoch 8/50, Train Loss: 0.0574, Val Loss: 0.1172\n",
      "Epoch 9/50, Train Loss: 0.0511, Val Loss: 0.0973\n",
      "Epoch 10/50, Train Loss: 0.0445, Val Loss: 0.0979\n",
      "Epoch 11/50, Train Loss: 0.0397, Val Loss: 0.1087\n",
      "Epoch 12/50, Train Loss: 0.0352, Val Loss: 0.1111\n",
      "Epoch 13/50, Train Loss: 0.0309, Val Loss: 0.1045\n",
      "Epoch 14/50, Train Loss: 0.0273, Val Loss: 0.1069\n",
      "Epoch 15/50, Train Loss: 0.0240, Val Loss: 0.1038\n",
      "Epoch 16/50, Train Loss: 0.0218, Val Loss: 0.0988\n",
      "Epoch 17/50, Train Loss: 0.0200, Val Loss: 0.0873\n",
      "Epoch 18/50, Train Loss: 0.0173, Val Loss: 0.0931\n",
      "Epoch 19/50, Train Loss: 0.0158, Val Loss: 0.1019\n",
      "Epoch 20/50, Train Loss: 0.0137, Val Loss: 0.0902\n",
      "Epoch 21/50, Train Loss: 0.0129, Val Loss: 0.0985\n",
      "Epoch 22/50, Train Loss: 0.0113, Val Loss: 0.0944\n",
      "Epoch 23/50, Train Loss: 0.0108, Val Loss: 0.0861\n",
      "Epoch 24/50, Train Loss: 0.0106, Val Loss: 0.1031\n",
      "Epoch 25/50, Train Loss: 0.0092, Val Loss: 0.0845\n",
      "Epoch 26/50, Train Loss: 0.0080, Val Loss: 0.0872\n",
      "Epoch 27/50, Train Loss: 0.0069, Val Loss: 0.0943\n",
      "Epoch 28/50, Train Loss: 0.0075, Val Loss: 0.0969\n",
      "Epoch 29/50, Train Loss: 0.0064, Val Loss: 0.0838\n",
      "Epoch 30/50, Train Loss: 0.0065, Val Loss: 0.1008\n",
      "Epoch 31/50, Train Loss: 0.0049, Val Loss: 0.0935\n",
      "Epoch 32/50, Train Loss: 0.0045, Val Loss: 0.0932\n",
      "Epoch 33/50, Train Loss: 0.0036, Val Loss: 0.0881\n",
      "Epoch 34/50, Train Loss: 0.0037, Val Loss: 0.0962\n",
      "Epoch 35/50, Train Loss: 0.0028, Val Loss: 0.0996\n",
      "Epoch 36/50, Train Loss: 0.0030, Val Loss: 0.1081\n",
      "Epoch 37/50, Train Loss: 0.0023, Val Loss: 0.0940\n",
      "Epoch 38/50, Train Loss: 0.0021, Val Loss: 0.0895\n",
      "Epoch 39/50, Train Loss: 0.0020, Val Loss: 0.0917\n",
      "Epoch 40/50, Train Loss: 0.0019, Val Loss: 0.0927\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 0.0971\n",
      "Epoch 42/50, Train Loss: 0.0017, Val Loss: 0.0992\n",
      "Epoch 43/50, Train Loss: 0.0024, Val Loss: 0.1210\n",
      "Epoch 44/50, Train Loss: 0.0024, Val Loss: 0.1128\n",
      "Epoch 45/50, Train Loss: 0.0011, Val Loss: 0.1063\n",
      "Epoch 46/50, Train Loss: 0.0010, Val Loss: 0.1082\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.1175\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.1077\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.1059\n",
      "Epoch 50/50, Train Loss: 0.0006, Val Loss: 0.1072\n",
      "Fold 25 Accuracy: 0.9685\n",
      "\n",
      "===== Fold 26 =====\n",
      "Epoch 1/50, Train Loss: 0.9886, Val Loss: 0.6077\n",
      "Epoch 2/50, Train Loss: 0.3782, Val Loss: 0.3654\n",
      "Epoch 3/50, Train Loss: 0.2019, Val Loss: 0.2844\n",
      "Epoch 4/50, Train Loss: 0.1309, Val Loss: 0.2431\n",
      "Epoch 5/50, Train Loss: 0.0974, Val Loss: 0.2922\n",
      "Epoch 6/50, Train Loss: 0.0766, Val Loss: 0.2498\n",
      "Epoch 7/50, Train Loss: 0.0633, Val Loss: 0.2457\n",
      "Epoch 8/50, Train Loss: 0.0533, Val Loss: 0.2659\n",
      "Epoch 9/50, Train Loss: 0.0458, Val Loss: 0.2513\n",
      "Epoch 10/50, Train Loss: 0.0414, Val Loss: 0.2703\n",
      "Epoch 11/50, Train Loss: 0.0355, Val Loss: 0.2666\n",
      "Epoch 12/50, Train Loss: 0.0313, Val Loss: 0.2734\n",
      "Epoch 13/50, Train Loss: 0.0282, Val Loss: 0.3541\n",
      "Epoch 14/50, Train Loss: 0.0263, Val Loss: 0.2290\n",
      "Epoch 15/50, Train Loss: 0.0226, Val Loss: 0.2629\n",
      "Epoch 16/50, Train Loss: 0.0195, Val Loss: 0.3080\n",
      "Epoch 17/50, Train Loss: 0.0183, Val Loss: 0.3391\n",
      "Epoch 18/50, Train Loss: 0.0151, Val Loss: 0.2672\n",
      "Epoch 19/50, Train Loss: 0.0139, Val Loss: 0.3497\n",
      "Epoch 20/50, Train Loss: 0.0128, Val Loss: 0.2117\n",
      "Epoch 21/50, Train Loss: 0.0118, Val Loss: 0.2817\n",
      "Epoch 22/50, Train Loss: 0.0097, Val Loss: 0.2638\n",
      "Epoch 23/50, Train Loss: 0.0099, Val Loss: 0.2876\n",
      "Epoch 24/50, Train Loss: 0.0097, Val Loss: 0.3808\n",
      "Epoch 25/50, Train Loss: 0.0075, Val Loss: 0.3169\n",
      "Epoch 26/50, Train Loss: 0.0071, Val Loss: 0.2759\n",
      "Epoch 27/50, Train Loss: 0.0059, Val Loss: 0.3241\n",
      "Epoch 28/50, Train Loss: 0.0051, Val Loss: 0.2672\n",
      "Epoch 29/50, Train Loss: 0.0046, Val Loss: 0.3718\n",
      "Epoch 30/50, Train Loss: 0.0064, Val Loss: 0.3544\n",
      "Epoch 31/50, Train Loss: 0.0039, Val Loss: 0.3175\n",
      "Epoch 32/50, Train Loss: 0.0035, Val Loss: 0.4306\n",
      "Epoch 33/50, Train Loss: 0.0033, Val Loss: 0.3459\n",
      "Epoch 34/50, Train Loss: 0.0026, Val Loss: 0.3325\n",
      "Epoch 35/50, Train Loss: 0.0024, Val Loss: 0.3867\n",
      "Epoch 36/50, Train Loss: 0.0022, Val Loss: 0.4771\n",
      "Epoch 37/50, Train Loss: 0.0025, Val Loss: 0.3752\n",
      "Epoch 38/50, Train Loss: 0.0022, Val Loss: 0.4105\n",
      "Epoch 39/50, Train Loss: 0.0015, Val Loss: 0.3605\n",
      "Epoch 40/50, Train Loss: 0.0015, Val Loss: 0.4653\n",
      "Epoch 41/50, Train Loss: 0.0013, Val Loss: 0.4176\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.3820\n",
      "Epoch 43/50, Train Loss: 0.0010, Val Loss: 0.3879\n",
      "Epoch 44/50, Train Loss: 0.0009, Val Loss: 0.3769\n",
      "Epoch 45/50, Train Loss: 0.0009, Val Loss: 0.4097\n",
      "Epoch 46/50, Train Loss: 0.0008, Val Loss: 0.4045\n",
      "Epoch 47/50, Train Loss: 0.0007, Val Loss: 0.4125\n",
      "Epoch 48/50, Train Loss: 0.0007, Val Loss: 0.3776\n",
      "Epoch 49/50, Train Loss: 0.0056, Val Loss: 0.4259\n",
      "Epoch 50/50, Train Loss: 0.0095, Val Loss: 0.3037\n",
      "Fold 26 Accuracy: 0.9238\n",
      "\n",
      "===== Fold 27 =====\n",
      "Epoch 1/50, Train Loss: 0.9698, Val Loss: 0.6921\n",
      "Epoch 2/50, Train Loss: 0.3644, Val Loss: 0.5102\n",
      "Epoch 3/50, Train Loss: 0.1905, Val Loss: 0.4695\n",
      "Epoch 4/50, Train Loss: 0.1276, Val Loss: 0.3752\n",
      "Epoch 5/50, Train Loss: 0.0990, Val Loss: 0.3354\n",
      "Epoch 6/50, Train Loss: 0.0783, Val Loss: 0.3308\n",
      "Epoch 7/50, Train Loss: 0.0665, Val Loss: 0.3256\n",
      "Epoch 8/50, Train Loss: 0.0576, Val Loss: 0.3195\n",
      "Epoch 9/50, Train Loss: 0.0507, Val Loss: 0.3634\n",
      "Epoch 10/50, Train Loss: 0.0463, Val Loss: 0.2872\n",
      "Epoch 11/50, Train Loss: 0.0403, Val Loss: 0.3537\n",
      "Epoch 12/50, Train Loss: 0.0357, Val Loss: 0.4056\n",
      "Epoch 13/50, Train Loss: 0.0334, Val Loss: 0.4192\n",
      "Epoch 14/50, Train Loss: 0.0307, Val Loss: 0.4308\n",
      "Epoch 15/50, Train Loss: 0.0289, Val Loss: 0.3670\n",
      "Epoch 16/50, Train Loss: 0.0246, Val Loss: 0.4192\n",
      "Epoch 17/50, Train Loss: 0.0212, Val Loss: 0.4022\n",
      "Epoch 18/50, Train Loss: 0.0190, Val Loss: 0.4488\n",
      "Epoch 19/50, Train Loss: 0.0183, Val Loss: 0.4583\n",
      "Epoch 20/50, Train Loss: 0.0158, Val Loss: 0.4549\n",
      "Epoch 21/50, Train Loss: 0.0155, Val Loss: 0.4727\n",
      "Epoch 22/50, Train Loss: 0.0140, Val Loss: 0.4324\n",
      "Epoch 23/50, Train Loss: 0.0113, Val Loss: 0.4210\n",
      "Epoch 24/50, Train Loss: 0.0103, Val Loss: 0.4591\n",
      "Epoch 25/50, Train Loss: 0.0096, Val Loss: 0.4673\n",
      "Epoch 26/50, Train Loss: 0.0084, Val Loss: 0.4698\n",
      "Epoch 27/50, Train Loss: 0.0081, Val Loss: 0.4823\n",
      "Epoch 28/50, Train Loss: 0.0080, Val Loss: 0.5026\n",
      "Epoch 29/50, Train Loss: 0.0063, Val Loss: 0.4875\n",
      "Epoch 30/50, Train Loss: 0.0056, Val Loss: 0.4469\n",
      "Epoch 31/50, Train Loss: 0.0044, Val Loss: 0.5194\n",
      "Epoch 32/50, Train Loss: 0.0047, Val Loss: 0.5113\n",
      "Epoch 33/50, Train Loss: 0.0045, Val Loss: 0.4810\n",
      "Epoch 34/50, Train Loss: 0.0033, Val Loss: 0.5139\n",
      "Epoch 35/50, Train Loss: 0.0038, Val Loss: 0.5050\n",
      "Epoch 36/50, Train Loss: 0.0047, Val Loss: 0.5418\n",
      "Epoch 37/50, Train Loss: 0.0034, Val Loss: 0.5135\n",
      "Epoch 38/50, Train Loss: 0.0024, Val Loss: 0.4969\n",
      "Epoch 39/50, Train Loss: 0.0019, Val Loss: 0.5228\n",
      "Epoch 40/50, Train Loss: 0.0016, Val Loss: 0.5218\n",
      "Epoch 41/50, Train Loss: 0.0015, Val Loss: 0.5374\n",
      "Epoch 42/50, Train Loss: 0.0015, Val Loss: 0.5254\n",
      "Epoch 43/50, Train Loss: 0.0013, Val Loss: 0.5529\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.5199\n",
      "Epoch 45/50, Train Loss: 0.0010, Val Loss: 0.5681\n",
      "Epoch 46/50, Train Loss: 0.0011, Val Loss: 0.5526\n",
      "Epoch 47/50, Train Loss: 0.0010, Val Loss: 0.5908\n",
      "Epoch 48/50, Train Loss: 0.0008, Val Loss: 0.5593\n",
      "Epoch 49/50, Train Loss: 0.0007, Val Loss: 0.6004\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.5992\n",
      "Fold 27 Accuracy: 0.8738\n",
      "\n",
      "===== Fold 28 =====\n",
      "Epoch 1/50, Train Loss: 0.9552, Val Loss: 0.5365\n",
      "Epoch 2/50, Train Loss: 0.3558, Val Loss: 0.2992\n",
      "Epoch 3/50, Train Loss: 0.1938, Val Loss: 0.2458\n",
      "Epoch 4/50, Train Loss: 0.1325, Val Loss: 0.2605\n",
      "Epoch 5/50, Train Loss: 0.0988, Val Loss: 0.2184\n",
      "Epoch 6/50, Train Loss: 0.0792, Val Loss: 0.1972\n",
      "Epoch 7/50, Train Loss: 0.0654, Val Loss: 0.1887\n",
      "Epoch 8/50, Train Loss: 0.0573, Val Loss: 0.1973\n",
      "Epoch 9/50, Train Loss: 0.0498, Val Loss: 0.2273\n",
      "Epoch 10/50, Train Loss: 0.0431, Val Loss: 0.2210\n",
      "Epoch 11/50, Train Loss: 0.0403, Val Loss: 0.2152\n",
      "Epoch 12/50, Train Loss: 0.0356, Val Loss: 0.2217\n",
      "Epoch 13/50, Train Loss: 0.0307, Val Loss: 0.2161\n",
      "Epoch 14/50, Train Loss: 0.0291, Val Loss: 0.2331\n",
      "Epoch 15/50, Train Loss: 0.0260, Val Loss: 0.2225\n",
      "Epoch 16/50, Train Loss: 0.0231, Val Loss: 0.2369\n",
      "Epoch 17/50, Train Loss: 0.0215, Val Loss: 0.2494\n",
      "Epoch 18/50, Train Loss: 0.0189, Val Loss: 0.2657\n",
      "Epoch 19/50, Train Loss: 0.0170, Val Loss: 0.2407\n",
      "Epoch 20/50, Train Loss: 0.0149, Val Loss: 0.2446\n",
      "Epoch 21/50, Train Loss: 0.0131, Val Loss: 0.2527\n",
      "Epoch 22/50, Train Loss: 0.0119, Val Loss: 0.2598\n",
      "Epoch 23/50, Train Loss: 0.0107, Val Loss: 0.2584\n",
      "Epoch 24/50, Train Loss: 0.0101, Val Loss: 0.2704\n",
      "Epoch 25/50, Train Loss: 0.0088, Val Loss: 0.2790\n",
      "Epoch 26/50, Train Loss: 0.0078, Val Loss: 0.2811\n",
      "Epoch 27/50, Train Loss: 0.0075, Val Loss: 0.2795\n",
      "Epoch 28/50, Train Loss: 0.0063, Val Loss: 0.3005\n",
      "Epoch 29/50, Train Loss: 0.0060, Val Loss: 0.2789\n",
      "Epoch 30/50, Train Loss: 0.0058, Val Loss: 0.2967\n",
      "Epoch 31/50, Train Loss: 0.0047, Val Loss: 0.3028\n",
      "Epoch 32/50, Train Loss: 0.0039, Val Loss: 0.2921\n",
      "Epoch 33/50, Train Loss: 0.0039, Val Loss: 0.3039\n",
      "Epoch 34/50, Train Loss: 0.0035, Val Loss: 0.3049\n",
      "Epoch 35/50, Train Loss: 0.0030, Val Loss: 0.3125\n",
      "Epoch 36/50, Train Loss: 0.0027, Val Loss: 0.3082\n",
      "Epoch 37/50, Train Loss: 0.0024, Val Loss: 0.3153\n",
      "Epoch 38/50, Train Loss: 0.0022, Val Loss: 0.3293\n",
      "Epoch 39/50, Train Loss: 0.0023, Val Loss: 0.3132\n",
      "Epoch 40/50, Train Loss: 0.0021, Val Loss: 0.3220\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 0.3062\n",
      "Epoch 42/50, Train Loss: 0.0015, Val Loss: 0.3288\n",
      "Epoch 43/50, Train Loss: 0.0016, Val Loss: 0.3436\n",
      "Epoch 44/50, Train Loss: 0.0111, Val Loss: 0.3586\n",
      "Epoch 45/50, Train Loss: 0.0067, Val Loss: 0.2753\n",
      "Epoch 46/50, Train Loss: 0.0024, Val Loss: 0.3979\n",
      "Epoch 47/50, Train Loss: 0.0014, Val Loss: 0.3488\n",
      "Epoch 48/50, Train Loss: 0.0010, Val Loss: 0.3494\n",
      "Epoch 49/50, Train Loss: 0.0009, Val Loss: 0.3431\n",
      "Epoch 50/50, Train Loss: 0.0008, Val Loss: 0.3435\n",
      "Fold 28 Accuracy: 0.9318\n",
      "\n",
      "===== Fold 29 =====\n",
      "Epoch 1/50, Train Loss: 0.9440, Val Loss: 0.6022\n",
      "Epoch 2/50, Train Loss: 0.3553, Val Loss: 0.3068\n",
      "Epoch 3/50, Train Loss: 0.1909, Val Loss: 0.2266\n",
      "Epoch 4/50, Train Loss: 0.1286, Val Loss: 0.1879\n",
      "Epoch 5/50, Train Loss: 0.0955, Val Loss: 0.1792\n",
      "Epoch 6/50, Train Loss: 0.0762, Val Loss: 0.2278\n",
      "Epoch 7/50, Train Loss: 0.0662, Val Loss: 0.1780\n",
      "Epoch 8/50, Train Loss: 0.0545, Val Loss: 0.1358\n",
      "Epoch 9/50, Train Loss: 0.0477, Val Loss: 0.1300\n",
      "Epoch 10/50, Train Loss: 0.0413, Val Loss: 0.1137\n",
      "Epoch 11/50, Train Loss: 0.0372, Val Loss: 0.1199\n",
      "Epoch 12/50, Train Loss: 0.0332, Val Loss: 0.1490\n",
      "Epoch 13/50, Train Loss: 0.0300, Val Loss: 0.1466\n",
      "Epoch 14/50, Train Loss: 0.0274, Val Loss: 0.1278\n",
      "Epoch 15/50, Train Loss: 0.0257, Val Loss: 0.1228\n",
      "Epoch 16/50, Train Loss: 0.0207, Val Loss: 0.1296\n",
      "Epoch 17/50, Train Loss: 0.0188, Val Loss: 0.1293\n",
      "Epoch 18/50, Train Loss: 0.0172, Val Loss: 0.1683\n",
      "Epoch 19/50, Train Loss: 0.0152, Val Loss: 0.1308\n",
      "Epoch 20/50, Train Loss: 0.0138, Val Loss: 0.1313\n",
      "Epoch 21/50, Train Loss: 0.0134, Val Loss: 0.1644\n",
      "Epoch 22/50, Train Loss: 0.0119, Val Loss: 0.1641\n",
      "Epoch 23/50, Train Loss: 0.0119, Val Loss: 0.1445\n",
      "Epoch 24/50, Train Loss: 0.0090, Val Loss: 0.1529\n",
      "Epoch 25/50, Train Loss: 0.0086, Val Loss: 0.1421\n",
      "Epoch 26/50, Train Loss: 0.0081, Val Loss: 0.1363\n",
      "Epoch 27/50, Train Loss: 0.0073, Val Loss: 0.1453\n",
      "Epoch 28/50, Train Loss: 0.0061, Val Loss: 0.2021\n",
      "Epoch 29/50, Train Loss: 0.0055, Val Loss: 0.1815\n",
      "Epoch 30/50, Train Loss: 0.0047, Val Loss: 0.1476\n",
      "Epoch 31/50, Train Loss: 0.0043, Val Loss: 0.1364\n",
      "Epoch 32/50, Train Loss: 0.0036, Val Loss: 0.1221\n",
      "Epoch 33/50, Train Loss: 0.0044, Val Loss: 0.1548\n",
      "Epoch 34/50, Train Loss: 0.0036, Val Loss: 0.1177\n",
      "Epoch 35/50, Train Loss: 0.0037, Val Loss: 0.1399\n",
      "Epoch 36/50, Train Loss: 0.0036, Val Loss: 0.1406\n",
      "Epoch 37/50, Train Loss: 0.0026, Val Loss: 0.1572\n",
      "Epoch 38/50, Train Loss: 0.0026, Val Loss: 0.1170\n",
      "Epoch 39/50, Train Loss: 0.0019, Val Loss: 0.1415\n",
      "Epoch 40/50, Train Loss: 0.0016, Val Loss: 0.1537\n",
      "Epoch 41/50, Train Loss: 0.0016, Val Loss: 0.1002\n",
      "Epoch 42/50, Train Loss: 0.0015, Val Loss: 0.1547\n",
      "Epoch 43/50, Train Loss: 0.0012, Val Loss: 0.1389\n",
      "Epoch 44/50, Train Loss: 0.0011, Val Loss: 0.1269\n",
      "Epoch 45/50, Train Loss: 0.0009, Val Loss: 0.1397\n",
      "Epoch 46/50, Train Loss: 0.0008, Val Loss: 0.1470\n",
      "Epoch 47/50, Train Loss: 0.0008, Val Loss: 0.1726\n",
      "Epoch 48/50, Train Loss: 0.0156, Val Loss: 0.2932\n",
      "Epoch 49/50, Train Loss: 0.0106, Val Loss: 0.1805\n",
      "Epoch 50/50, Train Loss: 0.0029, Val Loss: 0.1542\n",
      "Fold 29 Accuracy: 0.9502\n",
      "\n",
      "===== Fold 30 =====\n",
      "Epoch 1/50, Train Loss: 0.9206, Val Loss: 0.5596\n",
      "Epoch 2/50, Train Loss: 0.3464, Val Loss: 0.3501\n",
      "Epoch 3/50, Train Loss: 0.1875, Val Loss: 0.2659\n",
      "Epoch 4/50, Train Loss: 0.1238, Val Loss: 0.2535\n",
      "Epoch 5/50, Train Loss: 0.0921, Val Loss: 0.2531\n",
      "Epoch 6/50, Train Loss: 0.0716, Val Loss: 0.2491\n",
      "Epoch 7/50, Train Loss: 0.0590, Val Loss: 0.2233\n",
      "Epoch 8/50, Train Loss: 0.0498, Val Loss: 0.2609\n",
      "Epoch 9/50, Train Loss: 0.0448, Val Loss: 0.2149\n",
      "Epoch 10/50, Train Loss: 0.0382, Val Loss: 0.2248\n",
      "Epoch 11/50, Train Loss: 0.0345, Val Loss: 0.2439\n",
      "Epoch 12/50, Train Loss: 0.0306, Val Loss: 0.2304\n",
      "Epoch 13/50, Train Loss: 0.0284, Val Loss: 0.2746\n",
      "Epoch 14/50, Train Loss: 0.0256, Val Loss: 0.2234\n",
      "Epoch 15/50, Train Loss: 0.0227, Val Loss: 0.2213\n",
      "Epoch 16/50, Train Loss: 0.0208, Val Loss: 0.2120\n",
      "Epoch 17/50, Train Loss: 0.0180, Val Loss: 0.2204\n",
      "Epoch 18/50, Train Loss: 0.0168, Val Loss: 0.2426\n",
      "Epoch 19/50, Train Loss: 0.0156, Val Loss: 0.2476\n",
      "Epoch 20/50, Train Loss: 0.0144, Val Loss: 0.2017\n",
      "Epoch 21/50, Train Loss: 0.0132, Val Loss: 0.2433\n",
      "Epoch 22/50, Train Loss: 0.0125, Val Loss: 0.2350\n",
      "Epoch 23/50, Train Loss: 0.0105, Val Loss: 0.2214\n",
      "Epoch 24/50, Train Loss: 0.0083, Val Loss: 0.2225\n",
      "Epoch 25/50, Train Loss: 0.0080, Val Loss: 0.2239\n",
      "Epoch 26/50, Train Loss: 0.0068, Val Loss: 0.2152\n",
      "Epoch 27/50, Train Loss: 0.0058, Val Loss: 0.2347\n",
      "Epoch 28/50, Train Loss: 0.0063, Val Loss: 0.2122\n",
      "Epoch 29/50, Train Loss: 0.0052, Val Loss: 0.2164\n",
      "Epoch 30/50, Train Loss: 0.0049, Val Loss: 0.2259\n",
      "Epoch 31/50, Train Loss: 0.0038, Val Loss: 0.2375\n",
      "Epoch 32/50, Train Loss: 0.0044, Val Loss: 0.2290\n",
      "Epoch 33/50, Train Loss: 0.0033, Val Loss: 0.2252\n",
      "Epoch 34/50, Train Loss: 0.0029, Val Loss: 0.2430\n",
      "Epoch 35/50, Train Loss: 0.0032, Val Loss: 0.2179\n",
      "Epoch 36/50, Train Loss: 0.0024, Val Loss: 0.2423\n",
      "Epoch 37/50, Train Loss: 0.0021, Val Loss: 0.2243\n",
      "Epoch 38/50, Train Loss: 0.0020, Val Loss: 0.2284\n",
      "Epoch 39/50, Train Loss: 0.0016, Val Loss: 0.2353\n",
      "Epoch 40/50, Train Loss: 0.0015, Val Loss: 0.2307\n",
      "Epoch 41/50, Train Loss: 0.0013, Val Loss: 0.2331\n",
      "Epoch 42/50, Train Loss: 0.0012, Val Loss: 0.2440\n",
      "Epoch 43/50, Train Loss: 0.0010, Val Loss: 0.2448\n",
      "Epoch 44/50, Train Loss: 0.0071, Val Loss: 0.2897\n",
      "Epoch 45/50, Train Loss: 0.0097, Val Loss: 0.2979\n",
      "Epoch 46/50, Train Loss: 0.0060, Val Loss: 0.2258\n",
      "Epoch 47/50, Train Loss: 0.0028, Val Loss: 0.2827\n",
      "Epoch 48/50, Train Loss: 0.0010, Val Loss: 0.2708\n",
      "Epoch 49/50, Train Loss: 0.0008, Val Loss: 0.2511\n",
      "Epoch 50/50, Train Loss: 0.0007, Val Loss: 0.2451\n",
      "Fold 30 Accuracy: 0.8993\n",
      "\n",
      "LOSO LSTM Average Accuracy : 0.9520\n"
     ]
    }
   ],
   "source": [
    "accuracy_loso_list = []\n",
    "classification_loso_reports = []\n",
    "\n",
    "# Training using LOSO cross-validation over subjects\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(raw_data, label_encoded, subject_data)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "    # 데이터 분할\n",
    "    X_train, X_test = raw_data[train_idx], raw_data[test_idx]\n",
    "    y_train, y_test = label_encoded[train_idx], label_encoded[test_idx]\n",
    "\n",
    "    # Reshpae the input data 3D for LSTM: (num_samples, sequence_length, num_features)\n",
    "    # Here, we assume a sequence length of 1.\n",
    "    X_train_3D = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test_3D = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    # Convert numpy arrays to torch tensors and transfer them to the device\n",
    "    X_train_tensor = torch.tensor(X_train_3D, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_3D, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # Create the model\n",
    "    num_classes = len(np.unique(label_encoded))\n",
    "    input_dim = X_train.shape[1] # featuer 수(컬럼)\n",
    "    hidden_dim = 32   # Set desired hidden dimension (the original code used 64 for some experiments)\n",
    "    num_layers = 1    # Number of LSTM layers (can be modified; currently using a singlt layer)\n",
    "    model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "    # Set the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Create a DataLoader for the training set\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Epoch traing loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad() # Reset gradients to zero for each batch\n",
    "            outputs = model(batch_X)  # Output shape: (batch, num_classes)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward() # Backpropagate the loss\n",
    "            optimizer.step()# Update model parameters using the computed gradients\n",
    "            epoch_loss += loss.item() * batch_X.size(0) # Multiply by batch size to accumulate total loss\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase (using the test set as validation)\n",
    "        model.eval() # Switch to evaluation mode (this prevents data leakage)\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_tensor).item()\n",
    "\n",
    "        # Verbose output: print the training and validation loss for each epoch\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Evaluation: After training, predict on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        # Select the class with the highest probability\n",
    "        _, y_pred_tensor = torch.max(outputs, dim=1)\n",
    "        y_pred = y_pred_tensor.cpu().numpy() # Convert the GPU tensor to a CPU numpy array\n",
    "\n",
    "    # Compute the accuracy and classification report\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy_loso_list.append(acc)\n",
    "    classification_loso_reports.append(report)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Calculate the average accuracy across all folds\n",
    "average_accuracy_loso = np.mean(accuracy_loso_list)\n",
    "print('\\nLOSO LSTM Average Accuracy : {:.4f}'.format(average_accuracy_loso))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LOSO]- With raw data [LSTM] - ACC: 0.9520"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity each subject accuracy [LOSO]- With raw data [LSTM- earlystopping & reduceLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 1/50, Train Loss: 0.3544, Val Loss: 0.1117\n",
      "Epoch 2/50, Train Loss: 0.0915, Val Loss: 0.0428\n",
      "Epoch 3/50, Train Loss: 0.0663, Val Loss: 0.0303\n",
      "Epoch 4/50, Train Loss: 0.0510, Val Loss: 0.0230\n",
      "Epoch 5/50, Train Loss: 0.0465, Val Loss: 0.0230\n",
      "Epoch 6/50, Train Loss: 0.0373, Val Loss: 0.0290\n",
      "Epoch 7/50, Train Loss: 0.0371, Val Loss: 0.0338\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 8/50, Train Loss: 0.0290, Val Loss: 0.0496\n",
      "Epoch 9/50, Train Loss: 0.0212, Val Loss: 0.0133\n",
      "Epoch 10/50, Train Loss: 0.0158, Val Loss: 0.0120\n",
      "Epoch 11/50, Train Loss: 0.0145, Val Loss: 0.0149\n",
      "Epoch 12/50, Train Loss: 0.0130, Val Loss: 0.0176\n",
      "Epoch 13/50, Train Loss: 0.0107, Val Loss: 0.0164\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 14/50, Train Loss: 0.0088, Val Loss: 0.0123\n",
      "Epoch 15/50, Train Loss: 0.0062, Val Loss: 0.0109\n",
      "Epoch 16/50, Train Loss: 0.0054, Val Loss: 0.0115\n",
      "Epoch 17/50, Train Loss: 0.0050, Val Loss: 0.0119\n",
      "Epoch 18/50, Train Loss: 0.0044, Val Loss: 0.0108\n",
      "Epoch 19/50, Train Loss: 0.0040, Val Loss: 0.0106\n",
      "Epoch 20/50, Train Loss: 0.0033, Val Loss: 0.0094\n",
      "Epoch 21/50, Train Loss: 0.0033, Val Loss: 0.0092\n",
      "Epoch 22/50, Train Loss: 0.0026, Val Loss: 0.0120\n",
      "Epoch 23/50, Train Loss: 0.0025, Val Loss: 0.0096\n",
      "Epoch 24/50, Train Loss: 0.0026, Val Loss: 0.0107\n",
      "Epoch 00025: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 25/50, Train Loss: 0.0017, Val Loss: 0.0118\n",
      "Epoch 26/50, Train Loss: 0.0014, Val Loss: 0.0095\n",
      "Early stopping triggered at epoch 26\n",
      "Fold 1 Accuracy: 0.9971\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 1/50, Train Loss: 0.3247, Val Loss: 0.3703\n",
      "Epoch 2/50, Train Loss: 0.0841, Val Loss: 0.3592\n",
      "Epoch 3/50, Train Loss: 0.0590, Val Loss: 0.5813\n",
      "Epoch 4/50, Train Loss: 0.0500, Val Loss: 0.4255\n",
      "Epoch 5/50, Train Loss: 0.0403, Val Loss: 0.4263\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 6/50, Train Loss: 0.0368, Val Loss: 0.4252\n",
      "Epoch 7/50, Train Loss: 0.0229, Val Loss: 0.5182\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 2 Accuracy: 0.8537\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 1/50, Train Loss: 0.3517, Val Loss: 0.1055\n",
      "Epoch 2/50, Train Loss: 0.0915, Val Loss: 0.0331\n",
      "Epoch 3/50, Train Loss: 0.0669, Val Loss: 0.0210\n",
      "Epoch 4/50, Train Loss: 0.0560, Val Loss: 0.0288\n",
      "Epoch 5/50, Train Loss: 0.0446, Val Loss: 0.0251\n",
      "Epoch 6/50, Train Loss: 0.0376, Val Loss: 0.0193\n",
      "Epoch 7/50, Train Loss: 0.0295, Val Loss: 0.0147\n",
      "Epoch 8/50, Train Loss: 0.0273, Val Loss: 0.0112\n",
      "Epoch 9/50, Train Loss: 0.0245, Val Loss: 0.0184\n",
      "Epoch 10/50, Train Loss: 0.0209, Val Loss: 0.0221\n",
      "Epoch 11/50, Train Loss: 0.0237, Val Loss: 0.0178\n",
      "Epoch 00012: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 12/50, Train Loss: 0.0174, Val Loss: 0.0139\n",
      "Epoch 13/50, Train Loss: 0.0109, Val Loss: 0.0075\n",
      "Epoch 14/50, Train Loss: 0.0079, Val Loss: 0.0098\n",
      "Epoch 15/50, Train Loss: 0.0077, Val Loss: 0.0071\n",
      "Epoch 16/50, Train Loss: 0.0066, Val Loss: 0.0094\n",
      "Epoch 17/50, Train Loss: 0.0056, Val Loss: 0.0115\n",
      "Epoch 18/50, Train Loss: 0.0042, Val Loss: 0.0075\n",
      "Epoch 19/50, Train Loss: 0.0046, Val Loss: 0.0050\n",
      "Epoch 20/50, Train Loss: 0.0031, Val Loss: 0.0075\n",
      "Epoch 21/50, Train Loss: 0.0037, Val Loss: 0.0060\n",
      "Epoch 22/50, Train Loss: 0.0037, Val Loss: 0.0066\n",
      "Epoch 00023: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 23/50, Train Loss: 0.0014, Val Loss: 0.0059\n",
      "Epoch 24/50, Train Loss: 0.0010, Val Loss: 0.0050\n",
      "Epoch 25/50, Train Loss: 0.0009, Val Loss: 0.0047\n",
      "Epoch 26/50, Train Loss: 0.0008, Val Loss: 0.0051\n",
      "Epoch 27/50, Train Loss: 0.0007, Val Loss: 0.0047\n",
      "Epoch 28/50, Train Loss: 0.0006, Val Loss: 0.0028\n",
      "Epoch 29/50, Train Loss: 0.0013, Val Loss: 0.0031\n",
      "Epoch 30/50, Train Loss: 0.0004, Val Loss: 0.0028\n",
      "Epoch 31/50, Train Loss: 0.0004, Val Loss: 0.0051\n",
      "Epoch 32/50, Train Loss: 0.0004, Val Loss: 0.0041\n",
      "Epoch 33/50, Train Loss: 0.0003, Val Loss: 0.0051\n",
      "Epoch 00034: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 34/50, Train Loss: 0.0003, Val Loss: 0.0032\n",
      "Epoch 35/50, Train Loss: 0.0002, Val Loss: 0.0035\n",
      "Early stopping triggered at epoch 35\n",
      "Fold 3 Accuracy: 0.9968\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 1/50, Train Loss: 0.3423, Val Loss: 0.1236\n",
      "Epoch 2/50, Train Loss: 0.0888, Val Loss: 0.0820\n",
      "Epoch 3/50, Train Loss: 0.0588, Val Loss: 0.0892\n",
      "Epoch 4/50, Train Loss: 0.0502, Val Loss: 0.1050\n",
      "Epoch 5/50, Train Loss: 0.0400, Val Loss: 0.0540\n",
      "Epoch 6/50, Train Loss: 0.0319, Val Loss: 0.0921\n",
      "Epoch 7/50, Train Loss: 0.0272, Val Loss: 0.0753\n",
      "Epoch 8/50, Train Loss: 0.0221, Val Loss: 0.0625\n",
      "Epoch 9/50, Train Loss: 0.0210, Val Loss: 0.0460\n",
      "Epoch 10/50, Train Loss: 0.0177, Val Loss: 0.0953\n",
      "Epoch 11/50, Train Loss: 0.0150, Val Loss: 0.0904\n",
      "Epoch 12/50, Train Loss: 0.0129, Val Loss: 0.0510\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 13/50, Train Loss: 0.0158, Val Loss: 0.1090\n",
      "Epoch 14/50, Train Loss: 0.0065, Val Loss: 0.0658\n",
      "Early stopping triggered at epoch 14\n",
      "Fold 4 Accuracy: 0.9781\n",
      "\n",
      "===== Fold 5 =====\n",
      "Epoch 1/50, Train Loss: 0.3482, Val Loss: 0.0945\n",
      "Epoch 2/50, Train Loss: 0.0899, Val Loss: 0.1135\n",
      "Epoch 3/50, Train Loss: 0.0640, Val Loss: 0.0725\n",
      "Epoch 4/50, Train Loss: 0.0480, Val Loss: 0.0587\n",
      "Epoch 5/50, Train Loss: 0.0451, Val Loss: 0.0361\n",
      "Epoch 6/50, Train Loss: 0.0375, Val Loss: 0.0552\n",
      "Epoch 7/50, Train Loss: 0.0319, Val Loss: 0.0585\n",
      "Epoch 8/50, Train Loss: 0.0242, Val Loss: 0.0353\n",
      "Epoch 9/50, Train Loss: 0.0194, Val Loss: 0.0775\n",
      "Epoch 10/50, Train Loss: 0.0183, Val Loss: 0.0526\n",
      "Epoch 11/50, Train Loss: 0.0248, Val Loss: 0.0337\n",
      "Epoch 12/50, Train Loss: 0.0131, Val Loss: 0.0546\n",
      "Epoch 13/50, Train Loss: 0.0153, Val Loss: 0.0326\n",
      "Epoch 14/50, Train Loss: 0.0105, Val Loss: 0.0346\n",
      "Epoch 15/50, Train Loss: 0.0097, Val Loss: 0.0506\n",
      "Epoch 16/50, Train Loss: 0.0067, Val Loss: 0.0183\n",
      "Epoch 17/50, Train Loss: 0.0072, Val Loss: 0.0663\n",
      "Epoch 18/50, Train Loss: 0.0064, Val Loss: 0.0372\n",
      "Epoch 19/50, Train Loss: 0.0099, Val Loss: 0.1410\n",
      "Epoch 00020: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 20/50, Train Loss: 0.0102, Val Loss: 0.0537\n",
      "Epoch 21/50, Train Loss: 0.0035, Val Loss: 0.0798\n",
      "Early stopping triggered at epoch 21\n",
      "Fold 5 Accuracy: 0.9817\n",
      "\n",
      "===== Fold 6 =====\n",
      "Epoch 1/50, Train Loss: 0.3308, Val Loss: 0.8880\n",
      "Epoch 2/50, Train Loss: 0.0869, Val Loss: 1.0247\n",
      "Epoch 3/50, Train Loss: 0.0613, Val Loss: 1.2037\n",
      "Epoch 4/50, Train Loss: 0.0501, Val Loss: 0.9005\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 5/50, Train Loss: 0.0464, Val Loss: 1.2961\n",
      "Epoch 6/50, Train Loss: 0.0297, Val Loss: 1.2960\n",
      "Early stopping triggered at epoch 6\n",
      "Fold 6 Accuracy: 0.7833\n",
      "\n",
      "===== Fold 7 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "c:\\Users\\vivid\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.3587, Val Loss: 0.0995\n",
      "Epoch 2/50, Train Loss: 0.0918, Val Loss: 0.0447\n",
      "Epoch 3/50, Train Loss: 0.0641, Val Loss: 0.0264\n",
      "Epoch 4/50, Train Loss: 0.0477, Val Loss: 0.0281\n",
      "Epoch 5/50, Train Loss: 0.0455, Val Loss: 0.0102\n",
      "Epoch 6/50, Train Loss: 0.0355, Val Loss: 0.0166\n",
      "Epoch 7/50, Train Loss: 0.0313, Val Loss: 0.0200\n",
      "Epoch 8/50, Train Loss: 0.0272, Val Loss: 0.0137\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 9/50, Train Loss: 0.0240, Val Loss: 0.0144\n",
      "Epoch 10/50, Train Loss: 0.0153, Val Loss: 0.0134\n",
      "Early stopping triggered at epoch 10\n",
      "Fold 7 Accuracy: 0.9970\n",
      "\n",
      "===== Fold 8 =====\n",
      "Epoch 1/50, Train Loss: 0.3428, Val Loss: 0.3305\n",
      "Epoch 2/50, Train Loss: 0.0830, Val Loss: 0.3130\n",
      "Epoch 3/50, Train Loss: 0.0609, Val Loss: 0.2666\n",
      "Epoch 4/50, Train Loss: 0.0467, Val Loss: 0.2407\n",
      "Epoch 5/50, Train Loss: 0.0368, Val Loss: 0.4132\n",
      "Epoch 6/50, Train Loss: 0.0291, Val Loss: 0.2513\n",
      "Epoch 7/50, Train Loss: 0.0258, Val Loss: 0.2694\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 8/50, Train Loss: 0.0238, Val Loss: 0.3100\n",
      "Epoch 9/50, Train Loss: 0.0138, Val Loss: 0.3826\n",
      "Early stopping triggered at epoch 9\n",
      "Fold 8 Accuracy: 0.8798\n",
      "\n",
      "===== Fold 9 =====\n",
      "Epoch 1/50, Train Loss: 0.3437, Val Loss: 0.1165\n",
      "Epoch 2/50, Train Loss: 0.0899, Val Loss: 0.0722\n",
      "Epoch 3/50, Train Loss: 0.0621, Val Loss: 0.0626\n",
      "Epoch 4/50, Train Loss: 0.0456, Val Loss: 0.1000\n",
      "Epoch 5/50, Train Loss: 0.0417, Val Loss: 0.0853\n",
      "Epoch 6/50, Train Loss: 0.0347, Val Loss: 0.0622\n",
      "Epoch 7/50, Train Loss: 0.0269, Val Loss: 0.0483\n",
      "Epoch 8/50, Train Loss: 0.0221, Val Loss: 0.0346\n",
      "Epoch 9/50, Train Loss: 0.0205, Val Loss: 0.0339\n",
      "Epoch 10/50, Train Loss: 0.0200, Val Loss: 0.0348\n",
      "Epoch 11/50, Train Loss: 0.0146, Val Loss: 0.1391\n",
      "Epoch 12/50, Train Loss: 0.0118, Val Loss: 0.0290\n",
      "Epoch 13/50, Train Loss: 0.0127, Val Loss: 0.0327\n",
      "Epoch 14/50, Train Loss: 0.0126, Val Loss: 0.0317\n",
      "Epoch 15/50, Train Loss: 0.0145, Val Loss: 0.0609\n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 16/50, Train Loss: 0.0112, Val Loss: 0.0834\n",
      "Epoch 17/50, Train Loss: 0.0042, Val Loss: 0.0537\n",
      "Early stopping triggered at epoch 17\n",
      "Fold 9 Accuracy: 0.9783\n",
      "\n",
      "===== Fold 10 =====\n",
      "Epoch 1/50, Train Loss: 0.3464, Val Loss: 0.1732\n",
      "Epoch 2/50, Train Loss: 0.0923, Val Loss: 0.0997\n",
      "Epoch 3/50, Train Loss: 0.0658, Val Loss: 0.1402\n",
      "Epoch 4/50, Train Loss: 0.0514, Val Loss: 0.0728\n",
      "Epoch 5/50, Train Loss: 0.0403, Val Loss: 0.1243\n",
      "Epoch 6/50, Train Loss: 0.0334, Val Loss: 0.1454\n",
      "Epoch 7/50, Train Loss: 0.0267, Val Loss: 0.0981\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 8/50, Train Loss: 0.0264, Val Loss: 0.0939\n",
      "Epoch 9/50, Train Loss: 0.0166, Val Loss: 0.1048\n",
      "Early stopping triggered at epoch 9\n",
      "Fold 10 Accuracy: 0.9643\n",
      "\n",
      "===== Fold 11 =====\n",
      "Epoch 1/50, Train Loss: 0.3463, Val Loss: 0.2293\n",
      "Epoch 2/50, Train Loss: 0.0924, Val Loss: 0.2084\n",
      "Epoch 3/50, Train Loss: 0.0652, Val Loss: 0.2502\n",
      "Epoch 4/50, Train Loss: 0.0494, Val Loss: 0.1951\n",
      "Epoch 5/50, Train Loss: 0.0391, Val Loss: 0.2150\n",
      "Epoch 6/50, Train Loss: 0.0360, Val Loss: 0.1728\n",
      "Epoch 7/50, Train Loss: 0.0311, Val Loss: 0.2409\n",
      "Epoch 8/50, Train Loss: 0.0279, Val Loss: 0.2409\n",
      "Epoch 9/50, Train Loss: 0.0233, Val Loss: 0.2598\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50, Train Loss: 0.0203, Val Loss: 0.2655\n",
      "Epoch 11/50, Train Loss: 0.0105, Val Loss: 0.2269\n",
      "Early stopping triggered at epoch 11\n",
      "Fold 11 Accuracy: 0.9361\n",
      "\n",
      "===== Fold 12 =====\n",
      "Epoch 1/50, Train Loss: 0.3469, Val Loss: 0.1388\n",
      "Epoch 2/50, Train Loss: 0.0900, Val Loss: 0.0609\n",
      "Epoch 3/50, Train Loss: 0.0615, Val Loss: 0.0479\n",
      "Epoch 4/50, Train Loss: 0.0491, Val Loss: 0.0741\n",
      "Epoch 5/50, Train Loss: 0.0372, Val Loss: 0.0623\n",
      "Epoch 6/50, Train Loss: 0.0325, Val Loss: 0.0831\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 7/50, Train Loss: 0.0283, Val Loss: 0.0504\n",
      "Epoch 8/50, Train Loss: 0.0179, Val Loss: 0.0523\n",
      "Early stopping triggered at epoch 8\n",
      "Fold 12 Accuracy: 0.9768\n",
      "\n",
      "===== Fold 13 =====\n",
      "Epoch 1/50, Train Loss: 0.3360, Val Loss: 0.2741\n",
      "Epoch 2/50, Train Loss: 0.0897, Val Loss: 0.1777\n",
      "Epoch 3/50, Train Loss: 0.0632, Val Loss: 0.2349\n",
      "Epoch 4/50, Train Loss: 0.0512, Val Loss: 0.2670\n",
      "Epoch 5/50, Train Loss: 0.0429, Val Loss: 0.2421\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 6/50, Train Loss: 0.0334, Val Loss: 0.2593\n",
      "Epoch 7/50, Train Loss: 0.0246, Val Loss: 0.2226\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 13 Accuracy: 0.9350\n",
      "\n",
      "===== Fold 14 =====\n",
      "Epoch 1/50, Train Loss: 0.3557, Val Loss: 0.2578\n",
      "Epoch 2/50, Train Loss: 0.0967, Val Loss: 0.0991\n",
      "Epoch 3/50, Train Loss: 0.0629, Val Loss: 0.3378\n",
      "Epoch 4/50, Train Loss: 0.0500, Val Loss: 0.1773\n",
      "Epoch 5/50, Train Loss: 0.0417, Val Loss: 0.1092\n",
      "Epoch 6/50, Train Loss: 0.0335, Val Loss: 0.0777\n",
      "Epoch 7/50, Train Loss: 0.0252, Val Loss: 0.1207\n",
      "Epoch 8/50, Train Loss: 0.0222, Val Loss: 0.0945\n",
      "Epoch 9/50, Train Loss: 0.0201, Val Loss: 0.1525\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50, Train Loss: 0.0188, Val Loss: 0.1649\n",
      "Epoch 11/50, Train Loss: 0.0105, Val Loss: 0.1106\n",
      "Early stopping triggered at epoch 11\n",
      "Fold 14 Accuracy: 0.9632\n",
      "\n",
      "===== Fold 15 =====\n",
      "Epoch 1/50, Train Loss: 0.3540, Val Loss: 0.1064\n",
      "Epoch 2/50, Train Loss: 0.0919, Val Loss: 0.0537\n",
      "Epoch 3/50, Train Loss: 0.0640, Val Loss: 0.0571\n",
      "Epoch 4/50, Train Loss: 0.0501, Val Loss: 0.0643\n",
      "Epoch 5/50, Train Loss: 0.0366, Val Loss: 0.0554\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 6/50, Train Loss: 0.0320, Val Loss: 0.0670\n",
      "Epoch 7/50, Train Loss: 0.0213, Val Loss: 0.0651\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 15 Accuracy: 0.9782\n",
      "\n",
      "===== Fold 16 =====\n",
      "Epoch 1/50, Train Loss: 0.3357, Val Loss: 0.1552\n",
      "Epoch 2/50, Train Loss: 0.0900, Val Loss: 0.0718\n",
      "Epoch 3/50, Train Loss: 0.0624, Val Loss: 0.0979\n",
      "Epoch 4/50, Train Loss: 0.0507, Val Loss: 0.0964\n",
      "Epoch 5/50, Train Loss: 0.0452, Val Loss: 0.0577\n",
      "Epoch 6/50, Train Loss: 0.0363, Val Loss: 0.0982\n",
      "Epoch 7/50, Train Loss: 0.0338, Val Loss: 0.1099\n",
      "Epoch 8/50, Train Loss: 0.0288, Val Loss: 0.0593\n",
      "Epoch 9/50, Train Loss: 0.0196, Val Loss: 0.0420\n",
      "Epoch 10/50, Train Loss: 0.0191, Val Loss: 0.1316\n",
      "Epoch 11/50, Train Loss: 0.0186, Val Loss: 0.0778\n",
      "Epoch 12/50, Train Loss: 0.0136, Val Loss: 0.0839\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 13/50, Train Loss: 0.0138, Val Loss: 0.0597\n",
      "Epoch 14/50, Train Loss: 0.0066, Val Loss: 0.0576\n",
      "Early stopping triggered at epoch 14\n",
      "Fold 16 Accuracy: 0.9812\n",
      "\n",
      "===== Fold 17 =====\n",
      "Epoch 1/50, Train Loss: 0.3582, Val Loss: 0.2002\n",
      "Epoch 2/50, Train Loss: 0.0988, Val Loss: 0.1037\n",
      "Epoch 3/50, Train Loss: 0.0662, Val Loss: 0.0743\n",
      "Epoch 4/50, Train Loss: 0.0506, Val Loss: 0.0461\n",
      "Epoch 5/50, Train Loss: 0.0419, Val Loss: 0.0338\n",
      "Epoch 6/50, Train Loss: 0.0335, Val Loss: 0.0214\n",
      "Epoch 7/50, Train Loss: 0.0288, Val Loss: 0.0453\n",
      "Epoch 8/50, Train Loss: 0.0305, Val Loss: 0.0230\n",
      "Epoch 9/50, Train Loss: 0.0221, Val Loss: 0.0342\n",
      "Epoch 10/50, Train Loss: 0.0190, Val Loss: 0.0176\n",
      "Epoch 11/50, Train Loss: 0.0165, Val Loss: 0.0280\n",
      "Epoch 12/50, Train Loss: 0.0139, Val Loss: 0.0189\n",
      "Epoch 13/50, Train Loss: 0.0119, Val Loss: 0.0163\n",
      "Epoch 14/50, Train Loss: 0.0153, Val Loss: 0.0257\n",
      "Epoch 15/50, Train Loss: 0.0160, Val Loss: 0.0650\n",
      "Epoch 16/50, Train Loss: 0.0097, Val Loss: 0.0358\n",
      "Epoch 00017: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 17/50, Train Loss: 0.0101, Val Loss: 0.0258\n",
      "Epoch 18/50, Train Loss: 0.0040, Val Loss: 0.0282\n",
      "Early stopping triggered at epoch 18\n",
      "Fold 17 Accuracy: 0.9869\n",
      "\n",
      "===== Fold 18 =====\n",
      "Epoch 1/50, Train Loss: 0.3450, Val Loss: 0.3635\n",
      "Epoch 2/50, Train Loss: 0.0909, Val Loss: 0.2967\n",
      "Epoch 3/50, Train Loss: 0.0627, Val Loss: 0.2819\n",
      "Epoch 4/50, Train Loss: 0.0483, Val Loss: 0.2174\n",
      "Epoch 5/50, Train Loss: 0.0428, Val Loss: 0.2211\n",
      "Epoch 6/50, Train Loss: 0.0327, Val Loss: 0.2180\n",
      "Epoch 7/50, Train Loss: 0.0293, Val Loss: 0.2443\n",
      "Epoch 00008: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 8/50, Train Loss: 0.0284, Val Loss: 0.3429\n",
      "Epoch 9/50, Train Loss: 0.0166, Val Loss: 0.3008\n",
      "Early stopping triggered at epoch 9\n",
      "Fold 18 Accuracy: 0.8900\n",
      "\n",
      "===== Fold 19 =====\n",
      "Epoch 1/50, Train Loss: 0.3562, Val Loss: 0.1121\n",
      "Epoch 2/50, Train Loss: 0.0935, Val Loss: 0.0687\n",
      "Epoch 3/50, Train Loss: 0.0639, Val Loss: 0.0546\n",
      "Epoch 4/50, Train Loss: 0.0517, Val Loss: 0.0707\n",
      "Epoch 5/50, Train Loss: 0.0425, Val Loss: 0.0390\n",
      "Epoch 6/50, Train Loss: 0.0342, Val Loss: 0.0278\n",
      "Epoch 7/50, Train Loss: 0.0293, Val Loss: 0.0262\n",
      "Epoch 8/50, Train Loss: 0.0244, Val Loss: 0.0277\n",
      "Epoch 9/50, Train Loss: 0.0211, Val Loss: 0.0250\n",
      "Epoch 10/50, Train Loss: 0.0249, Val Loss: 0.0325\n",
      "Epoch 11/50, Train Loss: 0.0166, Val Loss: 0.0421\n",
      "Epoch 12/50, Train Loss: 0.0178, Val Loss: 0.0252\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 13/50, Train Loss: 0.0133, Val Loss: 0.0257\n",
      "Epoch 14/50, Train Loss: 0.0066, Val Loss: 0.0261\n",
      "Early stopping triggered at epoch 14\n",
      "Fold 19 Accuracy: 0.9898\n",
      "\n",
      "===== Fold 20 =====\n",
      "Epoch 1/50, Train Loss: 0.3439, Val Loss: 0.0627\n",
      "Epoch 2/50, Train Loss: 0.0930, Val Loss: 0.0871\n",
      "Epoch 3/50, Train Loss: 0.0655, Val Loss: 0.0271\n",
      "Epoch 4/50, Train Loss: 0.0492, Val Loss: 0.0476\n",
      "Epoch 5/50, Train Loss: 0.0405, Val Loss: 0.0656\n",
      "Epoch 6/50, Train Loss: 0.0331, Val Loss: 0.0261\n",
      "Epoch 7/50, Train Loss: 0.0349, Val Loss: 0.0488\n",
      "Epoch 8/50, Train Loss: 0.0336, Val Loss: 0.0311\n",
      "Epoch 9/50, Train Loss: 0.0258, Val Loss: 0.0415\n",
      "Epoch 10/50, Train Loss: 0.0209, Val Loss: 0.0177\n",
      "Epoch 11/50, Train Loss: 0.0187, Val Loss: 0.0158\n",
      "Epoch 12/50, Train Loss: 0.0157, Val Loss: 0.0204\n",
      "Epoch 13/50, Train Loss: 0.0138, Val Loss: 0.0204\n",
      "Epoch 14/50, Train Loss: 0.0148, Val Loss: 0.0347\n",
      "Epoch 00015: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 15/50, Train Loss: 0.0159, Val Loss: 0.0285\n",
      "Epoch 16/50, Train Loss: 0.0072, Val Loss: 0.0329\n",
      "Early stopping triggered at epoch 16\n",
      "Fold 20 Accuracy: 0.9787\n",
      "\n",
      "===== Fold 21 =====\n",
      "Epoch 1/50, Train Loss: 0.3427, Val Loss: 0.2715\n",
      "Epoch 2/50, Train Loss: 0.0888, Val Loss: 0.2658\n",
      "Epoch 3/50, Train Loss: 0.0604, Val Loss: 0.2153\n",
      "Epoch 4/50, Train Loss: 0.0461, Val Loss: 0.1788\n",
      "Epoch 5/50, Train Loss: 0.0352, Val Loss: 0.1442\n",
      "Epoch 6/50, Train Loss: 0.0283, Val Loss: 0.1527\n",
      "Epoch 7/50, Train Loss: 0.0258, Val Loss: 0.1896\n",
      "Epoch 8/50, Train Loss: 0.0231, Val Loss: 0.1443\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 9/50, Train Loss: 0.0196, Val Loss: 0.2333\n",
      "Epoch 10/50, Train Loss: 0.0109, Val Loss: 0.1986\n",
      "Early stopping triggered at epoch 10\n",
      "Fold 21 Accuracy: 0.9346\n",
      "\n",
      "===== Fold 22 =====\n",
      "Epoch 1/50, Train Loss: 0.3538, Val Loss: 0.1492\n",
      "Epoch 2/50, Train Loss: 0.0884, Val Loss: 0.0858\n",
      "Epoch 3/50, Train Loss: 0.0628, Val Loss: 0.0443\n",
      "Epoch 4/50, Train Loss: 0.0466, Val Loss: 0.1241\n",
      "Epoch 5/50, Train Loss: 0.0373, Val Loss: 0.1683\n",
      "Epoch 6/50, Train Loss: 0.0323, Val Loss: 0.0734\n",
      "Epoch 7/50, Train Loss: 0.0268, Val Loss: 0.0366\n",
      "Epoch 8/50, Train Loss: 0.0231, Val Loss: 0.0570\n",
      "Epoch 9/50, Train Loss: 0.0214, Val Loss: 0.0670\n",
      "Epoch 10/50, Train Loss: 0.0204, Val Loss: 0.0440\n",
      "Epoch 11/50, Train Loss: 0.0158, Val Loss: 0.0313\n",
      "Epoch 12/50, Train Loss: 0.0131, Val Loss: 0.0904\n",
      "Epoch 13/50, Train Loss: 0.0136, Val Loss: 0.0188\n",
      "Epoch 14/50, Train Loss: 0.0108, Val Loss: 0.1186\n",
      "Epoch 15/50, Train Loss: 0.0105, Val Loss: 0.1309\n",
      "Epoch 16/50, Train Loss: 0.0093, Val Loss: 0.0992\n",
      "Epoch 00017: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 17/50, Train Loss: 0.0222, Val Loss: 0.0800\n",
      "Epoch 18/50, Train Loss: 0.0070, Val Loss: 0.0844\n",
      "Early stopping triggered at epoch 18\n",
      "Fold 22 Accuracy: 0.9651\n",
      "\n",
      "===== Fold 23 =====\n",
      "Epoch 1/50, Train Loss: 0.3618, Val Loss: 0.1003\n",
      "Epoch 2/50, Train Loss: 0.0903, Val Loss: 0.0919\n",
      "Epoch 3/50, Train Loss: 0.0624, Val Loss: 0.0595\n",
      "Epoch 4/50, Train Loss: 0.0491, Val Loss: 0.0771\n",
      "Epoch 5/50, Train Loss: 0.0425, Val Loss: 0.0941\n",
      "Epoch 6/50, Train Loss: 0.0333, Val Loss: 0.0661\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 7/50, Train Loss: 0.0279, Val Loss: 0.0611\n",
      "Epoch 8/50, Train Loss: 0.0186, Val Loss: 0.0731\n",
      "Early stopping triggered at epoch 8\n",
      "Fold 23 Accuracy: 0.9795\n",
      "\n",
      "===== Fold 24 =====\n",
      "Epoch 1/50, Train Loss: 0.3449, Val Loss: 0.0938\n",
      "Epoch 2/50, Train Loss: 0.0915, Val Loss: 0.0396\n",
      "Epoch 3/50, Train Loss: 0.0625, Val Loss: 0.0369\n",
      "Epoch 4/50, Train Loss: 0.0533, Val Loss: 0.0232\n",
      "Epoch 5/50, Train Loss: 0.0403, Val Loss: 0.0326\n",
      "Epoch 6/50, Train Loss: 0.0327, Val Loss: 0.0248\n",
      "Epoch 7/50, Train Loss: 0.0340, Val Loss: 0.0218\n",
      "Epoch 8/50, Train Loss: 0.0300, Val Loss: 0.0222\n",
      "Epoch 9/50, Train Loss: 0.0212, Val Loss: 0.0267\n",
      "Epoch 10/50, Train Loss: 0.0180, Val Loss: 0.0122\n",
      "Epoch 11/50, Train Loss: 0.0194, Val Loss: 0.0098\n",
      "Epoch 12/50, Train Loss: 0.0129, Val Loss: 0.0135\n",
      "Epoch 13/50, Train Loss: 0.0134, Val Loss: 0.0220\n",
      "Epoch 14/50, Train Loss: 0.0184, Val Loss: 0.0285\n",
      "Epoch 00015: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 15/50, Train Loss: 0.0128, Val Loss: 0.0189\n",
      "Epoch 16/50, Train Loss: 0.0062, Val Loss: 0.0150\n",
      "Early stopping triggered at epoch 16\n",
      "Fold 24 Accuracy: 0.9948\n",
      "\n",
      "===== Fold 25 =====\n",
      "Epoch 1/50, Train Loss: 0.3491, Val Loss: 0.1222\n",
      "Epoch 2/50, Train Loss: 0.0898, Val Loss: 0.0874\n",
      "Epoch 3/50, Train Loss: 0.0609, Val Loss: 0.0653\n",
      "Epoch 4/50, Train Loss: 0.0483, Val Loss: 0.0810\n",
      "Epoch 5/50, Train Loss: 0.0409, Val Loss: 0.0681\n",
      "Epoch 6/50, Train Loss: 0.0300, Val Loss: 0.0797\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 7/50, Train Loss: 0.0252, Val Loss: 0.0663\n",
      "Epoch 8/50, Train Loss: 0.0163, Val Loss: 0.0684\n",
      "Early stopping triggered at epoch 8\n",
      "Fold 25 Accuracy: 0.9779\n",
      "\n",
      "===== Fold 26 =====\n",
      "Epoch 1/50, Train Loss: 0.3427, Val Loss: 0.2366\n",
      "Epoch 2/50, Train Loss: 0.0867, Val Loss: 0.3036\n",
      "Epoch 3/50, Train Loss: 0.0666, Val Loss: 0.2057\n",
      "Epoch 4/50, Train Loss: 0.0506, Val Loss: 0.2988\n",
      "Epoch 5/50, Train Loss: 0.0413, Val Loss: 0.1946\n",
      "Epoch 6/50, Train Loss: 0.0341, Val Loss: 0.2042\n",
      "Epoch 7/50, Train Loss: 0.0294, Val Loss: 0.2153\n",
      "Epoch 8/50, Train Loss: 0.0256, Val Loss: 0.2270\n",
      "Epoch 9/50, Train Loss: 0.0221, Val Loss: 0.1911\n",
      "Epoch 10/50, Train Loss: 0.0180, Val Loss: 0.3453\n",
      "Epoch 11/50, Train Loss: 0.0156, Val Loss: 0.3252\n",
      "Epoch 12/50, Train Loss: 0.0255, Val Loss: 0.1506\n",
      "Epoch 13/50, Train Loss: 0.0128, Val Loss: 0.2918\n",
      "Epoch 14/50, Train Loss: 0.0179, Val Loss: 0.3306\n",
      "Epoch 15/50, Train Loss: 0.0084, Val Loss: 0.2754\n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 16/50, Train Loss: 0.0095, Val Loss: 0.1723\n",
      "Epoch 17/50, Train Loss: 0.0049, Val Loss: 0.2692\n",
      "Early stopping triggered at epoch 17\n",
      "Fold 26 Accuracy: 0.9272\n",
      "\n",
      "===== Fold 27 =====\n",
      "Epoch 1/50, Train Loss: 0.3346, Val Loss: 0.4933\n",
      "Epoch 2/50, Train Loss: 0.0889, Val Loss: 0.4320\n",
      "Epoch 3/50, Train Loss: 0.0622, Val Loss: 0.4480\n",
      "Epoch 4/50, Train Loss: 0.0479, Val Loss: 0.4180\n",
      "Epoch 5/50, Train Loss: 0.0417, Val Loss: 0.7930\n",
      "Epoch 6/50, Train Loss: 0.0400, Val Loss: 0.3050\n",
      "Epoch 7/50, Train Loss: 0.0351, Val Loss: 0.4895\n",
      "Epoch 8/50, Train Loss: 0.0250, Val Loss: 0.5214\n",
      "Epoch 9/50, Train Loss: 0.0245, Val Loss: 0.6833\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50, Train Loss: 0.0215, Val Loss: 0.6850\n",
      "Epoch 11/50, Train Loss: 0.0120, Val Loss: 0.6435\n",
      "Early stopping triggered at epoch 11\n",
      "Fold 27 Accuracy: 0.8862\n",
      "\n",
      "===== Fold 28 =====\n",
      "Epoch 1/50, Train Loss: 0.3422, Val Loss: 0.2955\n",
      "Epoch 2/50, Train Loss: 0.0890, Val Loss: 0.2127\n",
      "Epoch 3/50, Train Loss: 0.0633, Val Loss: 0.2885\n",
      "Epoch 4/50, Train Loss: 0.0474, Val Loss: 0.2469\n",
      "Epoch 5/50, Train Loss: 0.0385, Val Loss: 0.2499\n",
      "Epoch 6/50, Train Loss: 0.0350, Val Loss: 0.2109\n",
      "Epoch 7/50, Train Loss: 0.0300, Val Loss: 0.2868\n",
      "Epoch 8/50, Train Loss: 0.0236, Val Loss: 0.2608\n",
      "Epoch 9/50, Train Loss: 0.0201, Val Loss: 0.2548\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 10/50, Train Loss: 0.0249, Val Loss: 0.3176\n",
      "Epoch 11/50, Train Loss: 0.0114, Val Loss: 0.2717\n",
      "Early stopping triggered at epoch 11\n",
      "Fold 28 Accuracy: 0.9318\n",
      "\n",
      "===== Fold 29 =====\n",
      "Epoch 1/50, Train Loss: 0.3517, Val Loss: 0.1452\n",
      "Epoch 2/50, Train Loss: 0.0883, Val Loss: 0.0850\n",
      "Epoch 3/50, Train Loss: 0.0616, Val Loss: 0.1113\n",
      "Epoch 4/50, Train Loss: 0.0474, Val Loss: 0.1629\n",
      "Epoch 5/50, Train Loss: 0.0398, Val Loss: 0.0949\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 6/50, Train Loss: 0.0345, Val Loss: 0.0926\n",
      "Epoch 7/50, Train Loss: 0.0239, Val Loss: 0.0975\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 29 Accuracy: 0.9644\n",
      "\n",
      "===== Fold 30 =====\n",
      "Epoch 1/50, Train Loss: 0.3314, Val Loss: 0.3805\n",
      "Epoch 2/50, Train Loss: 0.0878, Val Loss: 0.2744\n",
      "Epoch 3/50, Train Loss: 0.0622, Val Loss: 0.2967\n",
      "Epoch 4/50, Train Loss: 0.0450, Val Loss: 0.2899\n",
      "Epoch 5/50, Train Loss: 0.0412, Val Loss: 0.3690\n",
      "Epoch 00006: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 6/50, Train Loss: 0.0337, Val Loss: 0.2959\n",
      "Epoch 7/50, Train Loss: 0.0236, Val Loss: 0.2746\n",
      "Early stopping triggered at epoch 7\n",
      "Fold 30 Accuracy: 0.8854\n",
      "\n",
      "LOSO LSTM Average Accuracy : 0.9491\n"
     ]
    }
   ],
   "source": [
    "accuracy_loso_list = []\n",
    "classification_loso_reports = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(logo.split(raw_data, label_encoded, subject_data)):\n",
    "    print(f\"\\n===== Fold {fold+1} =====\")\n",
    "\n",
    "    X_train, X_test = raw_data[train_idx], raw_data[test_idx]\n",
    "    y_train, y_test = label_encoded[train_idx], label_encoded[test_idx]\n",
    "\n",
    "    X_train_3D = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test_3D = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_3D, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_3D, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "    # 모델 생성\n",
    "    num_classes = len(np.unique(label_encoded))\n",
    "    input_dim = X_train.shape[1] # featuer 수(컬럼)\n",
    "    hidden_dim = 64  \n",
    "    num_layers = 1   \n",
    "    model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    # 에포크 별 학습 루프\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(batch_X)  \n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_X.size(0) \n",
    "        \n",
    "        epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test_tensor)\n",
    "            val_loss = criterion(val_outputs, y_test_tensor).item()\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        \n",
    "        if no_improve_epochs >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        # 가장 높은 확률을 가진 클래스 선택\n",
    "        _, y_pred_tensor = torch.max(outputs, dim=1)\n",
    "        y_pred = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy_loso_list.append(acc)\n",
    "    classification_loso_reports.append(report)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "\n",
    "average_accuracy_loso = np.mean(accuracy_loso_list)\n",
    "print('\\nLOSO LSTM Average Accuracy : {:.4f}'.format(average_accuracy_loso))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [LOSO]- With raw data [LSTM- earlystopping & reduceLR] - ACC: 0.9491"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Each Activity Accuracy] - With raw data [LGBM] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity: LAYING\n",
      "Accuracy on testset\t0.9198\n",
      "\n",
      "Activity: STANDING\n",
      "Accuracy on testset\t0.8721\n",
      "\n",
      "Activity: SITTING\n",
      "Accuracy on testset\t0.7618\n",
      "\n",
      "Activity: WALKING\n",
      "Accuracy on testset\t0.9861\n",
      "\n",
      "Activity: WALKING_UPSTAIRS\n",
      "Accuracy on testset\t0.9819\n",
      "\n",
      "Activity: WALKING_DOWNSTAIRS\n",
      "Accuracy on testset\t0.9830\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts = label.value_counts()\n",
    "lgbm_raw_data = []\n",
    "\n",
    "for activity in label_counts.index:\n",
    "    act_data = both_df[label == activity].copy()\n",
    "    act_data_data = act_data.pop('Data')\n",
    "    act_subject_data = act_data.pop('subject')\n",
    "\n",
    "    # scale the data\n",
    "    scl = StandardScaler()\n",
    "    act_data = scl.fit_transform(act_data)\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoded = enc.fit_transform(act_subject_data)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(act_data, label_encoded, random_state = 3)\n",
    "\n",
    "    print('Activity: {}'.format(activity))\n",
    "    lgbm = LGBMClassifier(n_estimators = 500, random_state = 3, verbose =-1)\n",
    "    lgm = lgbm.fit(X_train, y_train)\n",
    "\n",
    "    score = accuracy_score(y_true = y_test, y_pred = lgbm.predict(X_test))\n",
    "    print('Accuracy on testset\\t{:.4f}\\n'.format(score))\n",
    "    lgbm_raw_data.append([activity, score])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Each Activity Accuracy] - With raw data [LSTM] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity: LAYING\n",
      "Epoch 1 / 50, Train Loss : 3.4290\n",
      "Epoch 2 / 50, Train Loss : 3.2212\n",
      "Epoch 3 / 50, Train Loss : 3.0527\n",
      "Epoch 4 / 50, Train Loss : 2.8620\n",
      "Epoch 5 / 50, Train Loss : 2.6674\n",
      "Epoch 6 / 50, Train Loss : 2.4801\n",
      "Epoch 7 / 50, Train Loss : 2.3020\n",
      "Epoch 8 / 50, Train Loss : 2.1376\n",
      "Epoch 9 / 50, Train Loss : 1.9863\n",
      "Epoch 10 / 50, Train Loss : 1.8482\n",
      "Epoch 11 / 50, Train Loss : 1.7236\n",
      "Epoch 12 / 50, Train Loss : 1.6088\n",
      "Epoch 13 / 50, Train Loss : 1.5023\n",
      "Epoch 14 / 50, Train Loss : 1.4073\n",
      "Epoch 15 / 50, Train Loss : 1.3177\n",
      "Epoch 16 / 50, Train Loss : 1.2398\n",
      "Epoch 17 / 50, Train Loss : 1.1648\n",
      "Epoch 18 / 50, Train Loss : 1.0931\n",
      "Epoch 19 / 50, Train Loss : 1.0310\n",
      "Epoch 20 / 50, Train Loss : 0.9712\n",
      "Epoch 21 / 50, Train Loss : 0.9159\n",
      "Epoch 22 / 50, Train Loss : 0.8646\n",
      "Epoch 23 / 50, Train Loss : 0.8169\n",
      "Epoch 24 / 50, Train Loss : 0.7719\n",
      "Epoch 25 / 50, Train Loss : 0.7295\n",
      "Epoch 26 / 50, Train Loss : 0.6888\n",
      "Epoch 27 / 50, Train Loss : 0.6526\n",
      "Epoch 28 / 50, Train Loss : 0.6189\n",
      "Epoch 29 / 50, Train Loss : 0.5863\n",
      "Epoch 30 / 50, Train Loss : 0.5591\n",
      "Epoch 31 / 50, Train Loss : 0.5283\n",
      "Epoch 32 / 50, Train Loss : 0.5020\n",
      "Epoch 33 / 50, Train Loss : 0.4782\n",
      "Epoch 34 / 50, Train Loss : 0.4542\n",
      "Epoch 35 / 50, Train Loss : 0.4323\n",
      "Epoch 36 / 50, Train Loss : 0.4120\n",
      "Epoch 37 / 50, Train Loss : 0.3951\n",
      "Epoch 38 / 50, Train Loss : 0.3780\n",
      "Epoch 39 / 50, Train Loss : 0.3612\n",
      "Epoch 40 / 50, Train Loss : 0.3469\n",
      "Epoch 41 / 50, Train Loss : 0.3322\n",
      "Epoch 42 / 50, Train Loss : 0.3198\n",
      "Epoch 43 / 50, Train Loss : 0.3067\n",
      "Epoch 44 / 50, Train Loss : 0.2954\n",
      "Epoch 45 / 50, Train Loss : 0.2850\n",
      "Epoch 46 / 50, Train Loss : 0.2743\n",
      "Epoch 47 / 50, Train Loss : 0.2644\n",
      "Epoch 48 / 50, Train Loss : 0.2557\n",
      "Epoch 49 / 50, Train Loss : 0.2471\n",
      "Epoch 50 / 50, Train Loss : 0.2385\n",
      "Accuracy on testset for activity LAYING: 0.7593\n",
      "\n",
      "Activity: STANDING\n",
      "Epoch 1 / 50, Train Loss : 3.3675\n",
      "Epoch 2 / 50, Train Loss : 3.2597\n",
      "Epoch 3 / 50, Train Loss : 3.1536\n",
      "Epoch 4 / 50, Train Loss : 3.0323\n",
      "Epoch 5 / 50, Train Loss : 2.9022\n",
      "Epoch 6 / 50, Train Loss : 2.7784\n",
      "Epoch 7 / 50, Train Loss : 2.6531\n",
      "Epoch 8 / 50, Train Loss : 2.5300\n",
      "Epoch 9 / 50, Train Loss : 2.4059\n",
      "Epoch 10 / 50, Train Loss : 2.2914\n",
      "Epoch 11 / 50, Train Loss : 2.1784\n",
      "Epoch 12 / 50, Train Loss : 2.0736\n",
      "Epoch 13 / 50, Train Loss : 1.9706\n",
      "Epoch 14 / 50, Train Loss : 1.8706\n",
      "Epoch 15 / 50, Train Loss : 1.7761\n",
      "Epoch 16 / 50, Train Loss : 1.6864\n",
      "Epoch 17 / 50, Train Loss : 1.6026\n",
      "Epoch 18 / 50, Train Loss : 1.5244\n",
      "Epoch 19 / 50, Train Loss : 1.4492\n",
      "Epoch 20 / 50, Train Loss : 1.3747\n",
      "Epoch 21 / 50, Train Loss : 1.3070\n",
      "Epoch 22 / 50, Train Loss : 1.2422\n",
      "Epoch 23 / 50, Train Loss : 1.1825\n",
      "Epoch 24 / 50, Train Loss : 1.1279\n",
      "Epoch 25 / 50, Train Loss : 1.0671\n",
      "Epoch 26 / 50, Train Loss : 1.0183\n",
      "Epoch 27 / 50, Train Loss : 0.9679\n",
      "Epoch 28 / 50, Train Loss : 0.9196\n",
      "Epoch 29 / 50, Train Loss : 0.8782\n",
      "Epoch 30 / 50, Train Loss : 0.8391\n",
      "Epoch 31 / 50, Train Loss : 0.7995\n",
      "Epoch 32 / 50, Train Loss : 0.7622\n",
      "Epoch 33 / 50, Train Loss : 0.7295\n",
      "Epoch 34 / 50, Train Loss : 0.6968\n",
      "Epoch 35 / 50, Train Loss : 0.6654\n",
      "Epoch 36 / 50, Train Loss : 0.6366\n",
      "Epoch 37 / 50, Train Loss : 0.6111\n",
      "Epoch 38 / 50, Train Loss : 0.5860\n",
      "Epoch 39 / 50, Train Loss : 0.5610\n",
      "Epoch 40 / 50, Train Loss : 0.5374\n",
      "Epoch 41 / 50, Train Loss : 0.5164\n",
      "Epoch 42 / 50, Train Loss : 0.4947\n",
      "Epoch 43 / 50, Train Loss : 0.4777\n",
      "Epoch 44 / 50, Train Loss : 0.4573\n",
      "Epoch 45 / 50, Train Loss : 0.4417\n",
      "Epoch 46 / 50, Train Loss : 0.4273\n",
      "Epoch 47 / 50, Train Loss : 0.4091\n",
      "Epoch 48 / 50, Train Loss : 0.3930\n",
      "Epoch 49 / 50, Train Loss : 0.3799\n",
      "Epoch 50 / 50, Train Loss : 0.3658\n",
      "Accuracy on testset for activity STANDING: 0.6059\n",
      "\n",
      "Activity: SITTING\n",
      "Epoch 1 / 50, Train Loss : 3.3818\n",
      "Epoch 2 / 50, Train Loss : 3.2909\n",
      "Epoch 3 / 50, Train Loss : 3.2017\n",
      "Epoch 4 / 50, Train Loss : 3.1043\n",
      "Epoch 5 / 50, Train Loss : 2.9949\n",
      "Epoch 6 / 50, Train Loss : 2.8889\n",
      "Epoch 7 / 50, Train Loss : 2.7844\n",
      "Epoch 8 / 50, Train Loss : 2.6824\n",
      "Epoch 9 / 50, Train Loss : 2.5841\n",
      "Epoch 10 / 50, Train Loss : 2.4855\n",
      "Epoch 11 / 50, Train Loss : 2.3912\n",
      "Epoch 12 / 50, Train Loss : 2.2986\n",
      "Epoch 13 / 50, Train Loss : 2.2134\n",
      "Epoch 14 / 50, Train Loss : 2.1266\n",
      "Epoch 15 / 50, Train Loss : 2.0437\n",
      "Epoch 16 / 50, Train Loss : 1.9620\n",
      "Epoch 17 / 50, Train Loss : 1.8870\n",
      "Epoch 18 / 50, Train Loss : 1.8120\n",
      "Epoch 19 / 50, Train Loss : 1.7342\n",
      "Epoch 20 / 50, Train Loss : 1.6652\n",
      "Epoch 21 / 50, Train Loss : 1.5989\n",
      "Epoch 22 / 50, Train Loss : 1.5343\n",
      "Epoch 23 / 50, Train Loss : 1.4704\n",
      "Epoch 24 / 50, Train Loss : 1.4121\n",
      "Epoch 25 / 50, Train Loss : 1.3519\n",
      "Epoch 26 / 50, Train Loss : 1.2971\n",
      "Epoch 27 / 50, Train Loss : 1.2468\n",
      "Epoch 28 / 50, Train Loss : 1.1928\n",
      "Epoch 29 / 50, Train Loss : 1.1457\n",
      "Epoch 30 / 50, Train Loss : 1.0988\n",
      "Epoch 31 / 50, Train Loss : 1.0559\n",
      "Epoch 32 / 50, Train Loss : 1.0116\n",
      "Epoch 33 / 50, Train Loss : 0.9727\n",
      "Epoch 34 / 50, Train Loss : 0.9344\n",
      "Epoch 35 / 50, Train Loss : 0.8982\n",
      "Epoch 36 / 50, Train Loss : 0.8636\n",
      "Epoch 37 / 50, Train Loss : 0.8304\n",
      "Epoch 38 / 50, Train Loss : 0.8003\n",
      "Epoch 39 / 50, Train Loss : 0.7705\n",
      "Epoch 40 / 50, Train Loss : 0.7431\n",
      "Epoch 41 / 50, Train Loss : 0.7146\n",
      "Epoch 42 / 50, Train Loss : 0.6870\n",
      "Epoch 43 / 50, Train Loss : 0.6671\n",
      "Epoch 44 / 50, Train Loss : 0.6414\n",
      "Epoch 45 / 50, Train Loss : 0.6184\n",
      "Epoch 46 / 50, Train Loss : 0.5984\n",
      "Epoch 47 / 50, Train Loss : 0.5799\n",
      "Epoch 48 / 50, Train Loss : 0.5599\n",
      "Epoch 49 / 50, Train Loss : 0.5427\n",
      "Epoch 50 / 50, Train Loss : 0.5241\n",
      "Accuracy on testset for activity SITTING: 0.5303\n",
      "\n",
      "Activity: WALKING\n",
      "Epoch 1 / 50, Train Loss : 3.2586\n",
      "Epoch 2 / 50, Train Loss : 2.9465\n",
      "Epoch 3 / 50, Train Loss : 2.6736\n",
      "Epoch 4 / 50, Train Loss : 2.4121\n",
      "Epoch 5 / 50, Train Loss : 2.1683\n",
      "Epoch 6 / 50, Train Loss : 1.9416\n",
      "Epoch 7 / 50, Train Loss : 1.7282\n",
      "Epoch 8 / 50, Train Loss : 1.5322\n",
      "Epoch 9 / 50, Train Loss : 1.3551\n",
      "Epoch 10 / 50, Train Loss : 1.1952\n",
      "Epoch 11 / 50, Train Loss : 1.0533\n",
      "Epoch 12 / 50, Train Loss : 0.9293\n",
      "Epoch 13 / 50, Train Loss : 0.8222\n",
      "Epoch 14 / 50, Train Loss : 0.7299\n",
      "Epoch 15 / 50, Train Loss : 0.6490\n",
      "Epoch 16 / 50, Train Loss : 0.5792\n",
      "Epoch 17 / 50, Train Loss : 0.5175\n",
      "Epoch 18 / 50, Train Loss : 0.4646\n",
      "Epoch 19 / 50, Train Loss : 0.4182\n",
      "Epoch 20 / 50, Train Loss : 0.3776\n",
      "Epoch 21 / 50, Train Loss : 0.3420\n",
      "Epoch 22 / 50, Train Loss : 0.3109\n",
      "Epoch 23 / 50, Train Loss : 0.2835\n",
      "Epoch 24 / 50, Train Loss : 0.2594\n",
      "Epoch 25 / 50, Train Loss : 0.2380\n",
      "Epoch 26 / 50, Train Loss : 0.2193\n",
      "Epoch 27 / 50, Train Loss : 0.2023\n",
      "Epoch 28 / 50, Train Loss : 0.1870\n",
      "Epoch 29 / 50, Train Loss : 0.1734\n",
      "Epoch 30 / 50, Train Loss : 0.1613\n",
      "Epoch 31 / 50, Train Loss : 0.1504\n",
      "Epoch 32 / 50, Train Loss : 0.1405\n",
      "Epoch 33 / 50, Train Loss : 0.1318\n",
      "Epoch 34 / 50, Train Loss : 0.1237\n",
      "Epoch 35 / 50, Train Loss : 0.1166\n",
      "Epoch 36 / 50, Train Loss : 0.1097\n",
      "Epoch 37 / 50, Train Loss : 0.1036\n",
      "Epoch 38 / 50, Train Loss : 0.0979\n",
      "Epoch 39 / 50, Train Loss : 0.0926\n",
      "Epoch 40 / 50, Train Loss : 0.0878\n",
      "Epoch 41 / 50, Train Loss : 0.0833\n",
      "Epoch 42 / 50, Train Loss : 0.0793\n",
      "Epoch 43 / 50, Train Loss : 0.0755\n",
      "Epoch 44 / 50, Train Loss : 0.0720\n",
      "Epoch 45 / 50, Train Loss : 0.0687\n",
      "Epoch 46 / 50, Train Loss : 0.0656\n",
      "Epoch 47 / 50, Train Loss : 0.0627\n",
      "Epoch 48 / 50, Train Loss : 0.0600\n",
      "Epoch 49 / 50, Train Loss : 0.0575\n",
      "Epoch 50 / 50, Train Loss : 0.0551\n",
      "Accuracy on testset for activity WALKING: 0.9907\n",
      "\n",
      "Activity: WALKING_UPSTAIRS\n",
      "Epoch 1 / 50, Train Loss : 3.3128\n",
      "Epoch 2 / 50, Train Loss : 3.0813\n",
      "Epoch 3 / 50, Train Loss : 2.8773\n",
      "Epoch 4 / 50, Train Loss : 2.6764\n",
      "Epoch 5 / 50, Train Loss : 2.4833\n",
      "Epoch 6 / 50, Train Loss : 2.2993\n",
      "Epoch 7 / 50, Train Loss : 2.1228\n",
      "Epoch 8 / 50, Train Loss : 1.9531\n",
      "Epoch 9 / 50, Train Loss : 1.7920\n",
      "Epoch 10 / 50, Train Loss : 1.6390\n",
      "Epoch 11 / 50, Train Loss : 1.4986\n",
      "Epoch 12 / 50, Train Loss : 1.3651\n",
      "Epoch 13 / 50, Train Loss : 1.2407\n",
      "Epoch 14 / 50, Train Loss : 1.1284\n",
      "Epoch 15 / 50, Train Loss : 1.0254\n",
      "Epoch 16 / 50, Train Loss : 0.9316\n",
      "Epoch 17 / 50, Train Loss : 0.8458\n",
      "Epoch 18 / 50, Train Loss : 0.7678\n",
      "Epoch 19 / 50, Train Loss : 0.6994\n",
      "Epoch 20 / 50, Train Loss : 0.6340\n",
      "Epoch 21 / 50, Train Loss : 0.5783\n",
      "Epoch 22 / 50, Train Loss : 0.5287\n",
      "Epoch 23 / 50, Train Loss : 0.4827\n",
      "Epoch 24 / 50, Train Loss : 0.4427\n",
      "Epoch 25 / 50, Train Loss : 0.4072\n",
      "Epoch 26 / 50, Train Loss : 0.3752\n",
      "Epoch 27 / 50, Train Loss : 0.3466\n",
      "Epoch 28 / 50, Train Loss : 0.3202\n",
      "Epoch 29 / 50, Train Loss : 0.2971\n",
      "Epoch 30 / 50, Train Loss : 0.2763\n",
      "Epoch 31 / 50, Train Loss : 0.2575\n",
      "Epoch 32 / 50, Train Loss : 0.2404\n",
      "Epoch 33 / 50, Train Loss : 0.2249\n",
      "Epoch 34 / 50, Train Loss : 0.2109\n",
      "Epoch 35 / 50, Train Loss : 0.1979\n",
      "Epoch 36 / 50, Train Loss : 0.1868\n",
      "Epoch 37 / 50, Train Loss : 0.1758\n",
      "Epoch 38 / 50, Train Loss : 0.1661\n",
      "Epoch 39 / 50, Train Loss : 0.1574\n",
      "Epoch 40 / 50, Train Loss : 0.1487\n",
      "Epoch 41 / 50, Train Loss : 0.1409\n",
      "Epoch 42 / 50, Train Loss : 0.1338\n",
      "Epoch 43 / 50, Train Loss : 0.1268\n",
      "Epoch 44 / 50, Train Loss : 0.1209\n",
      "Epoch 45 / 50, Train Loss : 0.1151\n",
      "Epoch 46 / 50, Train Loss : 0.1095\n",
      "Epoch 47 / 50, Train Loss : 0.1046\n",
      "Epoch 48 / 50, Train Loss : 0.0999\n",
      "Epoch 49 / 50, Train Loss : 0.0957\n",
      "Epoch 50 / 50, Train Loss : 0.0916\n",
      "Accuracy on testset for activity WALKING_UPSTAIRS: 0.9922\n",
      "\n",
      "Activity: WALKING_DOWNSTAIRS\n",
      "Epoch 1 / 50, Train Loss : 3.3338\n",
      "Epoch 2 / 50, Train Loss : 3.1278\n",
      "Epoch 3 / 50, Train Loss : 2.9459\n",
      "Epoch 4 / 50, Train Loss : 2.7696\n",
      "Epoch 5 / 50, Train Loss : 2.5952\n",
      "Epoch 6 / 50, Train Loss : 2.4218\n",
      "Epoch 7 / 50, Train Loss : 2.2531\n",
      "Epoch 8 / 50, Train Loss : 2.0876\n",
      "Epoch 9 / 50, Train Loss : 1.9310\n",
      "Epoch 10 / 50, Train Loss : 1.7788\n",
      "Epoch 11 / 50, Train Loss : 1.6350\n",
      "Epoch 12 / 50, Train Loss : 1.4990\n",
      "Epoch 13 / 50, Train Loss : 1.3700\n",
      "Epoch 14 / 50, Train Loss : 1.2473\n",
      "Epoch 15 / 50, Train Loss : 1.1327\n",
      "Epoch 16 / 50, Train Loss : 1.0286\n",
      "Epoch 17 / 50, Train Loss : 0.9334\n",
      "Epoch 18 / 50, Train Loss : 0.8467\n",
      "Epoch 19 / 50, Train Loss : 0.7686\n",
      "Epoch 20 / 50, Train Loss : 0.6980\n",
      "Epoch 21 / 50, Train Loss : 0.6349\n",
      "Epoch 22 / 50, Train Loss : 0.5789\n",
      "Epoch 23 / 50, Train Loss : 0.5277\n",
      "Epoch 24 / 50, Train Loss : 0.4824\n",
      "Epoch 25 / 50, Train Loss : 0.4417\n",
      "Epoch 26 / 50, Train Loss : 0.4055\n",
      "Epoch 27 / 50, Train Loss : 0.3737\n",
      "Epoch 28 / 50, Train Loss : 0.3449\n",
      "Epoch 29 / 50, Train Loss : 0.3190\n",
      "Epoch 30 / 50, Train Loss : 0.2957\n",
      "Epoch 31 / 50, Train Loss : 0.2747\n",
      "Epoch 32 / 50, Train Loss : 0.2556\n",
      "Epoch 33 / 50, Train Loss : 0.2385\n",
      "Epoch 34 / 50, Train Loss : 0.2230\n",
      "Epoch 35 / 50, Train Loss : 0.2087\n",
      "Epoch 36 / 50, Train Loss : 0.1957\n",
      "Epoch 37 / 50, Train Loss : 0.1837\n",
      "Epoch 38 / 50, Train Loss : 0.1726\n",
      "Epoch 39 / 50, Train Loss : 0.1624\n",
      "Epoch 40 / 50, Train Loss : 0.1529\n",
      "Epoch 41 / 50, Train Loss : 0.1445\n",
      "Epoch 42 / 50, Train Loss : 0.1365\n",
      "Epoch 43 / 50, Train Loss : 0.1294\n",
      "Epoch 44 / 50, Train Loss : 0.1228\n",
      "Epoch 45 / 50, Train Loss : 0.1167\n",
      "Epoch 46 / 50, Train Loss : 0.1111\n",
      "Epoch 47 / 50, Train Loss : 0.1058\n",
      "Epoch 48 / 50, Train Loss : 0.1009\n",
      "Epoch 49 / 50, Train Loss : 0.0964\n",
      "Epoch 50 / 50, Train Loss : 0.0921\n",
      "Accuracy on testset for activity WALKING_DOWNSTAIRS: 0.9688\n",
      "\n",
      "Final LSTM Results per Activity:\n",
      "Activity: LAYING, Accuracy: 0.7593\n",
      "Activity: STANDING, Accuracy: 0.6059\n",
      "Activity: SITTING, Accuracy: 0.5303\n",
      "Activity: WALKING, Accuracy: 0.9907\n",
      "Activity: WALKING_UPSTAIRS, Accuracy: 0.9922\n",
      "Activity: WALKING_DOWNSTAIRS, Accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# activity별로 정확도 lstm\n",
    "lstm_raw_data = []\n",
    "for activity in label_counts.index:\n",
    "    act_data = both_df[label == activity] #label value와 activiy가 같은 데이터 index 출력\n",
    "    act_data_data = act_data.pop('Data')\n",
    "    act_subject_data = act_data.pop('subject')\n",
    "\n",
    "    scl = StandardScaler()\n",
    "    act_data_scaled = scl.fit_transform(act_data)\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoded = enc.fit_transform(act_subject_data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(act_data_scaled, label_encoded, random_state = 3) \n",
    "\n",
    "    print(f'Activity: {activity}')\n",
    "\n",
    "    X_train_3D = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test_3D = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_3D, dtype = torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test_3D, dtype = torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype = torch.long).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype = torch.long).to(device)\n",
    "\n",
    "    input_dim = X_train_tensor.shape[2] # feature 수\n",
    "    num_classes = len(np.unique(label_encoded))\n",
    "    model = LSTMClassifier(input_dim, hidden_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = epoch_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1} / {num_epochs}, Train Loss : {epoch_loss:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, y_pred_tensor = torch.max(outputs, dim = 1)\n",
    "        y_pred = y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy on testset for activity {activity}: {acc:.4f}\\n')\n",
    "\n",
    "    lstm_raw_data.append([activity, acc])\n",
    "\n",
    "print('Final LSTM Results per Activity:')\n",
    "for activity, score in lstm_raw_data:\n",
    "    print(f'Activity: {activity}, Accuracy: {score:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limited Data for LSTM Training:\n",
    "\n",
    "It appears that the dataset is not large enough for the LSTM model to learn effectively. With limited data, the LSTM may struggle to capture complex temporal patterns, leading to poor generalization and suboptimal performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Each Activity Accuracy [LOSO] ] - With raw data [LGBM] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity: WALKING\n",
      "LOSO Accuracy: 0.0000\n",
      "\n",
      "Final LGBM Results per Activity (LOSO):\n",
      "Activity: WALKING, Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "lgbm_raw_data  = []\n",
    "\n",
    "for activity in label_counts.index:\n",
    "    if activity != 'WALKING':\n",
    "        continue\n",
    "    \n",
    "    act_data = both_df[label == activity].copy()\n",
    "    act_data_data = act_data.pop('Data')\n",
    "    act_subject_data = act_data.pop('subject')\n",
    "\n",
    "    # StandardScaler 적용\n",
    "    scl = StandardScaler()\n",
    "    act_data_scaled = scl.fit_transform(act_data)\n",
    "\n",
    "    # Label Encoding 적용\n",
    "    enc = LabelEncoder()\n",
    "    label_encoded = enc.fit_transform(act_subject_data)\n",
    "\n",
    "    groups = act_subject_data.values\n",
    "    \n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    fold_scores = []\n",
    "\n",
    "    # LOSO 적용\n",
    "    for train_idx, test_idx in logo.split(act_data_scaled, label_encoded, groups = groups):\n",
    "        X_train, X_test = act_data_scaled[train_idx], act_data_scaled[test_idx]\n",
    "        y_train, y_test = label_encoded[train_idx], label_encoded[test_idx]\n",
    "\n",
    "        # 모델 학습\n",
    "        lgbm = LGBMClassifier(n_estimators = 500, random_state = 3, device = 'gpu', verbose = -1) # LGBM GPU사용은 직접 지정\n",
    "        lgbm.fit(X_train, y_train)\n",
    "\n",
    "        # 예측 및 평가\n",
    "        score = accuracy_score(y_true = y_test, y_pred = lgbm.predict(X_test))\n",
    "        fold_scores.append(score)\n",
    "    \n",
    "    avg_score = np.mean(fold_scores)\n",
    "    print(f\"Activity: {activity}\")\n",
    "    print(f'LOSO Accuracy: {avg_score:.4f}\\n')\n",
    "\n",
    "    lgbm_raw_data.append([activity, avg_score])\n",
    "\n",
    "print('Final LGBM Results per Activity (LOSO):')\n",
    "for activity, score in lgbm_raw_data:\n",
    "    print(f\"Activity: {activity}, Accuracy: {score:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOSO Performance Issues for Each Activity:\n",
    "\n",
    "When applying Leave-One-Subject-Out (LOSO) cross-validation for each activity, the model completely fails to learn—for example, the accuracy for the \"LAYING\" activity is 0. \n",
    "\n",
    "I initially suspected that \"LAYING\" data might be inherently challenging to learn. \n",
    "\n",
    "However, even when I conducted experiments on the \"WALKING\" activity using a non-LOSO approach with an LGBM model (which achieved 99% accuracy), the model still failed to learn effectively under the LOSO scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
